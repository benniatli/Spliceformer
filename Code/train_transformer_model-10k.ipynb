{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import getData,spliceDataset,h5pyDataset,getDataPointList,getDataPointListFull,DataPointFull\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d\n",
    "from src.gpu_metrics import run_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 12 13:46:13 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              54W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              54W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-40GB          On  | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-40GB          On  | 00000000:BD:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              56W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3166851/2404782504.py\", line 3, in <module>\n",
      "    annotation, transcriptToLabel, seqData = getData(data_dir, setType)\n",
      "  File \"/splice-site-prediction/Code/src/dataloader.py\", line 65, in getData\n",
      "    seqData[chrom] = load_npz(path).tocsr()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/scipy/sparse/_matrix_io.py\", line 146, in load_npz\n",
      "    return cls((loaded['data'], (loaded['row'], loaded['col'])), shape=loaded['shape'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py\", line 254, in __getitem__\n",
      "    return format.read_array(bytes,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/numpy/lib/format.py\", line 779, in read_array\n",
      "    data = _read_bytes(fp, read_size, \"array data\")\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/numpy/lib/format.py\", line 908, in _read_bytes\n",
      "    r = fp.read(size - len(data))\n",
      "  File \"/opt/conda/lib/python3.8/zipfile.py\", line 940, in read\n",
      "    data = self._read1(n)\n",
      "  File \"/opt/conda/lib/python3.8/zipfile.py\", line 1030, in _read1\n",
      "    self._update_crc(data)\n",
      "  File \"/opt/conda/lib/python3.8/zipfile.py\", line 955, in _update_crc\n",
      "    self._running_crc = crc32(newdata, self._running_crc)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1477, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/opt/conda/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/opt/conda/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/opt/conda/lib/python3.8/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/opt/conda/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/opt/conda/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3166851/2404782504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msetType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscriptToLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/splice-site-prediction/Code/src/dataloader.py\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(data_dir, setType)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/sparse_sequence_data/{}_*.npz'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mseqData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranscriptToLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseqData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/scipy/sparse/_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmatrix_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 return format.read_array(bytes,\n\u001b[0m\u001b[1;32m    255\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_crc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m_update_crc\u001b[0;34m(self, newdata)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0;31m# Check the CRC if we're at the end of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "data_dir = '../Data'\n",
    "setType = 'train'\n",
    "annotation, transcriptToLabel, seqData = getData(data_dir, setType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListFull(annotation_train,transcriptToLabel,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListFull(annotation_validation,transcriptToLabel,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "hs = []\n",
    "learning_rate= k*1e-3\n",
    "gamma=0.5\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|█████████████████████████████| 2716/2716 [42:16<00:00,  1.07it/s, a_r=0.87, d_r=0.884, loss=0.000217, r_a=0.998, r_d=0.982, r_loss=0.948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.015583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|████████████████████████████| 2716/2716 [39:56<00:00,  1.13it/s, a_r=0.894, d_r=0.906, loss=0.000192, r_a=0.998, r_d=0.991, r_loss=0.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|██████████████████████████████| 2716/2716 [39:23<00:00,  1.15it/s, a_r=0.903, d_r=0.91, loss=0.00018, r_a=0.999, r_d=0.987, r_loss=0.642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|████████████████████████████| 2716/2716 [39:29<00:00,  1.15it/s, a_r=0.915, d_r=0.924, loss=0.000157, r_a=0.999, r_d=0.989, r_loss=0.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|██████████████████████████████| 2716/2716 [39:45<00:00,  1.14it/s, a_r=0.926, d_r=0.934, loss=0.000148, r_a=0.999, r_d=0.981, r_loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|█████████████████████████████| 2716/2716 [39:10<00:00,  1.16it/s, a_r=0.935, d_r=0.94, loss=0.000136, r_a=0.999, r_d=0.981, r_loss=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|████████████████████████████| 2716/2716 [39:24<00:00,  1.15it/s, a_r=0.947, d_r=0.953, loss=0.000118, r_a=0.998, r_d=0.986, r_loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|█████████████████████████████| 2716/2716 [39:55<00:00,  1.13it/s, a_r=0.959, d_r=0.966, loss=8.87e-5, r_a=0.999, r_d=0.992, r_loss=0.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|██████████████████████████████| 2716/2716 [39:45<00:00,  1.14it/s, a_r=0.968, d_r=0.97, loss=7.89e-5, r_a=0.999, r_d=0.986, r_loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|████████████████████████████| 2716/2716 [38:48<00:00,  1.17it/s, a_r=0.969, d_r=0.973, loss=7.07e-5, r_a=0.999, r_d=0.988, r_loss=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|█████████████████████████████| 2716/2716 [38:42<00:00,  1.17it/s, a_r=0.868, d_r=0.886, loss=0.000213, r_a=0.997, r_d=0.996, r_loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.016443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|████████████████████████████| 2716/2716 [39:00<00:00,  1.16it/s, a_r=0.895, d_r=0.908, loss=0.000183, r_a=0.998, r_d=0.998, r_loss=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|████████████████████████████| 2716/2716 [39:27<00:00,  1.15it/s, a_r=0.909, d_r=0.914, loss=0.000177, r_a=0.998, r_d=0.998, r_loss=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10:  49%|█████████████▌              | 1320/2716 [19:25<21:24,  1.09it/s, a_r=0.916, d_r=0.921, loss=0.000164, r_a=0.999, r_d=0.999, r_loss=0.601]"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_10k_090724_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max)\n",
    "    hs.append(h)\n",
    "\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    #plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [03:39<00:00, 13.74s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/SpliceAITrainingCode/dataset_test_0_10k.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_10k_090724_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs[:,:,CL_max//2:-CL_max//2].unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00018911732415244895\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9962\t0.9498\t0.9868\t0.9909\t0.977\t0.9777\t0.3228\t0.0026\t0.0004\t13572\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.995\t0.9531\t0.9895\t0.9924\t0.9794\t0.9789\t0.3274\t0.0021\t0.0003\t13619\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95146616278256 0.978190153837204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [03:20<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision score = 0.978190153837204 (95% confidence interval: [0.9767384931445122, 0.9795814752578735])\n",
      "topk score = 0.95146616278256 (95% confidence interval: [0.9496711785022705, 0.953234727457985])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "run_bootstrap(Y_true_acceptor,Y_pred_acceptor,Y_true_donor,Y_pred_donor,n_bootstraps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "data_dir = '../Data'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData(data_dir, setType)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16*8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 130/130 [31:49<00:00, 14.69s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_10k_090724_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00010955187279639043\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9805\t0.9385\t0.9913\t0.9956\t0.9635\t0.9796\t0.4549\t0.0027\t0.0004\t84193\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9816\t0.9433\t0.9941\t0.9971\t0.9684\t0.9804\t0.4851\t0.0021\t0.0003\t84624\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_10k_test_set_predictions_090724.csv.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408830479757446 0.9659759998321533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [32:37<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision score = 0.9659759998321533 (95% confidence interval: [0.9648173242807389, 0.9665709853172302])\n",
      "topk score = 0.9408830479757446 (95% confidence interval: [0.9399479672451853, 0.9415226325095927])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_10k_test_set_predictions_090724.csv.gz')\n",
    "run_bootstrap(df['Y_true_acceptor'].astype(np.int8),df['Y_pred_acceptor'].astype(np.float32),df['Y_true_donor'].astype(np.int8),df['Y_pred_donor'].astype(np.float32),n_bootstraps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
