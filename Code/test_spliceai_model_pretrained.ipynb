{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 16:55:25.202764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv1D, Cropping1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import add\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "import pickle\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pkg_resources import resource_filename\n",
    "from src.dataloader import get_GTEX_v8_Data,getDataPointListGTEX,spliceDataset\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d\n",
    "\n",
    "def getSpliceProb(input_sequence):\n",
    "    paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "    models = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "    #x = one_hot_encode('N'*(context//2) + input_sequence + 'N'*(context//2))[None, :]\n",
    "    x = one_hot_encode(input_sequence)[None, :]\n",
    "    y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "    acceptor_prob = y[0, :, 1]\n",
    "    donor_prob = y[0, :, 2]\n",
    "    return acceptor_prob, donor_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  9 16:55:32 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    35W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    34W / 250W |      0MiB / 32510MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Model\n",
    "###############################################################################\n",
    "\n",
    "L = 32\n",
    "N_GPUS = 8\n",
    "\n",
    "#if int(sys.argv[1]) == 80:\n",
    "#    W = np.asarray([11, 11, 11, 11])\n",
    "#    AR = np.asarray([1, 1, 1, 1])\n",
    "#    BATCH_SIZE = 18*N_GPUS\n",
    "#elif int(sys.argv[1]) == 400:\n",
    "#    W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11])\n",
    "#    AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4])\n",
    "#    BATCH_SIZE = 18*N_GPUS\n",
    "#elif int(sys.argv[1]) == 2000:\n",
    "#    W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "#                    21, 21, 21, 21])\n",
    "#    AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "#                     10, 10, 10, 10])\n",
    "#    BATCH_SIZE = 12*N_GPUS\n",
    "#elif int(sys.argv[1]) == 10000:\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 6*N_GPUS\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_max=10000\n",
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "\n",
    "SL=5000\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "splice_table='/odinn/tmp/benediktj/Data/SplicePrediction/annotation_ensembl_v87_train.txt'\n",
    "ref_genome='/odinn/tmp/benediktj/SpliceAITrainingCode/genome.fa'\n",
    "# Input details\n",
    "\n",
    "data_dir='/odinn/tmp/benediktj/Data/SplicePrediction/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0\n",
    "\n",
    "IN_MAP = np.asarray([[0, 0, 0, 0],\n",
    "                     [1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "# One-hot encoding of the inputs: 0 is for padding, and 1, 2, 3, 4 correspond\n",
    "# to A, C, G, T respectively.\n",
    "\n",
    "OUT_MAP = np.asarray([[1, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 1],\n",
    "                      [0, 0, 0]])\n",
    "# One-hot encoding of the outputs: 0 is for no splice, 1 is for acceptor,\n",
    "# 2 is for donor and -1 is for padding.\n",
    "\n",
    "\n",
    "def ceil_div(x, y):\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "\n",
    "def create_datapoints(seq, strand, tx_start, tx_end, jn_start, jn_end):\n",
    "    # This function first converts the sequence into an integer array, where\n",
    "    # A, C, G, T, N are mapped to 1, 2, 3, 4, 0 respectively. If the strand is\n",
    "    # negative, then reverse complementing is done. The splice junctions \n",
    "    # are also converted into an array of integers, where 0, 1, 2, -1 \n",
    "    # correspond to no splicing, acceptor, donor and missing information\n",
    "    # respectively. It then calls reformat_data and one_hot_encode\n",
    "    # and returns X, Y which can be used by Keras models.\n",
    "\n",
    "    seq = 'N'*(CL_max//2) + seq[CL_max//2:-CL_max//2] + 'N'*(CL_max//2)\n",
    "    # Context being provided on the RNA and not the DNA\n",
    "\n",
    "    seq = seq.upper().replace('A', '1').replace('C', '2')\n",
    "    seq = seq.replace('G', '3').replace('T', '4').replace('N', '0')\n",
    "\n",
    "    tx_start = int(tx_start)\n",
    "    tx_end = int(tx_end) \n",
    "\n",
    "    jn_start = map(lambda x: map(int, re.split(',', x)[:-1]), jn_start)\n",
    "    jn_end = map(lambda x: map(int, re.split(',', x)[:-1]), jn_end)\n",
    "\n",
    "    if strand == '+':\n",
    "\n",
    "        X0 = np.asarray(map(int, list(seq)))\n",
    "        Y0 = [-np.ones(tx_end-tx_start+1) for t in range(1)]\n",
    "\n",
    "        for t in range(1):\n",
    "            \n",
    "            if len(jn_start[t]) > 0:\n",
    "                Y0[t] = np.zeros(tx_end-tx_start+1)\n",
    "                for c in jn_start[t]:\n",
    "                    if tx_start <= c <= tx_end:\n",
    "                        Y0[t][c-tx_start] = 2\n",
    "                for c in jn_end[t]:\n",
    "                    if tx_start <= c <= tx_end:\n",
    "                        Y0[t][c-tx_start] = 1\n",
    "                    # Ignoring junctions outside annotated tx start/end sites\n",
    "                     \n",
    "    elif strand == '-':\n",
    "\n",
    "        X0 = (5-np.asarray(map(int, list(seq[::-1])))) % 5  # Reverse complement\n",
    "        Y0 = [-np.ones(tx_end-tx_start+1) for t in range(1)]\n",
    "\n",
    "        for t in range(1):\n",
    "\n",
    "            if len(jn_start[t]) > 0:\n",
    "                Y0[t] = np.zeros(tx_end-tx_start+1)\n",
    "                for c in jn_end[t]:\n",
    "                    if tx_start <= c <= tx_end:\n",
    "                        Y0[t][tx_end-c] = 2\n",
    "                for c in jn_start[t]:\n",
    "                    if tx_start <= c <= tx_end:\n",
    "                        Y0[t][tx_end-c] = 1\n",
    "\n",
    "    Xd, Yd = reformat_data(X0, Y0)\n",
    "    X, Y = one_hot_encode(Xd, Yd)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def reformat_data(X0, Y0):\n",
    "    # This function converts X0, Y0 of the create_datapoints function into\n",
    "    # blocks such that the data is broken down into data points where the\n",
    "    # input is a sequence of length SL+CL_max corresponding to SL nucleotides\n",
    "    # of interest and CL_max context nucleotides, the output is a sequence of\n",
    "    # length SL corresponding to the splicing information of the nucleotides\n",
    "    # of interest. The CL_max context nucleotides are such that they are\n",
    "    # CL_max/2 on either side of the SL nucleotides of interest.\n",
    "\n",
    "    num_points = ceil_div(len(Y0[0]), SL)\n",
    "\n",
    "    Xd = np.zeros((num_points, SL+CL_max))\n",
    "    Yd = [-np.ones((num_points, SL)) for t in range(1)]\n",
    "\n",
    "    X0 = np.pad(X0, [0, SL], 'constant', constant_values=0)\n",
    "    Y0 = [np.pad(Y0[t], [0, SL], 'constant', constant_values=-1)\n",
    "         for t in range(1)]\n",
    "\n",
    "    for i in range(num_points):\n",
    "        Xd[i] = X0[SL*i:CL_max+SL*(i+1)]\n",
    "\n",
    "    for t in range(1):\n",
    "        for i in range(num_points):\n",
    "            Yd[t][i] = Y0[t][SL*i:SL*(i+1)]\n",
    "\n",
    "    return Xd, Yd\n",
    "\n",
    "\n",
    "def clip_datapoints(X, Y, CL, N_GPUS):\n",
    "    # This function is necessary to make sure of the following:\n",
    "    # (i) Each time model_m.fit is called, the number of datapoints is a\n",
    "    # multiple of N_GPUS. Failure to ensure this often results in crashes.\n",
    "    # (ii) If the required context length is less than CL_max, then\n",
    "    # appropriate clipping is done below.\n",
    "    # Additionally, Y is also converted to a list (the .h5 files store \n",
    "    # them as an array).\n",
    "\n",
    "    rem = X.shape[0]%N_GPUS\n",
    "    clip = (CL_max-CL)//2\n",
    "\n",
    "    if rem != 0 and clip != 0:\n",
    "        return X[:-rem, clip:-clip], [Y[t][:-rem] for t in range(1)]\n",
    "    elif rem == 0 and clip != 0:\n",
    "        return X[:, clip:-clip], [Y[t] for t in range(1)]\n",
    "    elif rem != 0 and clip == 0:\n",
    "        return X[:-rem], [Y[t][:-rem] for t in range(1)]\n",
    "    else:\n",
    "        return X, [Y[t] for t in range(1)]\n",
    "\n",
    "\n",
    "def one_hot_encode(Xd, Yd):\n",
    "\n",
    "    return IN_MAP[Xd.astype('int8')], \\\n",
    "           [OUT_MAP[Yd[t].astype('int8')] for t in range(1)]\n",
    "\n",
    "\n",
    "def print_topl_statistics(y_true, y_pred):\n",
    "    # Prints the following information: top-kL statistics for k=0.5,1,2,4,\n",
    "    # auprc, thresholds for k=0.5,1,2,4, number of true splice sites.\n",
    "\n",
    "    idx_true = np.nonzero(y_true == 1)[0]\n",
    "    argsorted_y_pred = np.argsort(y_pred)\n",
    "    sorted_y_pred = np.sort(y_pred)\n",
    "\n",
    "    topkl_accuracy = []\n",
    "    threshold = []\n",
    "\n",
    "    for top_length in [0.5, 1, 2, 4]:\n",
    "\n",
    "        idx_pred = argsorted_y_pred[-int(top_length*len(idx_true)):]\n",
    "\n",
    "        topkl_accuracy += [np.size(np.intersect1d(idx_true, idx_pred)) \\\n",
    "                  / float(min(len(idx_pred), len(idx_true)))]\n",
    "        threshold += [sorted_y_pred[-int(top_length*len(idx_true))]]\n",
    "\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "          np.round(topkl_accuracy[0],4), np.round(topkl_accuracy[1],4), np.round(topkl_accuracy[2],4),\n",
    "          np.round(topkl_accuracy[3],4), np.round(auprc,4), np.round(threshold[0],4), np.round(threshold[1],4),\n",
    "          np.round(threshold[2],4), np.round(threshold[3],4), len(idx_true)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualUnit(l, w, ar):\n",
    "    # Residual unit proposed in \"Identity mappings in Deep Residual Networks\"\n",
    "    # by He et al.\n",
    "\n",
    "    def f(input_node):\n",
    "\n",
    "        bn1 = BatchNormalization()(input_node)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv1D(l, [w], dilation_rate=[ar], padding='same')(act1)\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv1D(l, [w], dilation_rate=[ar], padding='same')(act2)\n",
    "        output_node = add([conv2, input_node])\n",
    "\n",
    "        return output_node\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def SpliceAI(L, W, AR):\n",
    "    # L: Number of convolution kernels\n",
    "    # W: Convolution window size in each residual unit\n",
    "    # AR: Atrous rate in each residual unit\n",
    "\n",
    "    assert len(W) == len(AR)\n",
    "\n",
    "    CL = 2 * np.sum(AR*(W-1))\n",
    "\n",
    "    input0 = Input(shape=(None, 4))\n",
    "    conv = Conv1D(L, 1)(input0)\n",
    "    skip = Conv1D(L, 1)(conv)\n",
    "\n",
    "    for i in range(len(W)):\n",
    "        conv = ResidualUnit(L, W[i], AR[i])(conv)\n",
    "        \n",
    "        if (((i+1) % 4 == 0) or ((i+1) == len(W))):\n",
    "            # Skip connections to the output after every 4 residual units\n",
    "            dense = Conv1D(L, 1)(conv)\n",
    "            skip = add([skip, dense])\n",
    "\n",
    "    skip = Cropping1D(int(CL/2))(skip)\n",
    "\n",
    "    output0 = [[] for t in range(1)]\n",
    "\n",
    "    for t in range(1):\n",
    "        output0[t] = Conv1D(3, 1, activation='softmax')(skip)\n",
    "    \n",
    "    model = Model(inputs=input0, outputs=output0)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_crossentropy_2d(y_true, y_pred):\n",
    "    # Standard categorical cross entropy for sequence outputs\n",
    "    weights = [3.33445928e-01, 1.97431150e+03, 1.97432843e+03]\n",
    "    return - kb.mean(weights[0]*y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + weights[1]*y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10)\n",
    "                   + weights[2]*y_true[:, :, 2]*kb.log(y_pred[:, :, 2]+1e-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parallel(model, gpu_count):\n",
    "\n",
    "    def get_slice(data, idx, parts):\n",
    "\n",
    "        shape = tf.shape(data)\n",
    "        stride = tf.concat([shape[:1]//parts, shape[1:]*0], 0)\n",
    "        start = stride * idx\n",
    "\n",
    "        size = tf.concat([shape[:1]//parts, shape[1:]], 0) \n",
    "        # Split the batch into equal parts \n",
    "\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                # Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape,\n",
    "                                  arguments={'idx': i, 'parts': gpu_count})(x)\n",
    "                    inputs.append(slice_n)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                # Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # Merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(concatenate(outputs, axis=0))\n",
    "            \n",
    "        return Model(inputs=model.inputs, outputs=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# Training and validation\n",
    "###############################################################################\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/dataset_train_.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40234/1388827759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn_donor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mn_null\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mn_acceptor\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_idx = len(h5f.keys())//2\n",
    "idx_all = np.random.permutation(num_idx)\n",
    "idx_train = idx_all[:int(0.9*num_idx)]\n",
    "idx_valid = idx_all[int(0.9*num_idx):]\n",
    "\n",
    "EPOCH_NUM = 10*len(idx_train)\n",
    "\n",
    "n_null = 0\n",
    "n_acceptor = 0\n",
    "n_donor = 0\n",
    "for idx in idx_train:\n",
    "    y = h5f['Y' + str(idx)][:]\n",
    "    n_null += np.sum(y[0,:,:,0]==1)\n",
    "    n_acceptor += np.sum(y[0,:,:,1]==1)\n",
    "    n_donor += np.sum(y[0,:,:,2]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (n_null+n_acceptor+n_donor) / (3 * np.array([n_null,n_acceptor,n_donor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import resource_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 11:48:39.947913: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-29 11:48:40.855332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14639 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2021-11-29 11:48:40.861177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30989 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 11:48:47.530075: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-29 11:48:56.742389: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9763\t0.9121\t0.9862\t0.9939\t0.9514\t0.9891\t0.7128\t0.1227\t0.026\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.98\t0.9197\t0.9896\t0.9959\t0.9578\t0.991\t0.734\t0.1187\t0.0238\t89712\n",
      "--- 5325.377207040787 seconds ---\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/dataset_test_.h5', 'r')\n",
    "\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "#model = load_model('../Results/TF_Models/SpliceAI_{}_c.h5'.format(0))\n",
    "model = []\n",
    "n_models = 5\n",
    "\n",
    "paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "model = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Model testing\n",
    "###############################################################################\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "# The three neurons per output correspond to no splicing, splice acceptor (AG)\n",
    "# and splice donor (GT) respectively.\n",
    "\n",
    "for output_class in [1, 2]:\n",
    "\n",
    "    Y_true = [[] for t in range(1)]\n",
    "    Y_pred = [[] for t in range(1)]\n",
    "\n",
    "    for idx in range(num_idx):\n",
    "\n",
    "        X = h5f['X' + str(idx)][:]\n",
    "        Y = h5f['Y' + str(idx)][:]\n",
    "\n",
    "        Xc, Yc = clip_datapoints(X, Y, CL, 1)\n",
    "\n",
    "        Yps = [np.zeros(Yc[0].shape) for t in range(1)]\n",
    "\n",
    "        for v in range(n_models):\n",
    "            Yp = model[v].predict(Xc, batch_size=BATCH_SIZE)\n",
    "\n",
    "            if not isinstance(Yp, list):\n",
    "                Yp = [Yp]\n",
    "\n",
    "            for t in range(1):\n",
    "                Yps[t] += Yp[t]/n_models\n",
    "        # Ensemble averaging (mean of the ensemble predictions is used)\n",
    "\n",
    "        for t in range(1):\n",
    "\n",
    "            is_expr = (Yc[t].sum(axis=(1,2)) >= 1)\n",
    "\n",
    "            Y_true[t].extend(Yc[t][is_expr, :, output_class].flatten())\n",
    "            Y_pred[t].extend(Yps[t][is_expr, :, output_class].flatten())\n",
    "\n",
    "    print(\"\\n\\033[1m{}:\\033[0m\".format(output_class_labels[output_class]))\n",
    "\n",
    "    Y_true[0] = np.asarray(Y_true[0])\n",
    "    Y_pred[0] = np.asarray(Y_pred[0])\n",
    "    \n",
    "    print_topl_statistics(Y_true[0], Y_pred[0])\n",
    "    \n",
    "    #chunkSize = Y_true[0].shape[0]/10\n",
    "    \n",
    "    #for idx in range(10):\n",
    "    #    print_topl_statistics(Y_true[0][int(chunkSize*idx):int(chunkSize*(idx+1))], Y_pred[0][int(chunkSize*idx):int(chunkSize*(idx+1))])\n",
    "\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "print(\"--- {} seconds ---\".format(time.time() - start_time))\n",
    "print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data provided with paper: \n",
    "\n",
    "Acceptor PR-AUC = 0.9587\n",
    "\n",
    "Donor PR-AUC = 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUT_MAP = np.asarray([[1, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 1],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "class spliceDataset(Dataset):\n",
    "    def __init__(self, annotation, transform=None, target_transform=None):\n",
    "        #self.data = data\n",
    "        #self.labelDict = labelDict\n",
    "        self.annotation = annotation\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotation.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transcript,chrom,strand,tx_start,tx_end = self.annotation['transcript'].values[idx],self.annotation['chrom'].values[idx],self.annotation['strand'].values[idx],self.annotation['tx_start'].values[idx],self.annotation['tx_end'].values[idx]\n",
    "        #gene,chrom,strand = self.annotation['gene'].values[idx],self.annotation['chrom'].values[idx],self.annotation['strand'].values[idx]\n",
    "        \n",
    "        length = tx_end-tx_start\n",
    "        num_points = ceil_div(length, SL)\n",
    "        \n",
    "        Xd = np.zeros((num_points, SL+CL_max,4))\n",
    "        Yd = np.zeros((num_points, SL,3))\n",
    "        if strand=='+':\n",
    "            X0 = seqData[chrom][int(tx_start)-1-CL_max//2:int(tx_end)+SL+CL_max//2].toarray()\n",
    "            X0[:CL_max//2,:] = np.array([0,0,0,0,0])\n",
    "            X0[-(CL_max//2+SL):,:] = np.array([0,0,0,0,0])\n",
    "        else:\n",
    "            X0 = seqData[chrom][int(tx_start)-1-SL-CL_max//2:int(tx_end)+CL_max//2].toarray()\n",
    "            X0[:(CL_max//2+SL),:] = np.array([0,0,0,0,0])\n",
    "            X0[-CL_max//2:,:] = np.array([0,0,0,0,0])\n",
    "            X0 = X0[::-1,:]\n",
    "            X0[:,[0,1,2,3]] = X0[:,[0,1,2,3]][:,::-1]\n",
    "            \n",
    "        label = transcriptToLabel[transcript]\n",
    "        Y0 = np.zeros((length+SL,3))\n",
    "        Y0[:length,0] = np.ones(length)\n",
    "        Y0[label[1],:] = OUT_MAP[np.array(label[0]).astype('int8')]\n",
    "\n",
    "        for i in range(num_points):\n",
    "            tmp = X0[SL*i:CL_max+SL*(i+1),:]\n",
    "            if tmp.shape[0]==0:\n",
    "                continue\n",
    "            Xd[i,:,:4] = tmp[:,:4]\n",
    "            Yd[i,:,:] = Y0[SL*i:SL*(i+1),:]\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        #X = torch.Tensor(X.copy())\n",
    "        #print(X.shape)\n",
    "        #X = torch.nn.functional.pad(X.clone(), (0,0,CL_max//2,CL_max//2+X.shape[0]-SL*(X.shape[0]//SL)), \"constant\", 0)\n",
    "        #X = torch.transpose(X.unfold(0,SL,CL_max//2),1,2)\n",
    "        #print(X.shape)\n",
    "        #Y = torch.transpose(torch.Tensor(Y).unfold(0,SL,CL_max//2),1,2)\n",
    "        return Xd,Yd\n",
    "        #if self.include_prob:\n",
    "        #    return X, [Y[t] for t in range(1)],[Y_prob[t] for t in range(1)]\n",
    "        #else:\n",
    "        #    return X, [Y[t] for t in range(1)]\n",
    "\n",
    "def ceil_div(x, y):\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (example, label)\n",
    "             where 'example' is a tensor of arbitrary shape\n",
    "             and label/length are scalars\n",
    "    \"\"\"\n",
    "    #unfold1 = nn.Unfold((SL*3,1),SL,CL_max//2)\n",
    "    #unfold2 = nn.Unfold((SL,1),SL,0)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        features.append(torch.Tensor(data[i][0]))\n",
    "        labels.append(torch.Tensor(data[i][1]))\n",
    "        #features.append(tmp.unfold(0,SL*3,CL_max//2))\n",
    "        #labels.append(torch.Tensor(data[i][1]).unfold(0,SL,CL_max//2))\n",
    "    return torch.cat(features,dim=0).float(), torch.cat(labels,dim=0).float()\n",
    "\n",
    "#train_dataset = spliceDataset(annotation_train)\n",
    "#val_dataset = spliceDataset(annotation_validation)\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=16,collate_fn=collate_fn, pin_memory=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False,collate_fn=collate_fn, num_workers=16)\n",
    "\n",
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-050422'\n",
    "setType = 'test'\n",
    "#with open('{}/sparse_sequence_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    seqData = pickle.load(handle)\n",
    "    \n",
    "with open('{}/sparse_discrete_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "    transcriptToLabel = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "CHROM_TEST = ['chr1', 'chr3', 'chr5', 'chr7', 'chr9']\n",
    "\n",
    "annotation = pd.read_csv(data_dir+'/annotation_ensembl_v87_{}.txt'.format(setType),sep='\\t',header=None)[[0,1,2,3,4]]\n",
    "annotation.columns = ['name','chrom','strand','tx_start','tx_end']\n",
    "annotation['transcript'] = annotation['name'].apply(lambda x: x.split('---')[-2].split('.')[0]).values\n",
    "annotation['gene'] = annotation['name'].apply(lambda x: x.split('---')[-3].split('.')[0]).values\n",
    "#annotation['support'] = annotation['transcript'].apply(lambda x:transcriptToSupport[x])\n",
    "\n",
    "chrom_paths = glob(data_dir+'/sparse_sequence_data/*')\n",
    "chromToPath = {}\n",
    "for path in chrom_paths:\n",
    "    chromToPath[path.split('/')[-1].split('_')[0]] = path\n",
    "    \n",
    "seqData = {}\n",
    "for chrom in CHROM_TEST:\n",
    "    seqData[chrom] = load_npz(data_dir+'/sparse_sequence_data/{}_{}.npz'.format(chrom,setType)).tocsr()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.decode.is/simple\n",
      "Collecting spliceai\n",
      "  Downloading https://pypi.decode.is/packages/d6/2b/9dbf72fdd948cd606c21826cc3735a5beea52633dab72d95d9936a9454d4/spliceai-1.3.1-py2.py3-none-any.whl (16.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.7 MB 97.5 MB/s eta 0:00:01s eta 0:00:01��██████████████▋             | 9.7 MB 97.5 MB/s eta 0:00:01��████████████████▊       | 12.9 MB 97.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras>=2.0.5 in /odinn/tmp/benediktj/Singularity/.local/lib/python3.8/site-packages (from spliceai) (2.0.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from spliceai) (0.25.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from spliceai) (1.17.3)\n",
      "Collecting pysam>=0.10.0\n",
      "  Downloading https://pypi.decode.is/packages/41/0f/4ffdea619a8898c936f6f1b909759486167976d761fc265f931119f0da1e/pysam-0.18.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.2 MB 2.7 MB/s eta 0:00:01��█████████████████████████▊  | 15.0 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyfaidx>=0.5.0 in /odinn/tmp/benediktj/Singularity/.local/lib/python3.8/site-packages (from spliceai) (0.6.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from keras>=2.0.5->spliceai) (1.13.0)\n",
      "Requirement already satisfied: theano in /odinn/tmp/benediktj/Singularity/.local/lib/python3.8/site-packages (from keras>=2.0.5->spliceai) (1.0.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras>=2.0.5->spliceai) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->spliceai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->spliceai) (2021.1)\n",
      "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.8/dist-packages (from pyfaidx>=0.5.0->spliceai) (57.4.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from theano->keras>=2.0.5->spliceai) (1.4.1)\n",
      "Installing collected packages: pysam, spliceai\n",
      "\u001b[33m  WARNING: The script spliceai is installed in '/odinn/tmp/benediktj/Singularity/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed pysam-0.18.0 spliceai-1.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install spliceai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                           | 0/90 [00:00<?, ?it/s]2022-04-20 16:02:08.137901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-20 16:02:09.888944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [22:31<00:00, 15.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9763\t0.9121\t0.9862\t0.9939\t0.9514\t0.9890999794006348\t0.7127000093460083\t0.12269999831914902\t0.026000000536441803\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.98\t0.9197\t0.9896\t0.9959\t0.9578\t0.9909999966621399\t0.734000027179718\t0.11869999766349792\t0.023800000548362732\t89712\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "n_models = 5\n",
    "\n",
    "paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "model = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(annotation)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0,collate_fn=collate_fn, pin_memory=False)\n",
    "\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    Xc = batch_chunks.to(device).numpy()\n",
    "    targets = torch.squeeze(target_chunks.to(device),0).numpy()\n",
    "    outputs = []\n",
    "    for v in range(n_models):\n",
    "            Yp = model[v].predict(Xc, batch_size=BATCH_SIZE)\n",
    "            outputs.append(Yp)\n",
    "    outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9514+0.9578)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8', setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 17:22:05.759506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-12-15 17:22:07.604101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2022-12-15 17:22:07.604147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-15 17:22:07.610867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-12-15 17:22:07.613225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-12-15 17:22:07.613543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-12-15 17:22:07.614054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-12-15 17:22:07.615007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-12-15 17:22:07.615161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-12-15 17:22:07.616804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-12-15 17:22:07.625398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2022-12-15 17:22:07.625673: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xba4d640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-15 17:22:07.625688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-12-15 17:22:07.708775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb4737e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-15 17:22:07.708799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-12-15 17:22:07.709690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2022-12-15 17:22:07.709726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-15 17:22:07.709751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-12-15 17:22:07.709760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-12-15 17:22:07.709768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-12-15 17:22:07.709776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-12-15 17:22:07.709784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-12-15 17:22:07.709792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-12-15 17:22:07.711239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-12-15 17:22:07.711267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-15 17:22:08.036175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-12-15 17:22:08.036220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2022-12-15 17:22:08.036228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2022-12-15 17:22:08.038422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31005 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/743 [00:00<?, ?it/s]2022-12-15 17:22:31.480981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-12-15 17:23:07.017227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 743/743 [22:03<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "n_models = 5\n",
    "\n",
    "paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "model = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    Xc = torch.transpose(batch_features.type(torch.FloatTensor).to(device),1,2).numpy()\n",
    "    targets = torch.transpose(targets.to(device)[:,:,CL_max//2:-CL_max//2],1,2).numpy()\n",
    "    outputs = []\n",
    "    for v in range(n_models):\n",
    "            Yp = model[v].predict(Xc, batch_size=BATCH_SIZE)\n",
    "            outputs.append(Yp)\n",
    "    outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "\n",
    "    #targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    #outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation_metrics import print_topl_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0006880524325870373\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9954\t0.7482\t0.8785\t0.9518\t0.8378\t0.8901\t0.1673\t0.0352\t0.0070\t67035\t89600.0\t89600\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9949\t0.7459\t0.8748\t0.9471\t0.834\t0.8917\t0.1578\t0.0311\t0.0058\t68077\t91272.0\t91272\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135112"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67035+68077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180872"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89600+91272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 16:57:09.506806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-09 16:57:11.529890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2023-11-09 16:57:11.529940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-09 16:57:13.321761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-09 16:57:13.861930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-09 16:57:14.443840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-09 16:57:14.523518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-11-09 16:57:14.829327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-09 16:57:14.830565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-09 16:57:14.832301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2023-11-09 16:57:14.844354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2023-11-09 16:57:14.845785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe772bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-09 16:57:14.845805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-09 16:57:14.944044: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe086100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-09 16:57:14.944137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-11-09 16:57:14.945791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2023-11-09 16:57:14.945894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-09 16:57:14.945978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-09 16:57:14.946015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-09 16:57:14.946049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-09 16:57:14.946095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-11-09 16:57:14.946130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-09 16:57:14.946164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-09 16:57:14.947949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2023-11-09 16:57:14.947994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-09 16:57:43.059143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-09 16:57:43.059192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2023-11-09 16:57:43.059204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2023-11-09 16:57:43.061186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31013 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/771 [00:00<?, ?it/s]2023-11-09 16:58:12.721384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-09 16:58:57.308700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 771/771 [24:05<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader import get_GTEX_v8_Data\n",
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/'\n",
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')\n",
    "\n",
    "model = []\n",
    "n_models = 5\n",
    "\n",
    "paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "model = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    Xc = torch.transpose(batch_features.type(torch.FloatTensor).to(device),1,2).numpy()\n",
    "    targets = torch.transpose(targets.to(device)[:,:,CL_max//2:-CL_max//2],1,2).numpy()\n",
    "    outputs = []\n",
    "    for v in range(n_models):\n",
    "            Yp = model[v].predict(Xc, batch_size=BATCH_SIZE)\n",
    "            outputs.append(Yp)\n",
    "    outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "\n",
    "    #targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    #outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.000810858211367834\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9932\t0.7309\t0.8653\t0.9429\t0.8196\t0.8205\t0.1450\t0.0307\t0.0061\t72266\t98870.0\t98870\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9932\t0.7332\t0.8657\t0.9397\t0.82\t0.8302\t0.1380\t0.0272\t0.0050\t73400\t100114.0\t100114\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation_metrics import print_topl_statistics\n",
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73205"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7309+0.7332)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8196+0.82)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72266+73400"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
