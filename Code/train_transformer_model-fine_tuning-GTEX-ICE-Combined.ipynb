{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  7 18:00:14 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-DGXS-32GB            Off| 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   38C    P0               39W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS-32GB            Off| 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   39C    P0               41W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS-32GB            Off| 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0               38W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS-32GB            Off| 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   37C    P0               38W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_to_label_2 = defaultdict(list)\n",
    "#for key in tqdm(gene_to_label.keys()):\n",
    "#    jn_start, jn_end = gene_to_label[key]\n",
    "#    jn_starts = defaultdict(int)\n",
    "#    jn_ends = defaultdict(int)\n",
    "#    for jn in jn_start:\n",
    "#        jn_starts[jn] = 1\n",
    "#    for jn in jn_end:\n",
    "#        jn_ends[jn] = 1\n",
    "#    gene_to_label_2[key] = [jn_starts,jn_ends]\n",
    "    \n",
    "#gene_to_label = gene_to_label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation_train,gene_to_label,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//4, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:19<00:00,  2.27s/it, a_r=0.614, d_r=0.611, loss=0.000926, r_a=0.989, r_d=0.988, r_loss=6.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 633/633 [11:21<00:00,  1.08s/it, a_r=0.583, d_r=0.568, loss=0.00125, r_a=0.989, r_d=0.988, r_loss=7.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9956\t0.7237\t0.853\t0.9343\t0.8115\t0.9680\t0.2203\t0.0624\t0.0161\t16065\t22199.0\t22199\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9961\t0.7253\t0.859\t0.936\t0.8145\t0.9605\t0.2059\t0.0583\t0.0146\t16352\t22545.0\t22545\n",
      "epoch: 1/4, val loss = 0.000963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:02<00:00,  2.26s/it, a_r=0.62, d_r=0.623, loss=0.000893, r_a=0.991, r_d=0.99, r_loss=6.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 633/633 [11:24<00:00,  1.08s/it, a_r=0.581, d_r=0.597, loss=0.00122, r_a=0.991, r_d=0.99, r_loss=7.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9957\t0.726\t0.8602\t0.9402\t0.8171\t0.9678\t0.2277\t0.0673\t0.0164\t16117\t22199.0\t22199\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9957\t0.7298\t0.8652\t0.9407\t0.8196\t0.9640\t0.2342\t0.0675\t0.0166\t16453\t22545.0\t22545\n",
      "epoch: 2/4, val loss = 0.000939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [54:59<00:00,  2.26s/it, a_r=0.627, d_r=0.629, loss=0.000877, r_a=0.99, r_d=0.99, r_loss=6.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 633/633 [11:24<00:00,  1.08s/it, a_r=0.567, d_r=0.577, loss=0.00126, r_a=0.99, r_d=0.99, r_loss=7.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9958\t0.7267\t0.8601\t0.9367\t0.8162\t0.9517\t0.1790\t0.0459\t0.0106\t16132\t22199.0\t22199\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9949\t0.7276\t0.8634\t0.9401\t0.8173\t0.9572\t0.1971\t0.0544\t0.0146\t16403\t22545.0\t22545\n",
      "epoch: 3/4, val loss = 0.000959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:09<00:00,  2.26s/it, a_r=0.625, d_r=0.63, loss=0.000864, r_a=0.991, r_d=0.99, r_loss=6.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 633/633 [11:27<00:00,  1.09s/it, a_r=0.571, d_r=0.61, loss=0.00121, r_a=0.991, r_d=0.99, r_loss=7.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9956\t0.7314\t0.8669\t0.9425\t0.8213\t0.9515\t0.2019\t0.0571\t0.0135\t16237\t22199.0\t22199\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9952\t0.7334\t0.8692\t0.9439\t0.8233\t0.9660\t0.2548\t0.0730\t0.0176\t16534\t22545.0\t22545\n",
      "epoch: 4/4, val loss = 0.000927\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEICAYAAACJalkVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/G0lEQVR4nO3dd3yV9fn4/9eVQcJIgISwEkbYOwlEwIGCWEVUUhUVbFUq1p/WWa2zrVpbv5/WWgdSbV11VEEchagoKrjZI4yEYdghzARCWJnX74/7ziBmHTgnJ+N6Ph55cM77Hue6CeTK/X5f9/stqooxxhjjSwH+DsAYY0zjZ8nGGGOMz1myMcYY43OWbIwxxvicJRtjjDE+Z8nGGGOMz/k02YjIOBHZKCLpIvJgJdtDRORdd/sSEelebttDbvtGEbmoXPtrIrJPRNZVOFeEiHwhIj+6f7Z1238hImtEZK2ILBSROB9esjHGmEqIr56zEZFAYBPwMyADWAZMVtW0cvv8BhiiqreIyCTgclW9RkQGADOA4UBn4Eugj6oWici5wBHgTVUdVO5cTwLZqvpXN7G1VdUHROQsYL2qHhSRi4HHVHVEdbG3a9dOu3fv7rW/C2OMaQpWrFhxQFWjKtsW5MPPHQ6kq+oWABGZCSQBaeX2SQIec1+/D0wXEXHbZ6pqHrBVRNLd8y1S1W/L3wFVONdo9/UbwNfAA6q6sNw+i4GYmgLv3r07y5cvr8UlGmOMKSEi26va5stutGhgZ7n3GW5bpfuoaiGQA0TW8tiKOqjqbvf1HqBDJftMBT6t7GARuVlElovI8v3799fwUcYYYzzRKAsE1OkbPKl/UETG4CSbB6o45iVVTVTVxKioSu8CjTHGnCJfJptdQJdy72Pctkr3EZEgoDWQVctjK9orIp3cc3UC9pVsEJEhwCtAkqpmeXwlxhhjTosvx2yWAb1FJBYnUUwCrq2wTzJwA7AImAgsUFUVkWTgHRF5GqdAoDewtIbPKznXX90/5wCISFfgQ+A6Vd3kjQszxjQcBQUFZGRkcOLECX+H0miEhoYSExNDcHBwrY/xWbJR1UIRuR2YBwQCr6lqqog8DixX1WTgVeAttwAgGych4e43C6eYoBC4TVWLAERkBk4hQDsRyQAeVdVXcZLMLBGZCmwHrnZDeQRnHOgFp/aAQlVN9NV1G2Pql4yMDMLCwujevTvuzwBzGlSVrKwsMjIyiI2NrfVxPit9bsgSExPVqtGMaRzWr19Pv379LNF4kaqyYcMG+vfvf1K7iKyo6pf5RlkgYIwx5Vmi8a5T+fu0ZONFew+f4E8fpVJQVOzvUIwxpl6xZONFq3Yc4j8/bOOpeRv9HYoxpp7IysoiPj6e+Ph4OnbsSHR0dOn7/Pz8ao9dvnw5d955Zx1F6lu+rEZrcsYN6sgvR3bl399uYWTPSMb0be/vkIwxfhYZGUlKSgoAjz32GK1ateJ3v/td6fbCwkKCgir/UZyYmEhiYuOoZ7I7Gy/7wyUD6NcxjHtnrWbvYSu1NMb81JQpU7jlllsYMWIE999/P0uXLuXMM88kISGBs846i40bnd6Rr7/+mksvvRRwEtWNN97I6NGj6dGjB9OmTfPnJXjM7my8LDQ4kOnXDuWy57/nrpmrePumkQQG2OCkMfXBnz5KJS3zsFfPOaBzOI9eNtDj4zIyMli4cCGBgYEcPnyY7777jqCgIL788ksefvhhPvjgg58cs2HDBr766ityc3Pp27cvt956q0fPuviTJRsf6NW+FX/5+SDufW81zy/4kbsv6OPvkIwx9cxVV11FYGAgADk5Odxwww38+OOPiAgFBQWVHnPJJZcQEhJCSEgI7du3Z+/evcTE1Di3cL1gycZHrhwWww+bDzBt/o+MiI3kzJ6R/g7JmCbvVO5AfKVly5alr//4xz8yZswY/ve//7Ft2zZGjx5d6TEhISGlrwMDAyksLPR1mF5jYzY+9OekQXRv15K7Zq4i60iev8MxxtRTOTk5REc7E9u//vrr/g3GRyzZ+FDLkCCmTx7KoeMF3PveaoqLbbYGY8xP3X///Tz00EMkJCQ0qLsVT9h0NZXw9nQ1by3ezh9nr+Ph8f24+dyeXjuvMaZm69ev/8m0Kub0Vfb3atPV+NkvR3Tl4kEdefKzjazacdDf4RhjTJ2zZFMHRIS/XjmEjq1DuWPGKnKOV15pYowxjZUlmzrSunkwz09OYE/OCR78YA3WfWmMaUos2dShhK5tuX9cXz5dt4f/Ltnh73CMMabOWLKpYzed04PRfaP488dppGbm+DscY4ypE5Zs6lhAgPCPq+Jo2yKYO95ZxdG8xlnmaIwx5Vmy8YPIViE8NymBbVlH+eOcdf4OxxjjQ2PGjGHevHkntT377LPceuutle4/evRoSh69GD9+PIcOHfrJPo899hhPPfVUtZ87e/Zs0tLSSt8/8sgjfPnllx5G7z0+TTYiMk5ENopIuog8WMn2EBF5192+RES6l9v2kNu+UUQuKtf+mojsE5F1Fc4VISJfiMiP7p9t3XYRkWnuudaIyFAfXnKtjewRyZ1je/Phyl28vyLD3+EYY3xk8uTJzJw586S2mTNnMnny5BqPnTt3Lm3atDmlz62YbB5//HEuuOCCUzqXN/gs2YhIIPBP4GJgADBZRAZU2G0qcFBVewHPAH9zjx0ATAIGAuOAF9zzAbzutlX0IDBfVXsD8933uJ/f2/26GXjRG9fnDXec35uRPSL44+x1pO874u9wjDE+MHHiRD755JPShdK2bdtGZmYmM2bMIDExkYEDB/Loo49Wemz37t05cOAAAE888QR9+vThnHPOKV2CAODll1/mjDPOIC4ujiuvvJJjx46xcOFCkpOTue+++4iPj2fz5s1MmTKF999/H4D58+eTkJDA4MGDufHGG8nLyyv9vEcffZShQ4cyePBgNmzY4LW/B19OxDkcSFfVLQAiMhNIAtLK7ZMEPOa+fh+YLs7i1knATFXNA7aKSLp7vkWq+m35O6AK5xrtvn4D+Bp4wG1/U51a48Ui0kZEOqnqbm9d6KkKDBCem5TAxc99x+3vrGT2bWcTGhxY84HGmFPz6YOwZ613z9lxMFz81yo3R0REMHz4cD799FOSkpKYOXMmV199NQ8//DAREREUFRUxduxY1qxZw5AhQyo9x4oVK5g5cyYpKSkUFhYydOhQhg0bBsAVV1zBr3/9awD+8Ic/8Oqrr3LHHXcwYcIELr30UiZOnHjSuU6cOMGUKVOYP38+ffr04frrr+fFF1/k7rvvBqBdu3asXLmSF154gaeeeopXXnnFC39Jvu1GiwZ2lnuf4bZVuo+qFgI5QGQtj62oQ7kEsgfo4EEciMjNIrJcRJbv37+/ho/yng7hoTx9dRwb9uTyl0/Saj7AGNPglO9KK+lCmzVrFkOHDiUhIYHU1NSTurwq+u6777j88stp0aIF4eHhTJgwoXTbunXrGDVqFIMHD+btt98mNTW12lg2btxIbGwsffo4S5/ccMMNfPvtt6Xbr7jiCgCGDRvGtm3bTvWSf6JRLjGgqioiHj01qaovAS+BMzeaTwKrwui+7fn/zu3Bv7/dwpk92nHJkE51+fHGNB3V3IH4UlJSEr/97W9ZuXIlx44dIyIigqeeeoply5bRtm1bpkyZwokTp7ay75QpU5g9ezZxcXG8/vrrfP3116cVa8kyBt5ewsCXdza7gC7l3se4bZXuIyJBQGsgq5bHVrRXRDq55+oE7PMgDr/73UV9Sejahgc/WMPO7GP+DscY40WtWrVizJgx3HjjjUyePJnDhw/TsmVLWrduzd69e/n000+rPf7cc89l9uzZHD9+nNzcXD766KPSbbm5uXTq1ImCggLefvvt0vawsDByc3N/cq6+ffuybds20tPTAXjrrbc477zzvHSlVfNlslkG9BaRWBFphjPgn1xhn2TgBvf1RGCBO7aSDExyq9VicQb3l9bweeXPdQMwp1z79W5V2kggpz6M11QUHBjAtEkJiMDtM1aRX1js75CMMV40efJkVq9ezeTJk4mLiyMhIYF+/fpx7bXXcvbZZ1d77NChQ7nmmmuIi4vj4osv5owzzijd9uc//5kRI0Zw9tln069fv9L2SZMm8fe//52EhAQ2b95c2h4aGsp//vMfrrrqKgYPHkxAQAC33HKL9y+4Ap8uMSAi44FngUDgNVV9QkQeB5ararKIhAJvAQlANjCpXEHB74EbgULgblX91G2fgVMI0A7YCzyqqq+KSCQwC+gKbAeuVtVst+BgOk4F2zHgV6pa7foB3l5iwBOfrdvNLf9dya9HxfL7SyoW7xljPGVLDPiGp0sM+HTMRlXnAnMrtD1S7vUJ4Koqjn0CeKKS9kqL01U1CxhbSbsCt3kUuB+NG9SJ60Z24+XvtnJmz0jO79eh5oOMMaaesxkE6qHfX9Kf/p3CuXfWanbnHPd3OMYYc9os2dRDocGB/PPaBPIKi7lrZgqFRTZ+Y8zpsCU9vOtU/j4t2dRTPaJa8ZefD2Lp1mymLUj3dzjGNFihoaFkZWVZwvESVSUrK4vQ0FCPjmuUz9k0FlcMjWHh5iyeX/AjI3tEcFbPdv4OyZgGJyYmhoyMDOryYe3GLjQ0lJiYGI+OsWRTzz2eNJBVOw5y98wU5t41inatQvwdkjENSnBwMLGxsf4Oo8mzbrR6rkWzIKZfO5RDxwu4Z9ZqioutK8AY0/BYsmkA+ncK55FLB/Dtpv289N0Wf4djjDEes2TTQPxiRFcuGdyJp+ZtZMX2g/4OxxhjPGLJpoEQEf7vysF0ahPKnTNWkXOswN8hGWNMrVmyaUDCQ4N5fvJQ9h4+wf0frLZSTmNMg2HJpoGJ79KGBy/ux7zUvby1eLu/wzHGmFqxZNMATT0nlvP7tecvH69n3a4cf4djjDE1smTTAIkIT10VR0TLZtwxYxVH8ry3wJExxviCJZsGKqJlM56bFM/2rKP8cfY6G78xxtRrlmwasBE9Irn7gj78b9Uu3l+R4e9wjDGmSpZsGrjbxvTirJ6RPDInlfR9P10C1hhj6gNLNg1cYIDw7DXxtGgWyG1vr+JEQZG/QzLGmJ+wZNMItA8P5elr4tm4N5fHP07zdzjGGPMTPk02IjJORDaKSLqIPFjJ9hARedfdvkREupfb9pDbvlFELqrpnCJyvoisFJF1IvKGiAS57a1F5CMRWS0iqSLyK19es7+c1yeKW87ryTtLdvDxmkx/h2OMMSfxWbIRkUDgn8DFwABgsogMqLDbVOCgqvYCngH+5h47AJgEDATGAS+ISGBV5xSRAOANYJKqDgK2Aze4n3EbkKaqccBo4B8i0sxHl+1X917Yh6Fd2/DQB2vZkXXM3+EYY0wpX97ZDAfSVXWLquYDM4GkCvsk4SQJgPeBsSIibvtMVc1T1a1Aunu+qs4ZCeSr6ib3XF8AV7qvFQhzz9sKyAYa5YMpwYEBTJucgAjcPmMl+YW2nLQxpn7wZbKJBnaWe5/htlW6j6oWAjk4iaOqY6tqPwAEiUii2z4R6OK+ng70BzKBtcBdqvqTn8IicrOILBeR5Q15Rb+Yti14cmIcazJyePKzDf4OxxhjgEZSIKDOE42TgGdEZCmQC5SUZV0EpACdgXhguoiEV3KOl1Q1UVUTo6Ki6iRuXxk3qCM3nNmNV77fyvz1e/0djjHG+DTZ7KLs7gIgxm2rdB93QL81kFXNsVWeU1UXqeooVR0OfAuUdKn9CvhQHenAVqDfaV9dPffQ+P4M6BTOve+tZnfOcX+HY4xp4nyZbJYBvUUk1h2QnwQkV9gnmbKB/InAAvcuJRmY5FarxQK9gaXVnVNE2rt/hgAPAP9yz7sDGOtu6wD0BRr9cpehwYFMvzaBgsJi7pqRQmGRjd8YY/zHZ8nGHYO5HZgHrAdmqWqqiDwuIhPc3V4FIkUkHbgHeNA9NhWYBaQBnwG3qWpRVed0z3WfiKwH1gAfqeoCt/3PwFkishaYDzygqgd8dd31SY+oVjxx+WCWbsvmufk/+jscY0wTJjaB408lJibq8uXL/R2G19z33mreX5nBf6eO4Oxe7fwdjjGmkRKRFaqaWNm2RlEgYKr3p6SB9Ixqxd3vprA/N8/f4RhjmiBLNk1Ai2ZBTL82gcPHC7hnVgrFxXY3a4ypW5Zsmoh+HcN59LKBfPfjAf717WZ/h2OMaWIs2TQhk4d34ZIhnfjH55tYsT3b3+EYY5oQSzZNiIjwf1cMJrpNc+6ckcKhY/n+DskY00RYsmliwkODmX5tAvtyT3D/+2tsOWljTJ2wZNMEDYlpwwPj+vF52l7eWLjN3+EYY5oASzZN1NRzYhnbrz3/b+4G1u3K8Xc4xphGzpJNEyUiPHVVHJGtmnH7Oys5ktcoV10wxtQTlmyasLYtm/HcpAR2ZB/j9/9ba+M3xhifsWTTxA2PjeC3F/RhTkom7y3P8Hc4xphGypKN4TdjenF2r0geSV7Hpr25/g7HGNMIWbIxBAYIz1wTT6uQIG5/ZyXH84tqPsgYYzxgycYA0D4slKevjmfT3iM8/nFqzQcYY4wHLNmYUuf2ieLW0T2ZsXQnyasz/R2OMaYRsWTjTY2gmuuen/VhWLe2PPzhWrYdOOrvcIwxjYQlG2/auQReOBO++j/Ym9Ygk09wYADTJicQGCDcMWMVeYU2fmOMOX2WbLxJi6F5W/jmb/DimTD9DJj/Z9i9ukElnug2zXly4hDW7srhb59u9Hc4xphGwKfJRkTGichGEUkXkQcr2R4iIu+625eISPdy2x5y2zeKyEU1nVNEzheRlSKyTkTeEJGgcttGi0iKiKSKyDc+u+BuZ8Gv5sK9G+GSpyG8M3z/DPz7XJgWD188ArtWNIjEc9HAjkw5qzuv/bCVL9L2+jscY0wDJ756alxEAoFNwM+ADGAZMFlV08rt8xtgiKreIiKTgMtV9RoRGQDMAIYDnYEvgT7uYT85J7AB2A6MVdVNIvI4sF1VXxWRNsBCYJyq7hCR9qq6r7rYExMTdfny5d75iziaBRs/gbQ5sOVrKC6E1l2g/wQYkAQxZ0BA/bzBzCss4soXF5Jx8Dhz7xxF5zbN/R2SMaYeE5EVqppY2TZf/pQbDqSr6hZVzQdmAkkV9kkC3nBfvw+MFRFx22eqap6qbgXS3fNVdc5IIF9VN7nn+gK40n19LfChqu4AqCnReF3LSBh6PfzyA7gvHX7+InQYBMtehtcuhGcGwNz7YNv3UFy/xkdCggJ5fvJQCgqLuXPGKgqLiv0dkjGmgfJlsokGdpZ7n+G2VbqPqhYCOTiJo6pjq2o/AASJSElGnQh0cV/3AdqKyNciskJErq8sWBG5WUSWi8jy/fv3e3Shtda8LcRfC9fOhPs2wxWvQPQwWPkmvH4J/KMvfHQ3bP4KiurHxJix7Vry/64YzPLtB3nmy001H2CMMZUIqnmX+k9V1e2Ge0ZEQoDPgZLbhCBgGDAWaA4sEpHF5e6CSs7xEvASON1oPg86NByGXOV85R2B9C+crrY1s2DFf6B5BPS7xOlqiz0Pgpr5PKSqJMVHszA9ixe+3syZPdpxTu92fovFNGCqsDcVtnzldCnnZMCgiTDsBmjV3t/RGR/zZbLZRdndBUCM21bZPhnugH5rIKuGYyttV9VFwCgAEbmQsjGeDCBLVY8CR0XkWyAOZ+ynfghpBQMvd74KjkP6fCfxpM6GVW9BSGvoN95JPD3GQHBonYf42ISBrNxxkLvfTeHTu0YRFRZS5zGYBuhwppNYNrsJ5qjbi92uD7SMgq/+4lRvDkiC4b+GLiNAxJ8RGx/xZYFAEM4P9LE4CWEZcK2qppbb5zZgcLkCgStU9WoRGQi8Q1mBwHygNyBVnbNk4N+9s5kLPKGqC0SkPzAduAhoBiwFJqnquqpi92qBwOkozHP+k65Phg0fw4kcaBYGfS5y/nP2ugCataizcDbuyWXC9O85o3sEb944nIAA+6FgKsjLhW0/OHcvm7+CA27pfIt20GM09Bzj/Nk6xmk/8CMsewVS3oG8w9BhMAy/CQZfBc1a+usqzCmqrkDAZ8nG/eDxwLNAIPCaqj7hVootV9VkEQkF3gISgGycJLDFPfb3wI1AIXC3qn5a1Tnd9r8Dl+KMQ72oqs+Wi+M+4FdAMfBK+W2VqTfJprzCfNj2LaS5iedYFgS3gN4/cxJP74ucOyQfm7l0Bw9+uJb7LurLbWN6+fzzTD1XVAiZK8vuXjKWOhWXQaHOowA9xjgJpv3A6qsu847A2lmw9BXYl+rczSf8Es6YCpE96+xyzOnxW7JpqOplsimvqBC2/+B0ta3/yOmaCAp17nT6T4C+4yC0tU8+WlW5c2YKc9fu5t2bR5LYPcInn2PqKVXI3gKbFzgJZut3kJcDCHSKK7tz6TLy1Lp7VWHHIlj6snNHX1wIPcc6XWy9L4SAQC9fkPEmSzYeqvfJprziImeanLQ5zl1PbiYENnN+oxyQBH0vhhbeTQi5Jwq49PnvKSgs5pM7R9G2pf+KF0wdOJoFW79xu8a+hpwdTnvrrtBztPNvLfY8p8zfm3L3wIo3nIKZ3N3Qpisk3ggJ13v/s4xXWLLxUINKNuUVFzszFKTNdhJPzg4ICILYc53E0+9SaOmdSrI1GYe48sWFnNenPS9fPwyxQd3Go+AE7FzsDup/BbvXAOp0bcWOcu9exkBEj7oZzC8qgA2fOHc727+HwBAYdAWc8WuIGeb7zze1ZsnGQw022ZSnCpmrnK6ItDlO14cEQLezncTT/zII63haH/Ha91t5/OM0Hrl0ADeeE+ulwE2dKy6GvevKSpK3L4TCE84vKjHDy5JL5wQI9PPTEnvTnIKCNe9C/hEnpuE3w8Ar/FKlaU5mycZDjSLZlKfq/DBJS3bueg5sAgS6jixLPCXVQR6dVvn1myv4ZtM+Prz1bAbH+GacyPhAzq6yirEtX8OxA057VL+yQf1uZ9dJ0ckpOXEYVs90ZuI4sMl5Lm3odU43W9vu/o6uybJk46FGl2wq2rfBLS5IdpIQOHO09Z8AAyZ49J/14NF8xk/7jmZBAXx8xzmEhQb7JmZzek4cdqZEKkkwWT867S3blw3q9xjtTB7bkKjC1m+dpLNhrjPzep+LnC62nufX23kHGytLNh5q9MmmvAPpsH6Ok3x2r3baOsU7dzwDkmpVdrpsWzaTXlrM+MGdmDYp3sZv6oOiAti1siy5ZCwDLYKg5tD97HIlyQMaz0OUObucYoIVr8PR/c6YUuJUSPiFM1WU8TlLNh5qUsmmvIPb3K62ObDLvf4Og8oST1TfKg/951fp/H3eRv56xWAmDe9aN/GaMqqQlV42qL/1O8jPBcQZ1ygZd+kyHIIa+ewPhfnOXfvSl5xKzaDmMHiiUz7dKc7f0TVqlmw81GSTTXk5Gc4zPGlzYMdiQJ3+/JKlEToMPOk34uJi5frXlrJ8ezZzbjuHvh3D/Bd7U3H0gDPeUlKSfDjDaW/TrSy5xJ7r9dL3BmX3GqeLbc17UHjcKXgYfrPTXdzYk64fWLLxkCWbCg7vdmYtSJvjPEyqxRDR0/kPOyDJ6XYTYV/uCcY/9x1tWzQj+fZzaN7MHsDzqoLjzgOPJXcve9Y67aGtnedcSkuSrTLwJ44fdKbEWfaKU5nZMgqG3gCJvzql4hhTOUs2HrJkU40j+53Esz4ZtnzjjAO06epWtSXx/fFuXPefZVw9rAt/mzjE39E2bMXFsGdN2bjLjsVQlAcBwU4lYY/zoMf50DnenqyvreJi2LLAmRZn02fO3Xnf8U4XW+x5jWf8yk8s2XjIkk0tHcuGjXOdO57NX0FxAYRHs7zFOfx1e1+uu/pqkhK61HweU+bQzrLksvUbZw48cAbyS0uSz7JJKr3h4HZY/pqzntTxbGcm6jNugrjJzhIgxmOWbDxkyeYUHD8Em+ZB2hw0/UukKI/92oaQIUmED50IXc/y/wOB9dGJHGcwv+SByqx0p71Vx7JusR7nnfYDuKYaBScg9UNnhoLMlRDcEuKuccqnOwzwd3QNymknGxFpCRxX1WIR6QP0Az5V1QLvhlo/WLI5TXm5ZKd8zIpPX2cUqwglz5livnQxuHMhsIk+j1NUABnLy+5edq1wuiKDW55ckhzVz7p0/GHXCqeLbd0HTpdlt7OdLrZ+lzbdf7Me8EayWYGzMFlb4AecdWTyVfUX3gy0vrBk4x1fpO3ljjd/4E/9d3NNy5VOH3n+EQhtU5Z4eoxu3FVBqs4T7iWD+tu+d/4OJAA6Dy27e4k5w6+rsZoKjmY5CxcufxUO7YCwTjBsivNld5lV8kayWamqQ0XkDqC5qj4pIimqGu/lWOsFSzbe86ePUvnPD9v493XDuKhPG2dq+vXJztPeeTkQEu7MTD0gyXniO7i5v0M+fUf2OcUTJXcvuZlOe0QP90n9Mc6ElvagYf1XXAQ/fu50sW2e78wX1/8yp4ut21l291mBN5LNKuA3wDPAVHdlzLWqOti7odYPlmy8J6+wiCtfXMjO7OPMvWsU0W3cZFKY7wyAp812ZvQ9ftDpSipZhbT3zxrOIHj+MdixsGyesZIpgJq3PbkkuW03v4ZpTlPWZlj2KqT81xlraz/QWdxtyDX1dw65OuaNZHMecC/wg6r+TUR64Kyeead3Q60fLNl417YDR7n0+e/p2zGMmTePJDiwwnxVRQVO91LJYnDHDjhPffe+AAb83Fk0qz5VBxUXOVP7lAzq71gMRfnOOkJdR7qD+qOdp9WtJLnxyT8Ga99zHhbds9a5O4+b7FSyRfXxd3R+5dVqNBEJAFqp6mFvBFcfWbLxvuTVmdw5YxW/Gd2T+8f1q3rH4iLnwcWSxeCO7HHWL+l5ftlicM3b1FncpQ5uP7kk+fhBp73DICex9BzjVNw1a1H3sRn/UIWdS52kkzrbKf2PPc+ZoaDPuCZZfemNO5t3gFuAIpzigHDgOVX9ew3HjQOeAwKBV1T1rxW2hwBvAsOALOAaVd3mbnsImOp+5p2qOq+6c4rI+cBTQDNgBU53X2G5zzoDWARMUtX3q4vbko1vPPjBGmYu28mbNw7n3D5RNR9QXOysaV8yX9vhDOeBxh6jndkL+l7iuxUbjx9yZhMuSTAHtzrtYZ1PLklu1d43n28aliP7YOUbsPw/cHgXhMc4sxMMvQFa1eLfeiPhjWSToqrxIvILYCjwILBCVat8RFxEAoFNwM+ADJwkNVlV08rt8xtgiKreIiKTgMtV9RoRGQDMAIYDnYEvgZL705+cE9gAbAfGquomEXkc2K6qr5aL5QvgBPCaJRv/OJ5fRNI/vyf7aD5z7xpF+zAPFrtSdWYxLpmh+uA2kEBnoL1kFdLT+cFfmO/MjFySXDJXOtPyNGsF3UeV3b2062ODwqZqRYXOg87LXnZ+WQls5nQFD/+1U3HYyP/teCPZpALxwDvAdFX9RkRWq2qVU6iKyJnAY6p6kfv+IQBV/b9y+8xz91kkIkHAHiAKJ5mV7luyn3vYT84JvAIsVtWebvso4CFVHe++vxsoAM4APrZk4z8/7s3lsunfM7RrW96aOoLAgFP4z6fqTOOS5iaerHSnlLjrWWWLwYV3qvkc+zeUK0n+AQqOOgkseli5kuREe77CnJr9G5252FJmODNwdxzidLENurLRdrdWl2xq26n4b2AbsBr4VkS6ATWN2UQDO8u9zwBGVLWPqhaKSA4Q6bYvrnBstPu6snMeAIJEJFFVlwMTgS4AIhINXA6MwUk2lRKRm4GbAbp2tSnyfaV3hzD+NGEgD3ywlhe+SueOsb09P4mIM/jeKQ7O/yPsW1+WeD69z/nqMsJNPBOgjTtlTu6espLkLV9D7m6nPbIXxF/r3L3EjnImtjTmdEX1hfF/h7GPOMtYL30Fkm+Hz/8ACb90Ktkievg7yjpTq2SjqtOAaeWatovIGN+E5DlVVbcb7hl3HOhznLEegGeBB9zZD6o7x0vAS+Dc2fg24qbt6sQu/JCexTNfbmJEj0iGx57GFPgizpQiHQbAmIdg/6ayrrZ5DztfnYdC4QnY5/bgtog8uSS5JBkZ4wshYU6lWuJUZ9b0pS/D4hdh0T+h1wVOF1uvCxp95WKtko2ItAYeBc51m74BHgdyqjlsF+7dhSvGbatsnwy3G601TqFAdcdW2q6qi3BmOUBELqRsjCcRmOkmmnbAeBEpVNXZ1cRufEhEeOLyQazJOMRdM1cx985RtG3ppafno/pA1H1w7n3OVPJpyc5zPK3aO89D9BwDHQbbcsGm7olA93Ocr8O7nRVFV/wH3rnaWYPojKmQcF2jXX+otmM2HwDrgDfcpuuAOFW9oppjgnAG88fiJIRlwLWqmlpun9uAweUKBK5Q1atFZCDO+FBJgcB8oDcgVZ1TRNqr6j73zmYu8ISqLqgQ0+vYmE29sW5XDle8sJBRvdvxyg2Jtpy0aXoK82HDR04X246FEBTqjOmccRNED/V3dB6rbsymtr/e9VTVR1V1i/v1J6Dazka37Ph2YB6wHpjlJoXHRWSCu9urQKSIpAP3UFYYkArMAtKAz4DbVLWoqnO657pPRNYDa4CPKiYaU/8Mim7NQ+P7MX/DPl79fqu/wzGm7gU1c5LLjZ/CrQudh0NTZ8PLY+DlsbB6pjMrdSNQ2zubRcB9qvq9+/5s4ClVPdPH8fmF3dnUHVXl5rdW8PXGfXxw61kMiWnj75CM8a8TOU4F27JXIOtHZ4xx6PWQeKOzUGE95o3S5zichy9LynQOAjeo6hqvRVmPWLKpW4eO5XPJtO8JDBA+vvMcwkOt1NgYVJ2qyWWvOM/ugDMzwRk3OYUt9XDc8bS70VS15JmaITgPYSYA53sxRtOEtWnRjGmT49l16DgPfbgWW9DPGJyCgp5jYNLbcNcaOPtuZ3qc/14B0xNh0QvOTBcNhEepUVUPl5sT7R4fxGOaqGHdIrjnZ334ZM1uZizdWfMBxjQlbbrABY/CPWlw+UtOxdq8h+Dp/pB8pzMhaD13OvdhVjpkvOrW83oyqnc7/vRRKhv2NNp5Xo05dUEhzpLVN30JN38Dg65wHhj91znw2jhY+75T4VYPnU6ysb4O41UBAcLTV8cT3jyY299ZxbH8wpoPMqap6hwPSf+Ee9bDhX9xZsT4YCo8MxAWPAGHM/0d4UmqTTYikisihyv5ysV5/sUYr4oKC+HZa+LZvP8Ij85JrfkAY5q6FhFw1h1wxyq49j0nCX37d3hmELx7nTMhaD0YB612BgFVDaurQIwpcXavdtw+phfPL0jn7F7t+HlCdM0HGdPUBQRAnwudr+ytsPxVWPVfZxn2qH5OFVvcJGf6HD/wePG0psBKn/2vsKiYa19eQmpmDh/dcQ49omzZXWM8VnAc1n3gzMe2O8VZMiNuEpzxa2hfzSKGp8gbMwgYU6eCAgN4bnI8wUEB3P7OKk4UFNV8kDHmZMHNnRmmb/4abprvrPu08k14YQS8fqkzYW1R3YyNWrIx9Van1s15amIcabsP839z1/s7HGMaLhFnbaYr/u0UFIx91FmAcNb18Oxg+OZJyN3r0xAs2Zh67YIBHZh6TixvLNrOZ+v2+DscYxq+lu1g1D1w12qY9I6z7s5XTzhVbO/fCBm+GUKo7eJpxvjNA+P6sWxbNve/v5qBncPpEtE4Vzk0pk4FBEK/S5yvA+nuqqLvOIsJxlQ67HJ6H+f1MxrjZc2CAnh+cgLFCnfOXEVBUbG/QzKmcWnXCy7+K9y7Hs68zScfYcnGNAjdIlvy1ysHs2rHIf7x+SZ/h2NM49Sspc+WRbdkYxqMS4d0ZvLwrvzrm818s2m/v8MxxnjAko1pUB69bAB9O4Rxz7sp7D3cOBaVMqYpsGRjGpTQ4ECmX5vA0fxC7p6ZQlGxPZRsTENgycY0OL07hPF40iAWbcnin1+l+zscY0wt+DTZiMg4EdkoIuki8mAl20NE5F13+xIR6V5u20Nu+0YRuaimc4rI+SKyUkTWicgbIhLktv9CRNaIyFoRWeiuOmoauKuGxfDz+M48++UmFm/J8nc4xpga+CzZiEgg8E/gYmAAMFlEBlTYbSpwUFV7Ac8Af3OPHQBMAgYC44AXRCSwqnOKSADwBjBJVQcB24Eb3M/YCpynqoOBPwMv+eqaTd0REf5y+WC6RbbkrpmryD5aP9fwMMY4fHlnMxxIV9UtqpoPzASSKuyThJMkAN4HxoqIuO0zVTVPVbcC6e75qjpnJJCvqiU1sV8AVwKo6kJVPei2LwZifHCtxg9ahQTx/OQEDh4t4HfvrabYxm+Mqbd8mWyigfLr+2a4bZXuo6qFQA5O4qjq2KraDwBBIlLy2OtEoEslMU0FPq0sWBG5WUSWi8jy/futrLahGBTdmt9f0p8FG/bx6vdb/R2OMaYKjaJAQJ11EiYBz4jIUiAXOGmaYBEZg5NsHqjiHC+paqKqJkZFRfk6ZONF15/ZjYsGduBvn20gZechf4djjKmEL5PNLk6+u4hx2yrdxx3Qbw1kVXNsledU1UWqOkpVhwPfAqWPmYvIEOAVIElVbTS5kRERnrwyjg7hodwxYyWHTxT4OyRjTAW+TDbLgN4iEisizXDuPJIr7JNM2UD+RGCBe5eSDExyq9Vigd7A0urOKSLt3T9DcO5e/uW+7wp8CFxXbkzHNDKtWwQzbXICmYdO8OAHa7BFAY2pX3yWbNwxmNuBecB6YJaqporI4yIywd3tVSBSRNKBe4AH3WNTgVlAGvAZcJuqFlV1Tvdc94nIemAN8JGqLnDbH8EZB3pBRFJExJbgbKSGdWvL7y7sy9y1e3h7yQ5/h2OMKceWha6ELQvdcBUXK1NeX8biLVnMue1s+ncK93dIxjQZtiy0aTICAoSnr46jdfNgbn9nJUfz6mbJW2NM9SzZmEanXasQnrsmni0HjvLInNSaDzDG+JwlG9MondWrHXeM6cUHKzP4cGWGv8MxpsmzZGMarTvH9mZ49wj+MHsdqZk5/g7HmCbNko1ptIICA3hucjyhwYFcMu17Ln/hB17/YSv7c/P8HZoxTY5Vo1XCqtEalz05J/jfql3MSdnFhj25BAic3asdE+I6c9GgjoSHBvs7RGMaheqq0SzZVMKSTeO1aW8uySmZzFm9i53Zx2kWFMD5fduTFN+ZMf3aExoc6O8QjWmwLNl4yJJN46eqpOw8xJyUTD5es5sDR/IICwniwoEdSYrvzFk9IwkKtF5mYzxhycZDlmyalsKiYhZvyWZOyi4+W7eH3LxC2rVqxiWDOzEhPpqhXdvgrHxhjKmOJRsPWbJpuk4UFPH1xv0kr97Fl+v3kV9YTEzb5kyI60xSfDR9O4b5O0Rj6i1LNh6yZGMAck8U8HnqXuaszuSH9AMUFSv9OoZxWVxnJsR1pktEC3+HaEy9YsnGQ5ZsTEUHjuQxd+1u5qRksmK7s/Dr0K5tSIqPZvzgTkSFhfg5QmP8z5KNhyzZmOrszD7GR2sySU7JPKmUOik+mosGdiDMSqlNE2XJxkOWbExtbdyTS/LqXcxJySTjoFNKPbafU0o9uq+VUpumxZKNhyzZGE+pKqt2HiI5JZOP12Ry4Eg+YSFBXDTIKaU+s4eVUpvGz5KNhyzZmNNRWFTMoi1ZzEnJZF65UupLh3RmQnxnErpYKbVpnCzZeMiSjfEWp5R6H3NSMpm/wSml7hJRVkrdp4OVUpvGw5KNhyzZGF84XFJKnbKLH9IPUKzQr2MYE+I7c9kQK6U2DZ/fVuoUkXEislFE0kXkwUq2h4jIu+72JSLSvdy2h9z2jSJyUU3nFJHzRWSliKwTkTdEJMhtFxGZ5u6/RkSG+vKajalKeGgwE4fF8NbUESx5+AL+NGEgLZoF8uRnGxn15Fdc+eJC3ly0jQNHbFZq0/j47M5GRAKBTcDPgAxgGTBZVdPK7fMbYIiq3iIik4DLVfUaERkAzACGA52BL4E+7mE/OSewAdgOjFXVTSLyOLBdVV8VkfHAHcB4YATwnKqOqC52u7MxdWln9jGSV2fy0WqnlDowQJxS6rjOXGil1KYBqe7OJsiHnzscSFfVLW4QM4EkIK3cPknAY+7r94Hp4oycJgEzVTUP2Coi6e75qOKc+4F8Vd3k7vMF8BDwqrv9TXWy6mIRaSMinVR1ty8u2hhPdYlowW1jenHbmF5s2HOY5JRMkldncu97qwn5XwBj+7dnQlw0o/tGWSm1abB8mWyigZ3l3mfg3FlUuo+qFopIDhDpti+ucGy0+7qycx4AgkQkUVWXAxOBLtXEEQ2clGxE5GbgZoCuXbvW+iKN8aZ+HcPpNy6c+y7qy8odh0hO2cUna3czd+0ewkKCGDeoI0nx0ZzZM5LAAKtoMw2HL5NNnVFVdbvhnhGREOBzoMjDc7wEvARON5r3ozSm9kSEYd3aMqxbW/546QAWbnZKqT9dt4f3VmTQrlUIlw7pZKXUpsHwZbLZRdndBUCM21bZPhnugH5rIKuGYyttV9VFwCgAEbmQsjGe2sRhTL0VFBjAuX2iOLdPFE8UDOKrDftIXp3JO0t38PrCbXSNaMGEOOcZHiulNvWVL5PNMqC3iMTi/HCfBFxbYZ9k4AZgEU7X1wL3LiUZeEdEnsYpEOgNLAWkqnOKSHtV3efe2TwAPFHuM253x3dGADk2XmMaqtDgQC4e3ImLB3fi8IkC5q3bQ/LqTF74Op3pX6XTr2MYSfHRXBbXiZi2Vkpt6g+fJRt3DOZ2YB4QCLymqqlupdhyVU3GGcB/yy0AyMZJHrj7zcIpJigEblPVIoDKzul+5H0icilOOfeLqrrAbZ+LU4mWDhwDfuWrazamLoWHBnNVYheuSuzC/tw8PlnjFBb87bMN/O2zDSR2a0tSfGfGD+5EZCubldr4lz3UWQkrfTYN2Y4sZ1bqOSm72LT3CIEBwjm92pEU35kLB3akVUijGKo19ZDNIOAhSzamsdiw5zBzUpzlEHYdOk5IUAAX9O/AZXGdrZTaeJ0lGw9ZsjGNjaqycsdBd1bq3WQdzScsNIiLB3VkQpyVUhvvsGTjIUs2pjErLCrmh81ZJKdkMi91D0fyCokKc0up4zoTb6XU5hRZsvGQJRvTVJwoKGLBhn0kp2SyYKMzK3XXiBYkxXdmQlxnelsptfGAJRsPWbIxTVH5UuqSWan7dwonKb4zl8V1JrpNc3+HaOo5SzYesmRjmrp9uSeYu2Y3c1ZnsmrHIQDO6N6WCfHRjB/U0UqpTaUs2XjIko0xZUpKqWev2sWP+5xS6lG92zEhzkqpzcks2XjIko0xP6WqbNiTS/LqCqXUAzowwS2lDgmyUuqmzJKNhyzZGFO94mK3lHp1Jp9UKKVOio9mZA8rpW6KLNl4yJKNMbVXUko9J2UX89bt4Wh+UWkpdVJ8NHExra2UuomwZOMhSzbGnJqSUuo5Kbv4asN+8ouK6RbpzEqdFN+ZXu2tlLoxs2TjIUs2xpy+nOMFzEvdQ3JKJgs3O6XUAzqFM8FKqRstSzYesmRjjHftyz3BJ2t2Myclk5SdhwAY1q0tZ/WMZERsJEO7taFFM6tqa+gs2XjIko0xvrM96ygfrc7ki7S9rMs8TFGxEhQgDIlpzYgekYyIjSCxe4SVVDdAlmw8ZMnGmLpxJK+Q5duyWbI1myVbsliTkUNhsRIYIAzqHH5S8mndPNjf4ZoaWLLxkCUbY/zjWH4hK7cfYsnWLJZsySZl5yHyi4oRccZ7RsRGMjw2ghGxEbRt2czf4ZoKLNl4yJKNMfXDiYIiVu04xNKt2SzZmsXKHQc5UVAMQN8OYYzoEVGagKLCbAodf7Nk4yFLNsbUT/mFxazJOMSSrdks3pLFiu0HOZZfBEDPqJal3W4je0TSITzUz9E2PX5LNiIyDngOCAReUdW/VtgeArwJDAOygGtUdZu77SFgKlAE3Kmq86o7p4iMBf4OBABHgCmqmi4iXYE3gDbuMQ+q6tzq4rZkY0zDUFBUzLpdOaVjPsu3HSQ3rxCA7pEtGBEb6dz99Ii0Uus64JdkIyKBwCbgZ0AGsAyYrKpp5fb5DTBEVW8RkUnA5ap6jYgMAGYAw4HOwJdAH/ewSs8pIpuAJFVd7553uKpOEZGXgFWq+qJ73rmq2r262C3ZGNMwFRUraZmHWbI1i8Vbslm2LZuc4wUARLdpzogeEYx0E1DXiBY2s4GXVZdsfFlbOBxIV9UtbhAzgSQgrdw+ScBj7uv3genifPeTgJmqmgdsFZF093xUc04Fwt19WgOZ7uuq2o0xjUxggDA4pjWDY1pz06geFBcrG/fmsmRLFku2ZvP1xv18uHIXAB3DQ0vHfEb0iKBHu5aWfHzIl8kmGthZ7n0GMKKqfVS1UERygEi3fXGFY6Pd11Wd8yZgrogcBw4DI932x4DPReQOoCVwQWXBisjNwM0AXbt2rdUFGmPqt4AAoX+ncPp3CmfK2bGoKun7jrDY7XZbuDmLOSnO759RYSEMj41gZKzT7da7fStLPl7UmJ6a+i0wXlWXiMh9wNM4CWgy8Lqq/kNEzgTeEpFBqlpc/mBVfQl4CZxutDqO3RhTB0SE3h3C6N0hjOtGdkNV2XrgaOmYz5Kt2XyyZjcAES2bMbx7ROndT7+OYQTYTNanzJfJZhfQpdz7GLetsn0yRCQIp5srq4Zjf9IuIlFAnKoucdvfBT5zX08FxgGo6iIRCQXaAftO/dKMMY2BiNAjqhU9oloxeXhXVJWd2cdZ7D7ns2RrFp+l7gEgPDTIfcbH6XYb0CmcoMAAP19Bw+HLZLMM6C0isTiJYhJwbYV9koEbgEXARGCBqqqIJAPviMjTOAUCvYGlgFRxzoNAaxHpo6olBQTr3c/YAYwFXheR/kAosN9H12yMacBEhK6RLega2YKrE53fa3cdOs7S0uSTzZfrnd9TW4UEkdi9bWnyGRzdmmBLPlXyWbJxx2BuB+bhlBy/pqqpIvI4sFxVk4FXcbq10oFsnOSBu98snIH/QuA2VS0CqOycbvuvgQ9EpBgn+dzohnIv8LKI/BanWGCK2sNFxphaim7TnMsTYrg8IQaAvYdPnNTt9vXGDQC0aBbIsG5tGeGO+QyJaW0rl5ZjD3VWwkqfjTG1deBInjPDgZt8NuzJBSAkKICErm1K73yGdm1LaHDjTj42g4CHLNkYY07VwaP5LN2WXTrmk7b7MKrQLDCAuC6tS5PPsG5tG92yCpZsPGTJxhjjLTnHC1ix3Uk+i7dms25XTumyCoNjypJPYre2hIU27JmtLdl4yJKNMcZXjuQVsmL7wdJutzUZhygoUgIEBkW3dsZ8YiM5o3sErVs0rORjycZDlmyMMXXleH4RK3c4yWfxVndZhUJnWYV+HcPdiUUjGB4bSUQ9X1bBko2HLNkYY/zlREERKTsPlY75lF9WoU+HVmWTi8ZG1rtlFSzZeMiSjTGmvsgvLGbtrkMsdp/zWbEtm6Pusgo9oloyIjaSkW7y6djav8sqWLLxkCUbY0x9VVhUzLrMw6VjPsu2Zpcuq9AtsgUjYp0utxGxEXSJaFGnsVmy8ZAlG2NMQ1FUrKzffZjFbvJZurXCsgqxZfO7dYv07bIKlmw8ZMnGGNNQlV9WoeR5n6yj+QB0CA85acynZ5R3l1WwZOMhSzbGmMZCVdm8/0jpmM+SLVnsy80DoF2rkNI7n+GxEfRpf3ozW/tr8TRjjDF+JiL0ah9Gr/Zh/NJdVmFb1rHSMZ8lW7L4ZK2zrELbFsHcNqYXN43q4fU4LNkYY0wTIiLEtmtJbLuWTHKXVcg4eLx0zKd9uG8q2izZGGNMEyYidIloQZeIFlyV2KXmA06RLb5gjDHG5yzZGGOM8TlLNsYYY3zOko0xxhifs2RjjDHG5yzZGGOM8TlLNsYYY3zOko0xxhifs7nRKiEi+4Htp3h4O+CAF8PxJ7uW+qmxXEtjuQ6waynRTVWjKttgycbLRGR5VRPRNTR2LfVTY7mWxnIdYNdSG9aNZowxxucs2RhjjPE5Szbe95K/A/Aiu5b6qbFcS2O5DrBrqZGN2RhjjPE5u7Mxxhjjc5ZsjDHG+Jwlm1MkIuNEZKOIpIvIg5VsDxGRd93tS0Skux/CrJVaXMsUEdkvIinu103+iLMmIvKaiOwTkXVVbBcRmeZe5xoRGVrXMdZWLa5ltIjklPuePFLXMdaGiHQRka9EJE1EUkXkrkr2aRDfl1peS0P5voSKyFIRWe1ey58q2ce7P8NU1b48/AICgc1AD6AZsBoYUGGf3wD/cl9PAt71d9yncS1TgOn+jrUW13IuMBRYV8X28cCngAAjgSX+jvk0rmU08LG/46zFdXQChrqvw4BNlfz7ahDfl1peS0P5vgjQyn0dDCwBRlbYx6s/w+zO5tQMB9JVdYuq5gMzgaQK+yQBb7iv3wfGiojUYYy1VZtraRBU9Vsgu5pdkoA31bEYaCMineomOs/U4loaBFXdraor3de5wHogusJuDeL7UstraRDcv+sj7ttg96titZhXf4ZZsjk10cDOcu8z+Ok/utJ9VLUQyAEi6yQ6z9TmWgCudLs43hcR3y1U7lu1vdaG4ky3G+RTERno72Bq4nbDJOD8Fl1eg/u+VHMt0EC+LyISKCIpwD7gC1Wt8vvijZ9hlmxMbXwEdFfVIcAXlP22Y/xnJc48VHHA88Bs/4ZTPRFpBXwA3K2qh/0dz+mo4VoazPdFVYtUNR6IAYaLyCBffp4lm1OzCyj/232M21bpPiISBLQGsuokOs/UeC2qmqWqee7bV4BhdRSbt9Xm+9YgqOrhkm4QVZ0LBItIOz+HVSkRCcb54fy2qn5YyS4N5vtS07U0pO9LCVU9BHwFjKuwyas/wyzZnJplQG8RiRWRZjiDZ8kV9kkGbnBfTwQWqDvSVs/UeC0V+s8n4PRVN0TJwPVu9dNIIEdVd/s7qFMhIh1L+s9FZDjO/+V698uMG+OrwHpVfbqK3RrE96U219KAvi9RItLGfd0c+BmwocJuXv0ZFnSqBzZlqlooIrcD83CquV5T1VQReRxYrqrJOP8o3xKRdJyB3kn+i7hqtbyWO0VkAlCIcy1T/BZwNURkBk41UDsRyQAexRn4RFX/BczFqXxKB44Bv/JPpDWrxbVMBG4VkULgODCpnv4yczZwHbDWHR8AeBjoCg3u+1Kba2ko35dOwBsiEoiTEGep6se+/Blm09UYY4zxOetGM8YY43OWbIwxxvicJRtjjDE+Z8nGGGOMz1myMcYY43OWbIzxAxEpKjczcIpUMtv2aZy7e1WzRRvjL/acjTH+cdydKsSYJsHubIypR0Rkm4g8KSJr3fVGernt3UVkgTsZ6nwR6eq2dxCR/7kTP64WkbPcUwWKyMvuWiWfu0+JG+M3lmyM8Y/mFbrRrim3LUdVBwPTgWfdtueBN9zJUN8Gprnt04Bv3IkfhwKpbntv4J+qOhA4BFzp06sxpgY2g4AxfiAiR1S1VSXt24DzVXWLO+njHlWNFJEDQCdVLXDbd6tqOxHZD8SUmyi1ZPr7L1S1t/v+ASBYVf9SB5dmTKXszsaY+kereO2JvHKvi7DxWeNnlmyMqX+uKffnIvf1QsomQvwF8J37ej5wK5QuhtW6roI0xhP2244x/tG83MzBAJ+pakn5c1sRWYNzdzLZbbsD+I+I3Afsp2xm5LuAl0RkKs4dzK1AvZue3xgbszGmHnHHbBJV9YC/YzHGm6wbzRhjjM/ZnY0xxhifszsbY4wxPmfJxhhjjM9ZsjHGGONzlmyMMcb4nCUbY4wxPvf/A4/HN9toIy4LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:10<00:00,  2.27s/it, a_r=0.614, d_r=0.624, loss=0.000916, r_a=0.99, r_d=0.989, r_loss=5.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:04<00:00,  2.26s/it, a_r=0.616, d_r=0.617, loss=0.000899, r_a=0.99, r_d=0.99, r_loss=5.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:08<00:00,  2.26s/it, a_r=0.624, d_r=0.628, loss=0.000897, r_a=0.99, r_d=0.99, r_loss=5.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:09<00:00,  2.27s/it, a_r=0.626, d_r=0.628, loss=0.000881, r_a=0.99, r_d=0.989, r_loss=5.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:06<00:00,  2.26s/it, a_r=0.618, d_r=0.617, loss=0.000924, r_a=0.989, r_d=0.988, r_loss=6.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:03<00:00,  2.26s/it, a_r=0.621, d_r=0.629, loss=0.000898, r_a=0.99, r_d=0.989, r_loss=5.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:00<00:00,  2.26s/it, a_r=0.626, d_r=0.623, loss=0.000886, r_a=0.99, r_d=0.989, r_loss=5.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:00<00:00,  2.26s/it, a_r=0.634, d_r=0.641, loss=0.000851, r_a=0.991, r_d=0.99, r_loss=5.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:06<00:00,  2.26s/it, a_r=0.612, d_r=0.612, loss=0.000956, r_a=0.981, r_d=0.985, r_loss=3.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:10<00:00,  2.27s/it, a_r=0.619, d_r=0.623, loss=0.000911, r_a=0.985, r_d=0.987, r_loss=3.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:09<00:00,  2.27s/it, a_r=0.618, d_r=0.625, loss=0.000911, r_a=0.985, r_d=0.986, r_loss=3.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:06<00:00,  2.26s/it, a_r=0.629, d_r=0.628, loss=0.00085, r_a=0.988, r_d=0.988, r_loss=3.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:06<00:00,  2.26s/it, a_r=0.617, d_r=0.619, loss=0.000934, r_a=0.989, r_d=0.988, r_loss=5.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:03<00:00,  2.26s/it, a_r=0.619, d_r=0.626, loss=0.00091, r_a=0.99, r_d=0.989, r_loss=5.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:13<00:00,  2.27s/it, a_r=0.626, d_r=0.63, loss=0.000868, r_a=0.991, r_d=0.99, r_loss=5.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:08<00:00,  2.26s/it, a_r=0.627, d_r=0.626, loss=0.000871, r_a=0.991, r_d=0.99, r_loss=5.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:12<00:00,  2.27s/it, a_r=0.613, d_r=0.619, loss=0.000938, r_a=0.989, r_d=0.989, r_loss=9.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:05<00:00,  2.26s/it, a_r=0.62, d_r=0.62, loss=0.000901, r_a=0.99, r_d=0.99, r_loss=9.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:08<00:00,  2.26s/it, a_r=0.62, d_r=0.629, loss=0.000877, r_a=0.99, r_d=0.989, r_loss=9.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:13<00:00,  2.27s/it, a_r=0.626, d_r=0.632, loss=0.000875, r_a=0.991, r_d=0.99, r_loss=8.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:17<00:00,  2.27s/it, a_r=0.612, d_r=0.617, loss=0.000928, r_a=0.989, r_d=0.989, r_loss=9.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:11<00:00,  2.27s/it, a_r=0.623, d_r=0.625, loss=0.000911, r_a=0.99, r_d=0.99, r_loss=9.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:11<00:00,  2.27s/it, a_r=0.623, d_r=0.626, loss=0.000876, r_a=0.991, r_d=0.989, r_loss=8.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:04<00:00,  2.26s/it, a_r=0.628, d_r=0.629, loss=0.000865, r_a=0.992, r_d=0.991, r_loss=8.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:18<00:00,  2.27s/it, a_r=0.611, d_r=0.616, loss=0.000962, r_a=0.99, r_d=0.988, r_loss=8.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:06<00:00,  2.26s/it, a_r=0.616, d_r=0.627, loss=0.000894, r_a=0.99, r_d=0.989, r_loss=8.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:09<00:00,  2.27s/it, a_r=0.621, d_r=0.63, loss=0.00088, r_a=0.991, r_d=0.99, r_loss=8.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:03<00:00,  2.26s/it, a_r=0.63, d_r=0.632, loss=0.000865, r_a=0.991, r_d=0.99, r_loss=8.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:15<00:00,  2.27s/it, a_r=0.614, d_r=0.616, loss=0.000944, r_a=0.989, r_d=0.989, r_loss=9.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:03<00:00,  2.26s/it, a_r=0.623, d_r=0.627, loss=0.000901, r_a=0.991, r_d=0.99, r_loss=8.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:14<00:00,  2.27s/it, a_r=0.626, d_r=0.624, loss=0.000883, r_a=0.991, r_d=0.99, r_loss=9.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:11<00:00,  2.27s/it, a_r=0.63, d_r=0.635, loss=0.000868, r_a=0.991, r_d=0.99, r_loss=8.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:12<00:00,  2.27s/it, a_r=0.616, d_r=0.618, loss=0.000934, r_a=0.99, r_d=0.988, r_loss=8.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:12<00:00,  2.27s/it, a_r=0.624, d_r=0.631, loss=0.000908, r_a=0.99, r_d=0.988, r_loss=8.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:12<00:00,  2.27s/it, a_r=0.621, d_r=0.629, loss=0.00089, r_a=0.99, r_d=0.989, r_loss=8.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1461/1461 [55:10<00:00,  2.27s/it, a_r=0.628, d_r=0.634, loss=0.000855, r_a=0.992, r_d=0.99, r_loss=8.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_050623_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [04:37<00:00, 16.34s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0005919684712745654\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9965\t0.9344\t0.9848\t0.9889\t0.9713\t0.9962\t0.7748\t0.1755\t0.0486\t13352\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9955\t0.9372\t0.9873\t0.9914\t0.9741\t0.9970\t0.8062\t0.1961\t0.0542\t13391\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/'\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    \n",
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True,crop=False)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "\n",
    "for i,model in enumerate(models):\n",
    "        state_dict = torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_all_050623_{}'.format(i))\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_all_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 803/803 [1:05:23<00:00,  4.89s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0007022423108514837\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9966\t0.742\t0.8819\t0.9537\t0.834\t0.9342\t0.2282\t0.0720\t0.0187\t73366\t98870.0\t98870\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9965\t0.745\t0.8793\t0.9495\t0.8339\t0.9405\t0.2373\t0.0731\t0.0192\t74583\t100114.0\t100114\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(98870+100114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73366+74583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7435"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.742+0.745)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "#df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood/transformer_40k_test_set_predictions_120123.gz',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
