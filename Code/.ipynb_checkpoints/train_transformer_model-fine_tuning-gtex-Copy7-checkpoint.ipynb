{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 22 16:26:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    37W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:98:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    39W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-PCI...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    37W / 250W |      0MiB / 40960MiB |     29%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation_train,gene_to_label,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//4, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:19<00:00,  1.23s/it, a_r=0.641, d_r=0.637, loss=0.000791, r_a=0.994, r_d=0.993, r_loss=6.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████| 612/612 [06:00<00:00,  1.70it/s, a_r=0.623, d_r=0.606, loss=0.00107, r_a=0.994, r_d=0.993, r_loss=7.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9979\t0.7459\t0.8673\t0.942\t0.8333\t0.9846\t0.2584\t0.0785\t0.0200\t14681\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9974\t0.7453\t0.8705\t0.9426\t0.8323\t0.9815\t0.2320\t0.0690\t0.0172\t14990\t20114.0\t20114\n",
      "epoch: 1/4, val loss = 0.000799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:54<00:00,  1.22s/it, a_r=0.646, d_r=0.645, loss=0.000755, r_a=0.994, r_d=0.994, r_loss=5.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████| 612/612 [05:48<00:00,  1.75it/s, a_r=0.619, d_r=0.613, loss=0.00105, r_a=0.994, r_d=0.994, r_loss=7.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9983\t0.7494\t0.8737\t0.9476\t0.8386\t0.9863\t0.2622\t0.0805\t0.0197\t14750\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9979\t0.7473\t0.8748\t0.9461\t0.8364\t0.9858\t0.2544\t0.0732\t0.0172\t15031\t20114.0\t20114\n",
      "epoch: 2/4, val loss = 0.000782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:38<00:00,  1.21s/it, a_r=0.652, d_r=0.648, loss=0.000747, r_a=0.995, r_d=0.994, r_loss=5.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████| 612/612 [05:55<00:00,  1.72it/s, a_r=0.613, d_r=0.609, loss=0.00104, r_a=0.995, r_d=0.994, r_loss=7.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9985\t0.7512\t0.8755\t0.95\t0.8408\t0.9846\t0.2287\t0.0683\t0.0171\t14785\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9973\t0.7497\t0.8753\t0.9477\t0.8378\t0.9832\t0.2321\t0.0642\t0.0157\t15079\t20114.0\t20114\n",
      "epoch: 3/4, val loss = 0.000773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:39<00:00,  1.21s/it, a_r=0.655, d_r=0.657, loss=0.000721, r_a=0.995, r_d=0.995, r_loss=5.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████| 612/612 [06:05<00:00,  1.67it/s, a_r=0.619, d_r=0.609, loss=0.00103, r_a=0.995, r_d=0.995, r_loss=7.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9985\t0.7535\t0.8778\t0.9505\t0.8414\t0.9877\t0.2573\t0.0761\t0.0174\t14831\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9977\t0.7498\t0.8772\t0.9492\t0.8391\t0.9873\t0.2470\t0.0741\t0.0189\t15082\t20114.0\t20114\n",
      "epoch: 4/4, val loss = 0.000770\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|████████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:51<00:00,  1.22s/it, a_r=0.641, d_r=0.64, loss=0.00079, r_a=0.993, r_d=0.993, r_loss=5.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:41<00:00,  1.21s/it, a_r=0.647, d_r=0.644, loss=0.000771, r_a=0.994, r_d=0.993, r_loss=5.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:11<00:00,  1.23s/it, a_r=0.651, d_r=0.646, loss=0.000738, r_a=0.994, r_d=0.995, r_loss=5.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:54<00:00,  1.22s/it, a_r=0.655, d_r=0.653, loss=0.000724, r_a=0.995, r_d=0.995, r_loss=5.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:39<00:00,  1.21s/it, a_r=0.642, d_r=0.641, loss=0.000791, r_a=0.994, r_d=0.993, r_loss=5.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:57<00:00,  1.22s/it, a_r=0.641, d_r=0.645, loss=0.000774, r_a=0.994, r_d=0.994, r_loss=5.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:55<00:00,  1.22s/it, a_r=0.658, d_r=0.661, loss=0.000729, r_a=0.994, r_d=0.994, r_loss=5.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:07<00:00,  1.23s/it, a_r=0.658, d_r=0.651, loss=0.000741, r_a=0.995, r_d=0.995, r_loss=5.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:15<00:00,  1.23s/it, a_r=0.641, d_r=0.644, loss=0.000811, r_a=0.988, r_d=0.991, r_loss=3.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:48<00:00,  1.21s/it, a_r=0.648, d_r=0.644, loss=0.000756, r_a=0.989, r_d=0.992, r_loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:58<00:00,  1.22s/it, a_r=0.647, d_r=0.645, loss=0.000754, r_a=0.992, r_d=0.993, r_loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:47<00:00,  1.21s/it, a_r=0.653, d_r=0.65, loss=0.000731, r_a=0.991, r_d=0.993, r_loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:02<00:00,  1.22s/it, a_r=0.643, d_r=0.638, loss=0.000783, r_a=0.994, r_d=0.993, r_loss=4.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:59<00:00,  1.22s/it, a_r=0.641, d_r=0.64, loss=0.000773, r_a=0.994, r_d=0.994, r_loss=4.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:51<00:00,  1.22s/it, a_r=0.652, d_r=0.649, loss=0.000739, r_a=0.994, r_d=0.994, r_loss=4.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:57<00:00,  1.22s/it, a_r=0.653, d_r=0.647, loss=0.000751, r_a=0.995, r_d=0.994, r_loss=4.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:43<00:00,  1.21s/it, a_r=0.641, d_r=0.638, loss=0.000782, r_a=0.994, r_d=0.994, r_loss=8.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:57<00:00,  1.22s/it, a_r=0.653, d_r=0.648, loss=0.000753, r_a=0.995, r_d=0.995, r_loss=8.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:49<00:00,  1.21s/it, a_r=0.662, d_r=0.657, loss=0.000753, r_a=0.994, r_d=0.994, r_loss=8.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:49<00:00,  1.21s/it, a_r=0.655, d_r=0.65, loss=0.000734, r_a=0.995, r_d=0.995, r_loss=8.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|████████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:53<00:00,  1.22s/it, a_r=0.643, d_r=0.64, loss=0.000776, r_a=0.994, r_d=0.994, r_loss=8.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:56<00:00,  1.22s/it, a_r=0.649, d_r=0.645, loss=0.000762, r_a=0.994, r_d=0.994, r_loss=8.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:56<00:00,  1.22s/it, a_r=0.652, d_r=0.641, loss=0.000743, r_a=0.995, r_d=0.995, r_loss=8.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:43<00:00,  1.21s/it, a_r=0.658, d_r=0.651, loss=0.000745, r_a=0.996, r_d=0.995, r_loss=8.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:38<00:00,  1.21s/it, a_r=0.641, d_r=0.637, loss=0.000786, r_a=0.993, r_d=0.992, r_loss=8.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:44<00:00,  1.21s/it, a_r=0.641, d_r=0.645, loss=0.000764, r_a=0.995, r_d=0.994, r_loss=8.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:50<00:00,  1.21s/it, a_r=0.642, d_r=0.642, loss=0.000748, r_a=0.995, r_d=0.995, r_loss=8.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:49<00:00,  1.21s/it, a_r=0.655, d_r=0.655, loss=0.000725, r_a=0.995, r_d=0.994, r_loss=7.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:54<00:00,  1.22s/it, a_r=0.642, d_r=0.636, loss=0.00079, r_a=0.994, r_d=0.993, r_loss=8.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:49<00:00,  1.21s/it, a_r=0.649, d_r=0.647, loss=0.000765, r_a=0.995, r_d=0.995, r_loss=8.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:00<00:00,  1.22s/it, a_r=0.652, d_r=0.654, loss=0.000737, r_a=0.994, r_d=0.995, r_loss=8.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:52<00:00,  1.22s/it, a_r=0.655, d_r=0.651, loss=0.000738, r_a=0.994, r_d=0.995, r_loss=8.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:59<00:00,  1.22s/it, a_r=0.65, d_r=0.646, loss=0.0008, r_a=0.994, r_d=0.992, r_loss=8.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:54<00:00,  1.22s/it, a_r=0.64, d_r=0.642, loss=0.000786, r_a=0.994, r_d=0.993, r_loss=8.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [28:51<00:00,  1.22s/it, a_r=0.656, d_r=0.651, loss=0.000741, r_a=0.996, r_d=0.994, r_loss=8.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████| 1425/1425 [29:20<00:00,  1.24s/it, a_r=0.655, d_r=0.645, loss=0.000726, r_a=0.996, r_d=0.995, r_loss=7.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_021222_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:59<00:00, 10.59s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.000540425745996493\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9964\t0.9345\t0.9845\t0.9883\t0.9714\t0.9966\t0.7516\t0.1659\t0.0455\t13353\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9962\t0.9381\t0.9868\t0.9912\t0.9747\t0.9968\t0.7797\t0.1718\t0.0460\t13405\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    \n",
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [1:36:13<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0003161097466255434\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9811\t0.9308\t0.9896\t0.995\t0.9621\t0.9970\t0.8110\t0.1762\t0.0538\t83504\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9819\t0.935\t0.9927\t0.9966\t0.9661\t0.9974\t0.8420\t0.1865\t0.0557\t83882\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 774/774 [51:58<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0006119976054213493\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9977\t0.7589\t0.8938\t0.9618\t0.8516\t0.9632\t0.2236\t0.0684\t0.0175\t67994\t89600.0\t89600\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9978\t0.7576\t0.888\t0.956\t0.847\t0.9662\t0.2287\t0.0679\t0.0178\t69145\t91272.0\t91272\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/transformer_40k_test_set_predictions_120123.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492999999999999"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8516+0.847)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7582500000000001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7589+0.7576)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137139"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67994+69145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180872"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89600+91272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data('/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood', setType,'annotation_rnasplice-blood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 536/536 [27:01<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.002151629097392338\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9907\t0.637\t0.6795\t0.6997\t0.6506\t0.9589\t0.2154\t0.0641\t0.0157\t44514\t69880.0\t69880\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9942\t0.6597\t0.696\t0.711\t0.6705\t0.9806\t0.2487\t0.0718\t0.0184\t44199\t67001.0\t67001\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
