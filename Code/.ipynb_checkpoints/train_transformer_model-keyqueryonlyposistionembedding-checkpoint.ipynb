{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d\n",
    "from src.models import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 8\n",
    "k = 2\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = k*6*N_GPUS\n",
    "\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-050422'\n",
    "setType = 'train'\n",
    "annotation, transcriptToLabel, seqData = getData(data_dir, setType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(annotation_train,transcriptToLabel,SL,CL_max)\n",
    "val_dataset = spliceDataset(annotation_validation,transcriptToLabel,SL,CL_max)\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=k*100, shuffle=True, num_workers=16,collate_fn=collate_fn, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=k*100, shuffle=False,collate_fn=collate_fn, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [30:48<00:00, 18.31s/it, accepor_recall=0.878, donor_recall=0.889, loss=0.000206, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.010215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|████████████████████████████████████████████████████████████████████| 12/12 [03:57<00:00, 19.83s/it, accepor_recall=0.904, donor_recall=0.94, loss=0.000477, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9485\t0.8281\t0.9586\t0.9811\t0.8821\t0.9503999948501587\t0.7400000095367432\t0.09210000187158585\t0.00800000037997961\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9577\t0.8573\t0.9703\t0.9879\t0.908\t0.9689000248908997\t0.8345000147819519\t0.1670999974012375\t0.01730000041425228\t21432\n",
      "epoch: 1/10, val loss = 0.000440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [29:33<00:00, 17.56s/it, accepor_recall=0.896, donor_recall=0.909, loss=0.000167, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|███████████████████████████████████████████████████████████████████| 12/12 [03:48<00:00, 19.07s/it, accepor_recall=0.707, donor_recall=0.712, loss=0.000444, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9636\t0.8412\t0.9497\t0.978\t0.893\t0.910099983215332\t0.11569999903440475\t0.005200000014156103\t0.0010999999940395355\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9618\t0.8399\t0.9577\t0.9842\t0.8964\t0.8919000029563904\t0.1386999934911728\t0.00570000009611249\t0.0010999999940395355\t21432\n",
      "epoch: 2/10, val loss = 0.000390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [29:32<00:00, 17.55s/it, accepor_recall=0.915, donor_recall=0.915, loss=0.000182, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|███████████████████████████████████████████████████████████████████| 12/12 [03:37<00:00, 18.12s/it, accepor_recall=0.857, donor_recall=0.874, loss=0.000268, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9733\t0.8956\t0.9776\t0.9872\t0.9353\t0.9634000062942505\t0.30169999599456787\t0.00559999980032444\t0.0010000000474974513\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9708\t0.9064\t0.9853\t0.9942\t0.9446\t0.9429000020027161\t0.3517000079154968\t0.006200000178068876\t0.0008999999845400453\t21432\n",
      "epoch: 3/10, val loss = 0.000231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [29:33<00:00, 17.56s/it, accepor_recall=0.917, donor_recall=0.921, loss=0.000157, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|███████████████████████████████████████████████████████████████████| 12/12 [03:35<00:00, 18.00s/it, accepor_recall=0.823, donor_recall=0.798, loss=0.000363, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9644\t0.8637\t0.9623\t0.9848\t0.9118\t0.9550999999046326\t0.3050000071525574\t0.007600000128149986\t0.0010999999940395355\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9593\t0.8648\t0.9722\t0.9883\t0.9139\t0.9326000213623047\t0.21209999918937683\t0.003599999938160181\t0.0005000000237487257\t21432\n",
      "epoch: 4/10, val loss = 0.000317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [29:14<00:00, 17.37s/it, accepor_recall=0.929, donor_recall=0.936, loss=0.000151, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|███████████████████████████████████████████████████████████████████| 12/12 [04:05<00:00, 20.44s/it, accepor_recall=0.879, donor_recall=0.894, loss=0.000226, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9739\t0.9133\t0.9853\t0.9922\t0.9482\t0.9297999739646912\t0.35740000009536743\t0.004999999888241291\t0.0010000000474974513\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9724\t0.9194\t0.9903\t0.9949\t0.952\t0.9570000171661377\t0.4052000045776367\t0.003700000001117587\t0.0005000000237487257\t21432\n",
      "epoch: 5/10, val loss = 0.000195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|████████████████████████████████████████████████████████████████| 101/101 [29:35<00:00, 17.58s/it, accepor_recall=0.931, donor_recall=0.936, loss=0.00015, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|████████████████████████████████████████████████████████████████████| 12/12 [04:03<00:00, 20.28s/it, accepor_recall=0.886, donor_recall=0.91, loss=0.000242, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9717\t0.9099\t0.9836\t0.9907\t0.9446\t0.9642000198364258\t0.43720000982284546\t0.005200000014156103\t0.000699999975040555\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.974\t0.9184\t0.9879\t0.9937\t0.9512\t0.9873999953269958\t0.4896000027656555\t0.002300000051036477\t0.00019999999494757503\t21432\n",
      "epoch: 6/10, val loss = 0.000207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|███████████████████████████████████████████████████████████████| 101/101 [28:56<00:00, 17.20s/it, accepor_recall=0.936, donor_recall=0.941, loss=0.000126, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|███████████| 12/12 [03:54<00:00, 19.50s/it, accepor_recall=0.905, donor_recall=0.91, loss=0.000229, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9697\t0.9164\t0.9842\t0.9916\t0.9455\t0.9487000107765198\t0.49399998784065247\t0.0044999998062849045\t0.000699999975040555\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.97\t0.9198\t0.9881\t0.9939\t0.9507\t0.963699996471405\t0.4945000112056732\t0.0024999999441206455\t0.00039999998989515007\t21432\n",
      "epoch: 7/10, val loss = 0.000193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|██████████████████████████████████████████████████████| 101/101 [29:38<00:00, 17.61s/it, accepor_recall=0.954, donor_recall=0.961, loss=0.000104, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|██████████████████████████████████████████████████████████| 12/12 [03:38<00:00, 18.22s/it, accepor_recall=0.923, donor_recall=0.939, loss=0.000199, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9742\t0.9258\t0.9881\t0.9934\t0.9551\t0.9710000157356262\t0.5569000244140625\t0.0027000000700354576\t0.0005000000237487257\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9733\t0.9314\t0.9916\t0.9953\t0.959\t0.9775000214576721\t0.6735000014305115\t0.0032999999821186066\t0.0005000000237487257\t21432\n",
      "epoch: 8/10, val loss = 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|███████████████████████████████████████████████████████| 101/101 [29:45<00:00, 17.68s/it, accepor_recall=0.965, donor_recall=0.968, loss=8.89e-5, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|██████████████████████████████████████████████████████████| 12/12 [03:47<00:00, 18.98s/it, accepor_recall=0.904, donor_recall=0.912, loss=0.000206, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9749\t0.927\t0.9878\t0.9927\t0.9543\t0.9710000157356262\t0.3869999945163727\t0.00139999995008111\t0.00019999999494757503\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9756\t0.9315\t0.9909\t0.9948\t0.9592\t0.9735999703407288\t0.40720000863075256\t0.001500000013038516\t0.00019999999494757503\t21432\n",
      "epoch: 9/10, val loss = 0.000176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|██████████████████████████████████████████████████████| 101/101 [29:34<00:00, 17.56s/it, accepor_recall=0.968, donor_recall=0.971, loss=7.51e-5, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|█████████████████████████████████████████████████████████| 12/12 [03:40<00:00, 18.37s/it, accepor_recall=0.919, donor_recall=0.923, loss=0.000211, pred_l1_dist=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9718\t0.9287\t0.9866\t0.9926\t0.9527\t0.9871000051498413\t0.5321000218391418\t0.0015999999595806003\t0.0003000000142492354\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9698\t0.9319\t0.9901\t0.9946\t0.9549\t0.9890999794006348\t0.5302000045776367\t0.0010999999940395355\t0.00019999999494757503\t21432\n",
      "epoch: 10/10, val loss = 0.000179\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10:  25%|█████████████▊                                          | 25/101 [08:02<19:51, 15.68s/it, accepor_recall=0.638, donor_recall=0.685, loss=0.00171, pred_l1_dist=0]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd41c6054c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Epoch (train) 1/10:  25%|█████████████▊                                          | 25/101 [08:03<24:28, 19.33s/it, accepor_recall=0.638, donor_recall=0.685, loss=0.00171, pred_l1_dist=0]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_39650/2798543276.py\", line 23, in <module>\n",
      "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device)\n",
      "  File \"/SplicePrediction/Code/src/train.py\", line 91, in trainModel\n",
      "    train_loss.backward()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/opt/conda/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39650/2798543276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mwarmup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_constant_schedule_with_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelFileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/SplicePrediction/Code/src/train.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, fileName, criterion, train_loader, val_loader, optimizer, scheduler, warmup, BATCH_SIZE, epochs, device, exonInclusion, verbose, lowValidationGPUMem)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "hs = []\n",
    "\n",
    "for model_nr in range(5):\n",
    "    model_m = SpliceFormer(CL_max)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_170522_{}'.format(model_nr)\n",
    "    #model_m.load_state_dict(torch.load('../Results/PyTorch_Models/SpliceAI_Ensembl_dgxtest_{}'.format(0)))\n",
    "    #loss = nn.CrossEntropyLoss(weight=torch.from_numpy(weights).float().to(device),ignore_index=-1,reduction='mean')\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = nn.KLDivLoss()\n",
    "    learning_rate= k*1e-3\n",
    "    optimizer = torch.optim.Adam(model_m.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device)\n",
    "    hs.append(h)\n",
    "\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 17/17 [06:36<00:00, 23.30s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_030522_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[1].detach() for i in range(n_models)])\n",
    "        outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9961\t0.9486\t0.9881\t0.9913\t0.9779\t0.9782999753952026\t0.3280999958515167\t0.002899999963119626\t0.0005000000237487257\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9958\t0.9523\t0.9896\t0.9921\t0.9797\t0.9785000085830688\t0.33739998936653137\t0.002199999988079071\t0.0003000000142492354\t14289\n"
     ]
    }
   ],
   "source": [
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9486+0.9523)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9779+0.9797)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData(data_dir, setType)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 90/90 [4:22:57<00:00, 175.30s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_030522_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(annotation_test,transcriptToLabel_test,SL,CL_max)\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0,collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks.to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks.to(device),0),1,2)\n",
    "    batch_chunks = torch.split(batch_chunks, BATCH_SIZE, dim=0)\n",
    "    target_chunks = torch.split(target_chunks, BATCH_SIZE, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[1].detach() for i in range(n_models)])\n",
    "        outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9821\t0.9399\t0.9919\t0.9958\t0.9675\t0.9814000129699707\t0.45570001006126404\t0.0026000000070780516\t0.00039999998989515007\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9832\t0.9446\t0.9941\t0.997\t0.9713\t0.9811999797821045\t0.4941999912261963\t0.002099999925121665\t0.0003000000142492354\t89712\n"
     ]
    }
   ],
   "source": [
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9399+0.9446)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9675+0.9713)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
