{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "\n",
    "from src.train import trainModel\n",
    "from src.dataloader import getData,spliceDataset,h5pyDataset,getDataPointList,getDataPointListFull,DataPoint\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics\n",
    "import copy\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 21 17:06:24 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:5E:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    32W / 250W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA Tesla V1...  Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    32W / 250W |      0MiB / 32510MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snps = df.drop_duplicates(subset=['not_sQTL'])['not_sQTL'].values\n",
    "#res = pd.DataFrame({'Chr':[x.split(':')[0] for x in snps],'Pos':[int(x.split(':')[1]) for x in snps],'marker':snps})\n",
    "#res.sort_values(['Chr','Pos'],ascending=True).to_csv('../Data/not_sQTL.gor',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_list = pd.read_csv('../Data/snv_list.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 8\n",
    "k = 2\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = k*6*N_GPUS\n",
    "\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfastx\n",
    "data_dir = '../Data/'\n",
    "fasta_file_path = '../Data/genome.fa'\n",
    "gtf_file_path = '../Data/Homo_sapiens.GRCh38.87.db'\n",
    "fasta = pyfastx.Fasta(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACCUMULATION_STEPS = 1\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_031122_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_boundries = {}\n",
    "#for gene in tqdm(genes):\n",
    "#    gene_boundries[gene[\"gene_name\"][0]] = [int(gene[3]),int(gene[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/gene_boundries.pkl', 'wb') as f:\n",
    "#    pickle.dump(gene_boundries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gffutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = gffutils.FeatureDB(gtf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_snv = snv_list[snv_list['category']=='mutant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñç                                                                             | 177/28972 [01:33<3:43:54,  2.14it/s]"
     ]
    }
   ],
   "source": [
    "def predictSplicing(seq,models):\n",
    "    outputs = []\n",
    "    for i in range(seq.shape[0]):\n",
    "        batch_features = torch.tensor(seq[i,:,:], device=device).float().unsqueeze(0)\n",
    "        batch_features = torch.swapaxes(batch_features,1,2)\n",
    "        prediction = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        prediction = torch.stack(prediction)\n",
    "        prediction = torch.mean(prediction,dim=0)\n",
    "        outputs.append(prediction)\n",
    "    \n",
    "    outputs = torch.cat(outputs,dim=2)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    return outputs\n",
    "\n",
    "def plotPrediction(outputs):\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1,figsize=(22, 6),sharex=True)\n",
    "    x = np.arange(outputs.shape[2])\n",
    "    ax1.plot(x,outputs[0,1,:],linewidth=2,zorder=-32)\n",
    "    ax2.plot(x,outputs[0,2,:],linewidth=2,zorder=-32)\n",
    "    plt.xlabel('Distance from transcript start (nt)')\n",
    "    ax1.set_ylabel('Acceptor score')\n",
    "    ax2.set_ylabel('Donor Score')\n",
    "    ax1.legend(prop={'size': 14})\n",
    "    ax2.legend(prop={'size': 14})\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def ceil_div(x, y):\n",
    "\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "\n",
    "IN_MAP = np.asarray([[0, 0, 0, 0],\n",
    "                     [1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def one_hot_encode(Xd):\n",
    "\n",
    "    return IN_MAP[Xd.astype('int8')]\n",
    "\n",
    "def reformat_data(X0):\n",
    "    # This function converts X0, Y0 of the create_datapoints function into\n",
    "    # blocks such that the data is broken down into data points where the\n",
    "    # input is a sequence of length SL+CL_max corresponding to SL nucleotides\n",
    "    # of interest and CL_max context nucleotides, the output is a sequence of\n",
    "    # length SL corresponding to the splicing information of the nucleotides\n",
    "    # of interest. The CL_max context nucleotides are such that they are\n",
    "    # CL_max/2 on either side of the SL nucleotides of interest.\n",
    "\n",
    "    num_points = ceil_div(len(X0)-CL_max, SL)\n",
    "\n",
    "    Xd = np.zeros((num_points, SL+CL_max))\n",
    "    X0 = np.pad(X0, [0, SL], 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(num_points):\n",
    "        Xd[i] = X0[SL*i:CL_max+SL*(i+1)]\n",
    "\n",
    "    return Xd\n",
    "\n",
    "def seqToArray(seq,strand):\n",
    "    #seq = 'N'*(CL_max//2) + seq + 'N'*(CL_max//2)\n",
    "    seq = seq.upper()\n",
    "    seq = re.sub(r'[^AGTC]', '0',seq)\n",
    "    seq = seq.replace('A', '1').replace('C', '2')\n",
    "    seq = seq.replace('G', '3').replace('T', '4').replace('N', '0')\n",
    "    if strand == '+':\n",
    "        X0 = np.asarray([int(x) for x in seq])\n",
    "            \n",
    "    elif strand == '-':\n",
    "        X0 = (5-np.asarray([int(x) for x in seq[::-1]])) % 5  # Reverse complement\n",
    "        \n",
    "    Xd = reformat_data(X0)\n",
    "    return  one_hot_encode(Xd)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in tqdm(range(mutant_snv.shape[0])):\n",
    "    try:\n",
    "        category,chrm,strand,pos,ref_s,alt_s,transcript_id,event_id = mutant_snv.iloc[i,:][['category','chr','strand','snp_position_hg38_0based_start','ref_allele', 'alt_allele','ensembl_transcript_id','internal_id']]\n",
    "        pos = int(pos)+1\n",
    "        chrm = f'chr{chrm}'\n",
    "        gene_start = gtf[transcript_id].start\n",
    "        gene_end = gtf[transcript_id].end\n",
    "        start,end = np.max([pos-CL_max//2-2500+1,gene_start]),np.min([pos+2500+CL_max//2,gene_end])\n",
    "        chrm_length = len(fasta[chrm])\n",
    "        if start < 1:\n",
    "            start = 1\n",
    "        if end >chrm_length:\n",
    "            end = chrm_length\n",
    "\n",
    "        pos_s = pos-start\n",
    "\n",
    "        ref = fasta[chrm][start-1:end].seq\n",
    "        alt = ref\n",
    "        ref_len = len(ref_s)\n",
    "        alt_len = len(alt_s)\n",
    "        #print(strand)\n",
    "        #print(ref_s,ref[pos_s:(pos_s+ref_len)])\n",
    "        assert ref_s == ref[pos_s:(pos_s+ref_len)]\n",
    "        alt = alt[:pos_s]+alt_s+alt[(pos_s+ref_len):]\n",
    "        alt_align = np.arange(len(ref))\n",
    "        alt_align = np.concatenate([alt_align[:pos_s],np.repeat(pos_s,alt_len),alt_align[pos_s+ref_len:]])\n",
    "\n",
    "        ref = 'N'*(CL_max//2+2500-1-(pos-start))+ref+(CL_max//2+2500-(end-pos))*'N'\n",
    "        alt = 'N'*(CL_max//2+2500-1-(pos-start))+alt+(CL_max//2+2500-(end-pos))*'N'\n",
    "        assert len(ref)==45000\n",
    "        ref_len2 = len(ref)\n",
    "        alt_len2 = len(alt)\n",
    "\n",
    "        ref = seqToArray(ref,strand)\n",
    "        alt = seqToArray(alt,strand)\n",
    "\n",
    "        ref_prediction = predictSplicing(ref,models)[0,:,:]\n",
    "        alt_prediction = predictSplicing(alt,models)[0,:,:]\n",
    "\n",
    "        #tmp = np.zeros_like(ref_prediction)\n",
    "        if strand=='-':\n",
    "            ref_prediction = ref_prediction[:,::-1]\n",
    "            alt_prediction = alt_prediction[:,::-1]\n",
    "\n",
    "        ref_acceptor = ref_prediction[1,:]\n",
    "        alt_acceptor = alt_prediction[1,:]\n",
    "        ref_donor = ref_prediction[2,:]\n",
    "        alt_donor = alt_prediction[2,:]\n",
    "\n",
    "        #delta_1_a = alt_acceptor[:pos_s]-ref_acceptor[:pos_s]\n",
    "        #delta_1_d = alt_donor[:pos_s]-ref_donor[:pos_s]\n",
    "        #delta_3_a = alt_acceptor[pos_s+alt_len:]-ref_acceptor[pos_s+ref_len:]\n",
    "        #delta_3_d = alt_donor[pos_s+alt_len:]-ref_donor[pos_s+ref_len:]\n",
    "\n",
    "        #if ref_len2==alt_len2:\n",
    "        #    delta_2_a = alt_acceptor[pos_s:pos_s+ref_len]-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "        #    delta_2_d = alt_donor[pos_s:pos_s+ref_len]-ref_donor[pos_s:pos_s+ref_len]\n",
    "        #elif ref_len2>alt_len2:\n",
    "        #    a_pad = np.pad(alt_acceptor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "        #    d_pad = np.pad(alt_donor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "        #    delta_2_a = a_pad-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "        #    delta_2_d = d_pad-ref_donor[pos_s:pos_s+ref_len]\n",
    "\n",
    "       # elif ref_len2<alt_len2:\n",
    "       #     a_pad = np.pad(ref_acceptor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "       #     d_pad = np.pad(ref_donor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "       #     delta_2_a = alt_acceptor[pos_s:pos_s+alt_len]-a_pad\n",
    "       #     delta_2_d = alt_donor[pos_s:pos_s+alt_len]-d_pad\n",
    "\n",
    "       #     delta_2_a =np.append(delta_2_a[:ref_len-1],delta_2_a[np.argmax(np.absolute(delta_2_a[ref_len-1:alt_len]))])\n",
    "       #     delta_2_d =np.append(delta_2_d[:ref_len-1],delta_2_d[np.argmax(np.absolute(delta_2_d[ref_len-1:alt_len]))])\n",
    "\n",
    "        #acceptorDelta = np.concatenate([delta_1_a,delta_2_a,delta_3_a])\n",
    "        #donorDelta = np.concatenate([delta_1_d,delta_2_d,delta_3_d])\n",
    "        acceptorDelta = alt_acceptor-ref_acceptor\n",
    "        donorDelta = alt_donor-ref_donor\n",
    "        top_a_creation_pos = np.argmax(acceptorDelta)\n",
    "        top_d_creation_pos = np.argmax(donorDelta)\n",
    "        top_a_disruption_pos = np.argmin(acceptorDelta)\n",
    "        top_d_disruption_pos = np.argmin(donorDelta)\n",
    "        top_a_creation_delta = acceptorDelta[top_a_creation_pos]\n",
    "        top_d_creation_delta = donorDelta[top_d_creation_pos]\n",
    "        top_a_disruption_delta = acceptorDelta[top_a_disruption_pos]\n",
    "        top_d_disruption_delta = donorDelta[top_d_disruption_pos]\n",
    "\n",
    "        results[event_id] = [gene_start,gene_end,top_a_creation_pos,top_d_creation_pos,top_a_disruption_pos,top_d_disruption_pos,top_a_creation_delta,top_d_creation_delta,-top_a_disruption_delta,-top_d_disruption_delta]\n",
    "    except:\n",
    "        print('{} failed'.format(event_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/mfas_transformer_gtex_210423.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/no_sqtl_deltas_transformer_gtex_130223.pkl', 'rb') as f:\n",
    "#    results1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/mfas_transformer_gtex_130323.pkl', 'rb') as f:\n",
    "#    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).T\n",
    "df.columns = ['gene_start','gene_end','top_a_creation_pos','top_d_creation_pos','top_a_disruption_pos','top_d_disruption_pos','top_a_creation_delta','top_d_creation_delta','top_a_disruption_delta','top_d_disruption_delta']\n",
    "df.index.name = 'internal_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = snv_list.merge(df,on='internal_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['is_sdv']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = results[['is_sdv','top_d_disruption_delta','top_a_disruption_delta']].dropna()\n",
    "X,y = tmp[['top_d_disruption_delta','top_a_disruption_delta','top_d_disruption_delta','top_a_disruption_delta']].max(axis=1),tmp['is_sdv'].astype(int)\n",
    "fpr1, tpr1,t1 = roc_curve(y, X)\n",
    "auc_1 = auc(fpr1, tpr1)\n",
    "\n",
    "#aucs_1.append(auc_1)\n",
    "plt.plot(fpr1, tpr1,label=f\"Transformer-40k (AUC = {auc_1 :.3f})\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "#plt.savefig('../Results/mafs_transformer_auc.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results['dpsi'],results[['top_d_disruption_delta','top_a_disruption_delta']].max(axis=1),s=1)\n",
    "plt.ylabel('Transformer disruption delta score')\n",
    "plt.xlabel('$\\Delta$psi')\n",
    "#plt.savefig('../Results/mafs_dpsi_correlation.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['fp'] = np.all([results['dpsi']>-0.2,results[['top_d_disruption_delta','top_a_disruption_delta']].max(axis=1)>0.5],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher = np.argmax(results[['top_d_disruption_delta','top_a_disruption_delta']].values,axis=1)\n",
    "cond = [[x==0,x==1] for x in higher]\n",
    "results['max_pos'] = results[['top_d_disruption_pos','top_a_disruption_pos']].values[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['splice_dist'] = np.abs(results['max_pos']-2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = results['fp']==False\n",
    "plt.scatter(results['splice_dist'][cond],results['dpsi'][cond],s=1,c=results[['top_d_disruption_delta','top_a_disruption_delta']].max(axis=1)[cond], norm=colors.LogNorm())\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Transformer delta score', rotation=270, labelpad=15)\n",
    "cond = results['fp']==True\n",
    "plt.scatter(results['splice_dist'][cond],results['dpsi'][cond],c='red',s=10,label='False positives')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Predicted Distance of Disrupted Site from variant')\n",
    "plt.ylabel('$\\Delta$psi')\n",
    "#plt.savefig('../Results/mafs_predicted_distance_vs_dpsi.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall,t1 = precision_recall_curve(y, X)\n",
    "auc_1 = average_precision_score(y, X)\n",
    "\n",
    "#aucs_1.append(auc_1)\n",
    "plt.plot(recall,precision,label=f\"Transformer-40k (PR-AUC = {auc_1 :.3f})\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "#plt.savefig('../Results/mafs_prc.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
