{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "#from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "\n",
    "#from src.train import trainModel\n",
    "from src.dataloader import getData,spliceDataset,h5pyDataset,getDataPointList,getDataPointListFull,DataPoint\n",
    "#from src.weight_init import keras_init\n",
    "#rom src.losses import categorical_crossentropy_2d\n",
    "#rom src.models import SpliceAI_10K\n",
    "#from src.evaluation_metrics import print_topl_statistics\n",
    "import copy\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 10 11:44:23 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:5E:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    32W / 250W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA Tesla V1...  Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    32W / 250W |      0MiB / 32510MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setType = 'all'\n",
    "#annotation, transcriptToLabel, seqData = getData(data_dir, setType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 8\n",
    "k = 2\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = k*6*N_GPUS\n",
    "\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL=5000\n",
    "CL_max=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_sQTL = pd.read_csv('/odinn/data/dataprocessing/rnasplice-blood/curry/sQTL_summary/lead_sQTL.gor', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 257372/257372 [01:51<00:00, 2315.79it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/gene_boundries.pkl', 'rb') as f:\n",
    "    gene_boundries = pickle.load(f)\n",
    "    \n",
    "def unionBoundry(names,gene_boundries):\n",
    "    for i,name in enumerate(names):\n",
    "        if i==0:\n",
    "            gene_start,gene_end = gene_boundries[name]\n",
    "        else:\n",
    "            start,end = gene_boundries[name]\n",
    "            gene_start,gene_end = np.min([gene_start,start]),np.max([gene_end,end])\n",
    "    return gene_start,gene_end\n",
    "inside_gene = []\n",
    "\n",
    "for i in tqdm(range(lead_sQTL.shape[0])):\n",
    "    gene,chrm,strand,pos,jn_start,jn_end,ref_s,alt_s,event_id = lead_sQTL.iloc[i,:][['Gene_name','Chrom','Strand','Pos','Startx','End','REF','ALT','splice_event_id']]\n",
    "    names = gene.split(',')\n",
    "    gene_start,gene_end = unionBoundry(names,gene_boundries)\n",
    "    inside_gene.append(gene_start <= pos <= gene_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16091\n",
      "0.05/146407\n"
     ]
    }
   ],
   "source": [
    "#lead_sQTL = lead_sQTL[lead_sQTL['Max_Consequence']!='intergenic_variant']\n",
    "#lead_sQTL = lead_sQTL[lead_sQTL['Pos_bin']!='distant_downstream']\n",
    "#lead_sQTL = lead_sQTL[lead_sQTL['Pos_bin']!='distant_upstream']\n",
    "lead_sQTL = lead_sQTL[inside_gene]\n",
    "print(np.sum(lead_sQTL['REF']==lead_sQTL['ALT']))\n",
    "lead_sQTL = lead_sQTL[lead_sQTL['REF']!=lead_sQTL['ALT']]\n",
    "print(f'{0.05}/{lead_sQTL.shape[0]}')\n",
    "lead_sQTL = lead_sQTL[lead_sQTL['Pval']<=0.05/lead_sQTL.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfastx\n",
    "data_dir = '../Data/'\n",
    "fasta_file_path = '../Data/genome.fa'\n",
    "gtf_file_path = '../Data/Homo_sapiens.GRCh38.87.gtf'\n",
    "fasta = pyfastx.Fasta(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 11:46:16.931077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv1D, Cropping1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import add\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "def ResidualUnit(l, w, ar):\n",
    "    # Residual unit proposed in \"Identity mappings in Deep Residual Networks\"\n",
    "    # by He et al.\n",
    "\n",
    "    def f(input_node):\n",
    "\n",
    "        bn1 = BatchNormalization()(input_node)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv1D(l, [w], dilation_rate=[ar], padding='same')(act1)\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv1D(l, [w], dilation_rate=[ar], padding='same')(act2)\n",
    "        output_node = add([conv2, input_node])\n",
    "\n",
    "        return output_node\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def SpliceAI(L, W, AR):\n",
    "    # L: Number of convolution kernels\n",
    "    # W: Convolution window size in each residual unit\n",
    "    # AR: Atrous rate in each residual unit\n",
    "\n",
    "    assert len(W) == len(AR)\n",
    "\n",
    "    CL = 2 * np.sum(AR*(W-1))\n",
    "\n",
    "    input0 = Input(shape=(None, 4))\n",
    "    conv = Conv1D(L, 1)(input0)\n",
    "    skip = Conv1D(L, 1)(conv)\n",
    "\n",
    "    for i in range(len(W)):\n",
    "        conv = ResidualUnit(L, W[i], AR[i])(conv)\n",
    "        \n",
    "        if (((i+1) % 4 == 0) or ((i+1) == len(W))):\n",
    "            # Skip connections to the output after every 4 residual units\n",
    "            dense = Conv1D(L, 1)(conv)\n",
    "            skip = add([skip, dense])\n",
    "\n",
    "    skip = Cropping1D(int(CL/2))(skip)\n",
    "\n",
    "    output0 = [[] for t in range(1)]\n",
    "\n",
    "    for t in range(1):\n",
    "        output0[t] = Conv1D(3, 1, activation='softmax')(skip)\n",
    "    \n",
    "    model = Model(inputs=input0, outputs=output0)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_crossentropy_2d(y_true, y_pred):\n",
    "    # Standard categorical cross entropy for sequence outputs\n",
    "    weights = [3.33445928e-01, 1.97431150e+03, 1.97432843e+03]\n",
    "    return - kb.mean(weights[0]*y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + weights[1]*y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10)\n",
    "                   + weights[2]*y_true[:, :, 2]*kb.log(y_pred[:, :, 2]+1e-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 11:46:19.830650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-10 11:46:21.451488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:5e:00.0\n",
      "2023-01-10 11:46:21.452409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 1 with properties: \n",
      "name: NVIDIA Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2023-01-10 11:46:21.452468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-10 11:46:21.458763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-10 11:46:21.461125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-10 11:46:21.461835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-10 11:46:21.462357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-10 11:46:21.463296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-10 11:46:21.463459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-10 11:46:21.466822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0, 1\n",
      "2023-01-10 11:46:21.475660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2023-01-10 11:46:21.479081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xccd9a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-10 11:46:21.479102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-01-10 11:46:21.627382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc5dc620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-10 11:46:21.627421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-01-10 11:46:21.627430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-01-10 11:46:21.630660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:5e:00.0\n",
      "2023-01-10 11:46:21.631557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 1 with properties: \n",
      "name: NVIDIA Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:86:00.0\n",
      "2023-01-10 11:46:21.631621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-10 11:46:21.631637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-10 11:46:21.631647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-10 11:46:21.631658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-10 11:46:21.631668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-10 11:46:21.631678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-10 11:46:21.631688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-10 11:46:21.634936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0, 1\n",
      "2023-01-10 11:46:21.634997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-10 11:46:22.211061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-10 11:46:22.211130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1 \n",
      "2023-01-10 11:46:22.211138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N Y \n",
      "2023-01-10 11:46:22.211142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   Y N \n",
      "2023-01-10 11:46:22.213971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31013 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0)\n",
      "2023-01-10 11:46:22.215430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 31013 MB memory) -> physical GPU (device: 1, name: NVIDIA Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import resource_filename\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "models = []\n",
    "n_models = 5\n",
    "\n",
    "paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "models = [load_model(resource_filename('spliceai', x)) for x in paths]\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_boundries = {}\n",
    "#for gene in tqdm(genes):\n",
    "#    gene_boundries[gene[\"gene_name\"][0]] = [int(gene[3]),int(gene[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/gene_boundries.pkl', 'wb') as f:\n",
    "#    pickle.dump(gene_boundries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                              | 0/80999 [00:00<?, ?it/s]2023-01-10 11:46:41.654426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-10 11:46:42.824848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "  2%|████▎                                                                                                                                                                                            | 1806/80999 [15:02<8:26:29,  2.61it/s]"
     ]
    }
   ],
   "source": [
    "def predictSplicing(seq,models):\n",
    "    outputs = []\n",
    "    for i in range(seq.shape[0]):\n",
    "        Xc = torch.tensor(seq[i,:,:], device=device).float().unsqueeze(0).numpy()\n",
    "        #Xc = torch.swapaxes(batch_features,1,2)\n",
    "        predictions = []\n",
    "        for v in range(n_models):\n",
    "            Yp = models[v].predict(Xc, batch_size=1)\n",
    "            predictions.append(Yp)\n",
    "        predictions = (predictions[0]+predictions[1]+predictions[2]+predictions[3]+predictions[4])/n_models\n",
    "        outputs.append(np.swapaxes(predictions,1,2))\n",
    "    \n",
    "    outputs = np.concatenate(outputs,axis=2)\n",
    "    #outputs = outputs.cpu().detach().numpy()\n",
    "    return outputs\n",
    "\n",
    "def plotPrediction(outputs):\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1,figsize=(22, 6),sharex=True)\n",
    "    x = np.arange(outputs.shape[2])\n",
    "    ax1.plot(x,outputs[0,1,:],linewidth=2,zorder=-32)\n",
    "    ax2.plot(x,outputs[0,2,:],linewidth=2,zorder=-32)\n",
    "    plt.xlabel('Distance from transcript start (nt)')\n",
    "    ax1.set_ylabel('Acceptor score')\n",
    "    ax2.set_ylabel('Donor Score')\n",
    "    ax1.legend(prop={'size': 14})\n",
    "    ax2.legend(prop={'size': 14})\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def ceil_div(x, y):\n",
    "\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "\n",
    "IN_MAP = np.asarray([[0, 0, 0, 0],\n",
    "                     [1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def one_hot_encode(Xd):\n",
    "\n",
    "    return IN_MAP[Xd.astype('int8')]\n",
    "\n",
    "def reformat_data(X0):\n",
    "    # This function converts X0, Y0 of the create_datapoints function into\n",
    "    # blocks such that the data is broken down into data points where the\n",
    "    # input is a sequence of length SL+CL_max corresponding to SL nucleotides\n",
    "    # of interest and CL_max context nucleotides, the output is a sequence of\n",
    "    # length SL corresponding to the splicing information of the nucleotides\n",
    "    # of interest. The CL_max context nucleotides are such that they are\n",
    "    # CL_max/2 on either side of the SL nucleotides of interest.\n",
    "\n",
    "    num_points = ceil_div(len(X0)-CL_max, SL)\n",
    "    Xd = np.zeros((num_points, SL+CL_max))\n",
    "    X0 = np.pad(X0, [0, SL], 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(num_points):\n",
    "        Xd[i] = X0[SL*i:CL_max+SL*(i+1)]\n",
    "\n",
    "    return Xd\n",
    "\n",
    "def seqToArray(seq,strand):\n",
    "    seq = 'N'*(CL_max//2) + seq + 'N'*(CL_max//2)\n",
    "    seq = seq.upper()\n",
    "    seq = re.sub(r'[^AGTC]', '0',seq)\n",
    "    seq = seq.replace('A', '1').replace('C', '2')\n",
    "    seq = seq.replace('G', '3').replace('T', '4').replace('N', '0')\n",
    "    if strand == '+':\n",
    "        X0 = np.asarray([int(x) for x in seq])\n",
    "            \n",
    "    elif strand == '-':\n",
    "        X0 = (5-np.asarray([int(x) for x in seq[::-1]])) % 5  # Reverse complement\n",
    "        \n",
    "    Xd = reformat_data(X0)\n",
    "    return  one_hot_encode(Xd)\n",
    "    \n",
    "#acceptorDeltas = []\n",
    "#donorDeltas = []\n",
    "results = {}\n",
    "#markers = lead_sQTL['Name'].drop_duplicates().values\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(lead_sQTL.shape[0])):\n",
    "    gene,chrm,strand,pos,jn_start,jn_end,ref_s,alt_s,event_id = lead_sQTL.iloc[i,:][['Gene_name','Chrom','Strand','Pos','Startx','End','REF','ALT','splice_event_id']]\n",
    "    names = gene.split(',')\n",
    "    gene_start,gene_end = unionBoundry(names,gene_boundries)\n",
    "    starts,ends = [],[]\n",
    "    if pos<jn_start:\n",
    "        start,end = np.max([pos-CL_max//2,gene_start]),np.min([jn_end+CL_max//2,gene_end])\n",
    "    elif jn_start<=pos<jn_end:\n",
    "        start,end = np.max([jn_start-CL_max//2,gene_start]),np.min([jn_end+CL_max//2,gene_end])\n",
    "    else:\n",
    "        start,end = np.max([jn_start-CL_max//2,gene_start]),np.min([pos+CL_max//2,gene_end])\n",
    "    if start < 1:\n",
    "        start = 1\n",
    "    #for name in names:\n",
    "    #    tmp = gene_boundries[name]\n",
    "    #    starts.append(tmp[0])\n",
    "    #    ends.append(tmp[1])\n",
    "\n",
    "    #gene_start,gene_end = np.min(starts),np.max(ends)\n",
    "\n",
    "     #= df_gene[].iloc[0]\n",
    "    #start,end = np.max([pos-CL_max//2,gene_start]),np.min([pos+CL_max//2,gene_end])\n",
    "\n",
    "    #if strand=='-':\n",
    "    #    starts,ends = [],[]\n",
    "    #    for i in range(df_gene.shape[0]):\n",
    "    #        starts.append(pos+df_gene['acceptor'].iloc[i]-CL_max//2)\n",
    "    #        ends.append(pos+df_gene['donor'].iloc[i]+CL_max//2)\n",
    "    #    start2,end2 = np.min(starts),np.max(ends)\n",
    "    #    start = np.min([start,start2])\n",
    "    #    end = np.max([end,end2])\n",
    "    #else:\n",
    "    #    starts,ends = [],[]\n",
    "    #    for i in range(df_gene.shape[0]):\n",
    "    #        starts.append(pos-df_gene['donor'].iloc[i]-CL_max//2)\n",
    "    #        ends.append(pos-df_gene['acceptor'].iloc[i]+CL_max//2)\n",
    "    #    start2,end2 = np.min(starts),np.max(ends)\n",
    "    #    start = np.min([start,start2])\n",
    "    #    end = np.max([end,end2])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        pos_s = pos-start\n",
    "        ref = fasta[chrm][start-1:end].seq\n",
    "        alt = ref\n",
    "        ref_len = len(ref_s)\n",
    "        alt_len = len(alt_s)\n",
    "        assert ref_s == ref[pos_s:(pos_s+ref_len)]\n",
    "        alt = alt[:pos_s]+alt_s+alt[(pos_s+ref_len):]\n",
    "        alt_align = np.arange(len(ref))\n",
    "        alt_align = np.concatenate([alt_align[:pos_s],np.repeat(pos_s,alt_len),alt_align[pos_s+ref_len:]])\n",
    "\n",
    "        ref_len2 = len(ref)\n",
    "        alt_len2 = len(alt)\n",
    "\n",
    "        ref = seqToArray(ref,strand)\n",
    "        alt = seqToArray(alt,strand)\n",
    "\n",
    "        ref_prediction = predictSplicing(ref,models)[0,:,:ref_len2]\n",
    "        alt_prediction = predictSplicing(alt,models)[0,:,:alt_len2]\n",
    "\n",
    "        tmp = np.zeros_like(ref_prediction)\n",
    "        if strand=='-':\n",
    "            ref_prediction = ref_prediction[:,::-1]\n",
    "            alt_prediction = alt_prediction[:,::-1]\n",
    "\n",
    "        ref_acceptor = ref_prediction[1,:]\n",
    "        alt_acceptor = alt_prediction[1,:]\n",
    "        ref_donor = ref_prediction[2,:]\n",
    "        alt_donor = alt_prediction[2,:]\n",
    "\n",
    "        delta_1_a = alt_acceptor[:pos_s]-ref_acceptor[:pos_s]\n",
    "        delta_1_d = alt_donor[:pos_s]-ref_donor[:pos_s]\n",
    "        delta_3_a = alt_acceptor[pos_s+alt_len:]-ref_acceptor[pos_s+ref_len:]\n",
    "        delta_3_d = alt_donor[pos_s+alt_len:]-ref_donor[pos_s+ref_len:]\n",
    "\n",
    "\n",
    "        if ref_len2==alt_len2:\n",
    "            delta_2_a = alt_acceptor[pos_s:pos_s+ref_len]-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "            delta_2_d = alt_donor[pos_s:pos_s+ref_len]-ref_donor[pos_s:pos_s+ref_len]\n",
    "        elif ref_len2>alt_len2:\n",
    "            a_pad = np.pad(alt_acceptor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "            d_pad = np.pad(alt_donor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "            delta_2_a = a_pad-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "            delta_2_d = d_pad-ref_donor[pos_s:pos_s+ref_len]\n",
    "\n",
    "        elif ref_len2<alt_len2:\n",
    "            a_pad = np.pad(ref_acceptor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "            d_pad = np.pad(ref_donor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "            delta_2_a = alt_acceptor[pos_s:pos_s+alt_len]-a_pad\n",
    "            delta_2_d = alt_donor[pos_s:pos_s+alt_len]-d_pad\n",
    "\n",
    "            delta_2_a =np.append(delta_2_a[:ref_len-1],delta_2_a[np.argmax(np.absolute(delta_2_a[ref_len-1:alt_len]))])\n",
    "            delta_2_d =np.append(delta_2_d[:ref_len-1],delta_2_d[np.argmax(np.absolute(delta_2_d[ref_len-1:alt_len]))])\n",
    "\n",
    "        acceptorDelta = np.concatenate([delta_1_a,delta_2_a,delta_3_a])\n",
    "        donorDelta = np.concatenate([delta_1_d,delta_2_d,delta_3_d])\n",
    "\n",
    "        if strand=='-':\n",
    "            acceptor_loc =jn_start-start\n",
    "            donor_loc = jn_end-start+1\n",
    "        else:\n",
    "            acceptor_loc = jn_end-start+1\n",
    "            donor_loc = jn_start-start\n",
    "\n",
    "        acceptor_delta_nr = alt_acceptor.shape[0]-np.argsort(np.argsort(np.absolute(acceptorDelta)))[acceptor_loc]\n",
    "        donor_delta_nr = alt_donor.shape[0]-np.argsort(np.argsort(np.absolute(donorDelta)))[donor_loc]\n",
    "        top_a_creation_pos = np.argmax(acceptorDelta)\n",
    "        top_d_creation_pos = np.argmax(donorDelta)\n",
    "        top_a_disruption_pos = np.argmin(acceptorDelta)\n",
    "        top_d_disruption_pos = np.argmin(donorDelta)\n",
    "        top_a_creation_delta = acceptorDelta[top_a_creation_pos]\n",
    "        top_d_creation_delta = donorDelta[top_d_creation_pos]\n",
    "        top_a_disruption_delta = acceptorDelta[top_a_disruption_pos]\n",
    "        top_d_disruption_delta = donorDelta[top_d_disruption_pos]\n",
    "\n",
    "        results[event_id] = [acceptorDelta[acceptor_loc],donorDelta[donor_loc],ref_acceptor[acceptor_loc],ref_donor[donor_loc],alt_acceptor[acceptor_loc],alt_donor[donor_loc],acceptor_delta_nr,donor_delta_nr,start+top_a_creation_pos,start+top_d_creation_pos,start+top_a_disruption_pos,start+top_d_disruption_pos,top_a_creation_delta,top_d_creation_delta,-top_a_disruption_delta,-top_d_disruption_delta]\n",
    "    except:\n",
    "        print('{} failed'.format(event_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/sqtl_deltas_splice_ai_pretrained_100123.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/sqtl_deltas_splice_ai_pretrained_100123.pkl', 'rb') as f:\n",
    "#    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).T\n",
    "df.columns = ['acceptor_delta','donor_delta','ref_acceptor','ref_donor','alt_acceptor','alt_donor','acceptor_delta_order','donor_delta_order','top_a_creation_pos','top_d_creation_pos','top_a_disruption_pos','top_d_disruption_pos','top_a_creation_delta','top_d_creation_delta','top_a_disruption_delta','top_d_disruption_delta']\n",
    "df.index.name = 'splice_event_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(np.sort(np.max(np.absolute(df[['acceptor_delta','donor_delta']]),axis=1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/sqtl_deltas_splice_ai_2.pkl', 'wb') as f:\n",
    "#    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06845360824742268"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.1\n",
    "df[np.any([np.absolute(df['acceptor_delta'])>t,np.absolute(df['acceptor_delta'])>t],axis=0)].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.merge(lead_sQTL[['splice_event_id','Strand','jct_prevalence','Pos_bin','REF','ALT']],on='splice_event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any([df['top_a_creation_delta']>t,df['top_d_creation_delta']>t,df['top_a_disruption_delta']>t,df['top_d_disruption_delta']>t],axis=0).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2764604810996564"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.1\n",
    "np.sum(np.any([df['top_a_creation_delta']>t,df['top_d_creation_delta']>t,df['top_a_disruption_delta']>t,df['top_d_disruption_delta']>t],axis=0))/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lead_sQTL.merge(df,on='splice_event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_anno = pd.read_csv('/nfs/odinn/users/gislih/RNA/requests/rna_paper/splice_anno/clover_snpindel_filtered_junctions_reannotated.01-12-2021.tsv.gz',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lead_sQTL.merge(variant_anno[['Name','variant_type']],on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "disrupting_variant = tmp[tmp['variant_type']=='disrupting']['splice_event_id'].values\n",
    "creating_variant = tmp[tmp['variant_type']=='creating']['splice_event_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372093023255814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disrupting = df[df.index.isin(disrupting_variant)]\n",
    "np.sum(np.max(disrupting[['top_a_disruption_delta','top_d_disruption_delta']],axis=1)>=0.1)/disrupting.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8124108416547788"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creating = df[df.index.isin(creating_variant)]\n",
    "np.sum(np.max(creating[['top_a_creation_delta','top_d_creation_delta']],axis=1)>=0.1)/creating.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
