{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 12 12:10:39 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:31:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    36W / 250W |      0MiB / 40960MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:98:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    36W / 250W |      0MiB / 40960MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA A100-PCI...  Off  | 00000000:CA:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    38W / 250W |      0MiB / 40960MiB |     30%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood/'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_rnasplice-blood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation_train,gene_to_label,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//4, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [21:38<00:00,  1.34s/it, a_r=0.55, d_r=0.577, loss=0.00104, r_a=0.99, r_d=0.991, r_loss=7.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 446/446 [04:10<00:00,  1.78it/s, a_r=0.557, d_r=0.579, loss=0.00173, r_a=0.99, r_d=0.991, r_loss=10.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9953\t0.6896\t0.8353\t0.917\t0.783\t0.9608\t0.2750\t0.0877\t0.0271\t11557\t16760.0\t16760\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9947\t0.7061\t0.8603\t0.9336\t0.8038\t0.9685\t0.2926\t0.0733\t0.0200\t11444\t16208.0\t16208\n",
      "epoch: 1/4, val loss = 0.001105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [19:51<00:00,  1.23s/it, a_r=0.561, d_r=0.595, loss=0.00101, r_a=0.991, r_d=0.993, r_loss=7.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.001003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 446/446 [04:20<00:00,  1.71it/s, a_r=0.56, d_r=0.574, loss=0.00175, r_a=0.991, r_d=0.993, r_loss=10.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9956\t0.694\t0.8397\t0.9214\t0.7874\t0.9434\t0.2949\t0.0779\t0.0201\t11632\t16760.0\t16760\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9951\t0.709\t0.8633\t0.9382\t0.8072\t0.9656\t0.2012\t0.0618\t0.0156\t11492\t16208.0\t16208\n",
      "epoch: 2/4, val loss = 0.001095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [20:04<00:00,  1.24s/it, a_r=0.565, d_r=0.591, loss=0.000959, r_a=0.992, r_d=0.994, r_loss=7.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 446/446 [04:29<00:00,  1.65it/s, a_r=0.552, d_r=0.571, loss=0.00171, r_a=0.992, r_d=0.994, r_loss=9.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9955\t0.6973\t0.8416\t0.9229\t0.7897\t0.9529\t0.2407\t0.0635\t0.0154\t11687\t16760.0\t16760\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9947\t0.7095\t0.8663\t0.9396\t0.8099\t0.9705\t0.2189\t0.0554\t0.0126\t11500\t16208.0\t16208\n",
      "epoch: 3/4, val loss = 0.001081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [20:03<00:00,  1.24s/it, a_r=0.566, d_r=0.592, loss=0.000954, r_a=0.992, r_d=0.993, r_loss=7.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████████| 446/446 [04:24<00:00,  1.69it/s, a_r=0.554, d_r=0.58, loss=0.00171, r_a=0.992, r_d=0.993, r_loss=10.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9955\t0.6953\t0.8415\t0.9236\t0.7896\t0.9494\t0.2381\t0.0709\t0.0181\t11654\t16760.0\t16760\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9944\t0.7093\t0.8667\t0.9408\t0.8099\t0.9748\t0.2907\t0.0815\t0.0183\t11496\t16208.0\t16208\n",
      "epoch: 4/4, val loss = 0.001076\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEGCAYAAACzYDhlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw60lEQVR4nO3deXhV1b3/8fc385xAEqaEEJDJMAZTnKpinUeEagvtbeXqr1Y7j1611qm1drCttdb2WrXaXiu1VhGrlDoWW0dQZBQJECWADIGEQEjIsH5/7J1wcjhAgJycIZ/X85wn++zprE30fLLWXnstc84hIiISTgmRLoCIiMQ/hY2IiISdwkZERMJOYSMiImGnsBERkbBLinQBolFBQYErLS2NdDFERGLKokWLtjnnCkNtU9iEUFpaysKFCyNdDBGRmGJmHxxom5rRREQk7BQ2IiISdgobEREJO92zEZG419zcTHV1NY2NjZEuSlxIS0ujuLiY5OTkLh+jsBGRuFddXU12djalpaWYWaSLE9Occ9TU1FBdXc3QoUO7fJya0UQk7jU2NpKfn6+g6QZmRn5+/mHXEhU2ItIrKGi6z5H8WypsutGO3Xu59enl1O1pjnRRRESiisKmG1Xv2MPDr1bx03+8F+miiEiUqKmpYeLEiUycOJEBAwZQVFTU8X7v3r0HPXbhwoV87Wtf66GShpc6CHSjccW5/PfJQ3ng3+uYVl5ERWnfSBdJRCIsPz+fxYsXA3DLLbeQlZXFd77znY7tLS0tJCWF/iquqKigoqKiJ4oZdqrZdLNvnTWSorx0rn9iKXtb2iJdHBGJQrNmzeLqq6/m+OOP59prr+XNN9/kxBNPpLy8nJNOOolVq1YB8PLLL3PhhRcCXlBdccUVTJkyhWHDhnH33XdH8hIOm2o23SwzNYkfXDKGKx5ayP/+aw1fPWNEpIskIgFufXo5Kzbu7NZzlg3K4eaLxhzWMdXV1bz66qskJiayc+dOXnnlFZKSknj++ee54YYb+Nvf/rbfMe+99x4vvfQS9fX1jBo1imuuueawnnWJJIVNGHxidH8uGD+QX79UyQXjBzKsMCvSRRKRKHPZZZeRmJgIQF1dHZdffjmrV6/GzGhuDt3J6IILLiA1NZXU1FT69evH5s2bKS4u7sliHzGFTZjcfFEZC97fyg1PLuXRL5ygbpciUeJwayDhkpmZ2bH8/e9/n9NPP50nn3ySqqoqpkyZEvKY1NTUjuXExERaWlrCXcxuo3s2YdIvO43rzzuW19du56+LqiNdHBGJYnV1dRQVFQHw0EMPRbYwYaKwCaMZHxtMxZA+/OjZlWzb1RTp4ohIlLr22mu5/vrrKS8vj6nayuEw51ykyxB1KioqXHdNnrZ6cz3n3/0KF4wbyF0zyrvlnCJyeFauXMmxxx4b6WLElVD/pma2yDkXsq+2ajZhNqJ/NtdMGc6cxRtZ8P7WSBdHRCQiFDY94EtTjmFYQSbfm7OUPXtbI10cEZEep7DpAWnJifxo+jjWb9/DXS+8H+niiIj0OIVNDzlhWD6fqijm/lfWdfsDZSIi0U5h04NuOP9Y8tKTuf6JJbS2qWOGiPQeCpselJeRwk0XlfFudR1/fK0q0sUREekxCpsedvGEQZw6spA7569iY+2eSBdHRHrA6aefzvz58zutu+uuu7jmmmtC7j9lyhTaH784//zzqa2t3W+fW265hTvvvPOgnztnzhxWrFjR8f6mm27i+eefP8zSdw+FTQ8zM26/ZCytznHTU8vRc04i8W/mzJnMnj2707rZs2czc+bMQx777LPPkpeXd0SfGxw2t912G2eeeeYRnetoKWwiYHDfDL555kieX7mZ+cs/inRxRCTMLr30Up555pmOydKqqqrYuHEjjz76KBUVFYwZM4abb7455LGlpaVs27YNgNtvv52RI0fy8Y9/vGMaAoDf//73fOxjH2PChAl88pOfpKGhgVdffZW5c+fy3e9+l4kTJ7JmzRpmzZrF448/DsALL7xAeXk548aN44orrqCpqanj826++WYmTZrEuHHjeO+97pkMUgNxRsiVHx/KU4s3ctNTyzlpeAE5abExTLhIzJt3HXy0tHvPOWAcnPfjA27u27cvkydPZt68eUydOpXZs2fzqU99ihtuuIG+ffvS2trKGWecwZIlSxg/fnzIcyxatIjZs2ezePFiWlpamDRpEscddxwA06dP5wtf+AIAN954Iw888ABf/epXufjii7nwwgu59NJLO52rsbGRWbNm8cILLzBy5Eg+//nP89vf/pZvfOMbABQUFPD2229z7733cuedd3L//fcf9T+RajYRkpSYwB3Tx7FtV5OmkRbpBQKb0tqb0B577DEmTZpEeXk5y5cv79TkFeyVV15h2rRpZGRkkJOTw8UXX9yxbdmyZZxyyimMGzeORx55hOXLlx+0LKtWrWLo0KGMHDkSgMsvv5wFCxZ0bJ8+fToAxx13HFVVVUd6yZ2oZhNBEwbncflJpTz0ahXTyos4boimkRYJu4PUQMJp6tSpfPOb3+Ttt9+moaGBvn37cuedd/LWW2/Rp08fZs2aRWNj4xGde9asWcyZM4cJEybw0EMP8fLLLx9VWdunMujOaQxUs4mwb589ioE5aZpGWiTOZWVlcfrpp3PFFVcwc+ZMdu7cSWZmJrm5uWzevJl58+Yd9PhTTz2VOXPmsGfPHurr63n66ac7ttXX1zNw4ECam5t55JFHOtZnZ2dTX1+/37lGjRpFVVUVlZWVAPzpT3/itNNO66YrDU1hE2FZqUncNnUs72/exe9fWRvp4ohIGM2cOZN3332XmTNnMmHCBMrLyxk9ejSf+cxnOPnkkw967KRJk/j0pz/NhAkTOO+88/jYxz7Wse0HP/gBxx9/PCeffDKjR4/uWD9jxgx+9rOfUV5ezpo1azrWp6Wl8Yc//IHLLruMcePGkZCQwNVXX939FxxAUwyE0J1TDHTVlx5ZxPMrtzD/G6cytCDz0AeISJdpioHupykGYtQtF40hNSmBG55YqmdvRCTuKGyiRL+cNP7n3NG8traGv729IdLFERHpVgqbKPKZySUcN6QPP3xmBTWaRlqkW6nFoPscyb+lwiaKJCQYd0wfx+6mFm5/ZmWkiyMSN9LS0qipqVHgdAPnHDU1NaSlpR3WcXrOJsqM7J/N1acdw69frGTapCJOGVEY6SKJxLzi4mKqq6vZulVTs3eHtLQ0iouLD+uYsPZGM7NzgV8BicD9zrkfB21PBf4IHAfUAJ92zlX5264HrgRaga855+b76x8ELgS2OOfGBpzrMuAW4FhgsnNuob++FFgJtA8k9Lpz7qB9/CLRGy1QY3Mr5/3qFVrbHPO/cSrpKYkRK4uISFdFpDeamSUCvwHOA8qAmWZWFrTblcAO59xw4JfAT/xjy4AZwBjgXOBe/3wAD/nrgi0DpgMLQmxb45yb6L/C25m8G6QlJ3L7tLF8uL2Bu19cHeniiIgctXDes5kMVDrn1jrn9gKzgalB+0wFHvaXHwfOMDPz1892zjU559YBlf75cM4tALYHf5hzbqVzblXw+lh10jEFXHZcMfctWMvKTZpGWkRiWzjDpghYH/C+2l8Xch/nXAtQB+R38djDMdTM3jGzf5nZKaF2MLOrzGyhmS2MlnbdfdNIL9U00iIS03pDb7RNQIlzrhz4FvBnM8sJ3sk5d59zrsI5V1FYGB035ftkpvD9C8tYvL6W/3v9g0gXR0TkiIUzbDYAgwPeF/vrQu5jZklALl5Hga4c2yV+U1yNv7wIWAOMPJJzRcLUiYM4ZUQBP/3He2yq0zTSIhKbwhk2bwEjzGyomaXg3fCfG7TPXOByf/lS4EXndY+bC8wws1QzGwqMAN48kkKYWWF75wIzG+afK2ZGvPSmkR5Hq3Pc/NTB56gQEYlWYQsb/x7MV4D5eF2PH3POLTez28ysfdafB4B8M6vEa+K6zj92OfAYsAL4B/Bl51wrgJk9CrwGjDKzajO70l8/zcyqgROBZ8xsvv8ZpwJLzGwxXieEq51z+3UwiGYl+Rl848yR/HPFZv6xTNNIi0js0ajPIUT6OZtQmlvbuPie/7B9dxPPf+s0sjWNtIhEGY36HAeS/Wmkt9Q38bP5cdPDW0R6CYVNDJk4OI/LTyzlT69/wKIPdkS6OCIiXaawiTHfOWcUA3LSuOGJpTS3ahppEYkNCpsY0z6N9KrN9dy3IGY61YlIL6ewiUFnlfXnvLED+NULq6natjvSxREROSSFTYy65eIxpCYm8L05mkZaRKKfwiZG9c9J49rzRvOfyhqe0DTSIhLlFDYx7LOTS5hUkscPn1nB9t17I10cEZEDUtjEMG8a6fHUN7bww2dWRLo4IiIHpLCJcaMGeNNIP/H2Bv69elukiyMiEpLCJg585RPDKc3P4HtzltLY3Brp4oiI7EdhEwfSkhP50bRxfFDTwN0vaBppEYk+Cps4cdLwAj45yZtG+r2PNI20iEQXhU0c+d4Fx5KTnsx1f9M00iISXRQ2caRvZgrfv/BYFq+v5ZE3NI20iEQPhU2cuWRikT+N9Co+qmuMdHFERACFTdwxM354yViaW9u4ee6ySBdHRARQ2MSlIfmZfP3MEcxfvpn5yzWNtIhEnsImTn3hlGGMHpDNzU8tp76xOdLFEZFeTmETp9qnkd5c38idmkZaRCJMYRPHykv68PkThvDH1z/gnQ81jbSIRI7CJs5955xR9M9O43pNIy0iEaSwiXPZacncOnUM731Uz/2vrIt0cUSkl1LY9ALnjBnAOWP6c9fz7/NBjaaRFpGep7DpJW69eCzJiQl878llmkZaRHqcwqaXGJCbxrXnjuLflduYs1jTSItIz1LY9CKfPX4I5SV5/ODvKzWNtIj0KIVNL5KYYNwxfRw79zTzo2dXRro4ItKLKGx6mdEDcrjq1GE8vqiaVys1jbSI9AyFTS/0tTNGMCQ/gxue1DTSItIzFDa9UPs00lU1DdzzYmWkiyMivYDCppc6eXgB0ycV8bt/rWHVR/WRLo6IxLmkSBcgrtRVw8t3QGY/yOoPWe0//eXUbDCLdCk73HhBGS+9t4Xrn1jC41efREJC9JRNROKLwqY77d4KlS/C7i3Q1rL/9qS0/QMoqz9kFgat6wfJ6WEvbt/MFG68oIxv//VdHnnzQz53wpCwf6aI9E4Km+40qBy+vRLa2mDPDti12QueXVu85V2b9y1vXwcfvg4NB+gRlpoLWYVBNaT2cOrXOagSj/zXOH1SEU+8U81P573H2WX96Z+TdsTnEhE5EAvn0CVmdi7wKyARuN859+Og7anAH4HjgBrg0865Kn/b9cCVQCvwNefcfH/9g8CFwBbn3NiAc10G3AIcC0x2zi0M2BbyXAdSUVHhFi5ceLBduk9rM+zeti+Idm/pHEodP7dCU12IExhk5PthFBxO/nJ7s156H0jY/zZd1bbdnHPXAj4xuh+//a/jwn/NIhKXzGyRc64i1Law1WzMLBH4DXAWUA28ZWZznXMrAna7EtjhnBtuZjOAnwCfNrMyYAYwBhgEPG9mI51zrcBDwD14IRVoGTAd+N+gchzsXJGXmAw5A73XoTTv8cMnqKYUWHv68DVvuaVx/+MTkjrXivxwKs3qz6/Gt/HAOyv49+vNfHxiWdTdXxKR2BbOZrTJQKVzbi2Amc0GpgKBYTMVrzYC8Dhwj5mZv362c64JWGdmlf75XnPOLTCz0uAPc86t9D8neNMBz9UdF9mjktOhzxDvdTDOQdNOrzYU3HzXEU4fwUdLvPeulXOBc1OBf/ivpPT9m++y+oWuNSWr6U1EDi6cYVMErA94Xw0cf6B9nHMtZlYH5PvrXw86tugoynHIc5nZVcBVACUlJUf4UVHCDNJyvVfB8IPv29YGe7bDrs28v3Ytv/37q5xXmsDZJQTcX1rr1ZgaakKfIzX3EMHk/8woOKr7SyISu/R/vs85dx9wH3j3bCJcnJ6TkACZBZBZwMj+Y8jeMpQvvv4BT557MhMH53Xet7XZ63HXUVMKcX9p07vez72hnt0x/7NCBFFwrSm9j5rxROJIOMNmAzA44H2xvy7UPtVmlgTk4nUU6Mqx3VkO8X33nFHMX/4R1z+xlLlfOZnkxIAOBYnJkDPIex3K3oYD9MQLWFezxvvZ2rT/8QnJ+wIoM0TzXWBApWQpmESiXDjD5i1ghJkNxftynwF8JmifucDlePdPLgVedM45M5sL/NnMfoF3U38E8OYRlqM7zxX3stOSufXisVz9f4t44N/ruPq0Y47sRCkZkFIKfUoPvp9z0FgXUGMK7om3Beo3eTWm3VvAte1/juSMzgEU6qHa7AHeKyHxyK5HRI5K2MLGvwfzFWA+XtfnB51zy83sNmChc24u8ADwJ/+m/Xa8QMLf7zG8zgQtwJfbe4+Z2aPAFKDAzKqBm51zD5jZNODXQCHwjJktds6dc7BzSWjnjh3A2WXeNNLnjx1ISX5G+D7MDNLzvFfBiIPv29YKDdtDPL8UUHvaVglV//HuQwVLSPJqZbmDIbe48888fzklMxxXKdLrhfU5m1jVo8/ZRKlNdXs46xcLKC/J449XTA7Vyy+6teztfH+pfiPUrveGFKqrhrr1sHMjBP/dkd7HD6H2ICr2g8h/n9kv5LNKIhKh52wktg3MTee754zi5rnLeWrxRi4pP9LOgBGSlAK5Rd7rQFpbvC7gddV+EK3fF0Q71sG6Bft3dEhMgZwiP4RK9gVSR0AV9chQQyKxRmEjB/RfJwzhyXc28IO/r+C0kYX0yUyJdJG6V2LSvrAoOSH0PntqO9eG6gJqR2te8u4nEdQ6kFGwr1luv1pSiTfiQ6zVFEWOkprRQlAz2j4rN+3kol//m2nlRfzssgmRLk70aW32muMCa0XBzXXNDZ2PSUrb/55RR3NdsVdzSkqNzPWIHAU1o8kRO3ZgDl84dRi/fXkN0yYVcdIxBZEuUnRJTD74qA7OeYOytodRcHPd6n9695U6Ma8HXah7Ru0/9RySxBjVbEJQzaazxuZWzv7lAhITjHlfP4W0ZHUf7lYtTQE1ofbXh53fB491l5zZuTaUWwy5AfeQcgZ5QSjSg1SzkaOSlpzI7dPG8rkH3uQ3L1Xy7bNHRbpI8SUpFfKP8V6hOOeNDB58z6i9yW7j4v2nqrAEyB4Y1IEhqJt3Wm7YL02kncJGuuSUEYVMK/emkb5owiBG9s+OdJF6DzN/hO5CKJoUep+9DbBzQ1BznR9IG96GFXOhrbnzMak5B+7inVvshZUegpVuoma0ENSMFlrNribO+MW/OKYwi79+8URNIx1L2tq8B2HrqqH2Q0L2sNuzo/MxlhjQzfsAzXWpWZG5HolKakaTbpGflcqNF5Txnb++y5/f/JD/0jTSsSMhYd+QPcUhvwugadeBu3l/8JpXcwr5EGyInnXtzXV6CFZ8XQobM8sE9jjn2sxsJDAamOecaz7EoRJnPjmpiCferuYn897jLE0jHV9Ss6DfaO8VSlsr1H/UuTdde5Pdjg+8YYKCZ5NNSPYfrg0xKkNOkTeIanK6N0xQYop62MWxLjWjmdki4BSgD/AfvEE29zrnPhve4kWGmtEObp0/jfSZx/bj3s9qGmkJ0Fi3rzZUG9Sjrm699xBsqMFUwWu2S8n0wic5w1/O2BdGwcspGf66A+0bsE9Kpnrn9YDuaEYz51yDmV0J3Ouc+6mZLe62EkpMGVqQydc+MZw7//k+z6/YzJll/SNdJIkW7ZP29R8Tentrsxc4tX7w7N3ldW5o9l/7Le/2pkNv2O4t723w3jfvhraWwytbQpLXZbxTSIVYDhl4h9o3UxMDHkKXw8bMTgQ+C1zpr1M3lV7sqlOPYe67G7npqWWccEw+Wan6H026IDHZG7Inrxtmw23ZGzqY9u4+eHC1b29f3rvLG6w1eN8D1cAOeG0pXQ+mgwZe+/agfWO8Z2BXvyG+AVwPPOkP2T8MeClspZKol5KUwB3Tx3Pp717l5/9cxc0XHeAvWZFwSUrxXul53X9u56B17/7BtF+IhdgeuM/e3dC407vXFbxv8Jh6h5KYui+MktMPHkyBwbXfviG2J2eEvSNHl8LGOfcv4F8AZpYAbHPOfS2cBZPod9yQPnz2+BIefrWKSyYWMSF4GmmRWGXmPWyblAr07f7zO+eNCrFfcO0JCrGg4Oq03V9u2B66GfJwJaV7wVM2FS66q9svuau90f4MXA204nUOyDGzXznnftbtJZKYcu25o/nn8s1cF2oaaREJzcyvUaQD+d1//rY2L8w6BdPu0PfHgrcPHN/95aHrzWhlzrmdZvZZYB5wHbAIUNj0cjlpydx68RiueeRtHvz3Or54pNNIi0j3SUjwp2bPgMzoGDy3q3+GJptZMnAJMNd/vkZDDwjgTSN95rH9+eXz77N++xFU30Uk7nU1bP4XqAIygQVmNgTYGa5CSWwxM26bOoZEM743ZxkaAklEgnUpbJxzdzvnipxz5zvPB8DpYS6bxJBBeel855xRLHh/K3Pf3Rjp4ohIlOlS2JhZrpn9wswW+q+f49VyRDp8/sRSJhTnctvTK6ht2Bvp4ohIFOlqM9qDQD3wKf+1E/hDuAolsSkxwbhj+nhq9zTzo2dXRro4IhJFuho2xzjnbnbOrfVftwLDwlkwiU1lg3L4f6cM5bGF1by2pibSxRGRKNHVsNljZh9vf2NmJwN7wlMkiXXfOGMkg/um870nl9LY3HroA0Qk7nU1bK4GfmNmVWZWBdwDfDFspZKYlp6SyO2XjGPttt3c+/KaSBdHRKJAV3ujveucmwCMB8Y758qBT4S1ZBLTTh1ZyCUTB/HblytZvbk+0sURkQg7rLFFnHM7nXPtz9d8KwzlkThy44VlZKYmcf0TS2lr07M3Ir3Z0QxkpSn15KAKslK54fxjWfjBDma/tT7SxRGRCDqasNGfqnJIlx1XzAnD+nLHvJVs2dkY6eKISIQcNGzMrN7MdoZ41QODeqiMEsPMjB9NG0dTSxu3/n1FpIsjIhFy0LBxzmU753JCvLKdc5qaUbpkWGEWXz19OM8s2cQLKzdHujgiEgGafER6xBdPO4YR/bK46anl7G46zLnjRSTmKWykR3jTSI9jQ+0efvHc+5Eujoj0MIWN9JiK0r589vgS/vCfdSytrot0cUSkB4U1bMzsXDNbZWaVZnZdiO2pZvYXf/sbZlYasO16f/0qMzsnYP2DZrbFzJYFnauvmT1nZqv9n3389VPMrM7MFvuvm8J4yXII1547mvysVK57YgktrW2RLo6I9JCwhY2ZJQK/Ac4DyoCZZlYWtNuVwA7n3HDgl8BP/GPLgBnAGOBc4F7/fAAP+euCXQe84JwbAbzgv2/3inNuov+6rTuuT45Mbro3jfTyjTv5w3+qIl0cEekh4azZTAYq/VGi9wKzgalB+0wFHvaXHwfOMDPz1892zjU559YBlf75cM4tALaH+LzAcz2MN4W1RKHzxg7gjNH9+MVzmkZapLcIZ9gUAYGPjVf760Lu45xrAeqA/C4eG6y/c26Tv/wR0D9g24lm9q6ZzTOzMYd1FdLtzIzbLhmLGdyoaaRFeoW47CDgvG+v9m+wt4Eh/kCivwbmhDrGzK5qn4l069atPVPQXqwoL53vnD2Kf72/laeXbDr0ASIS08IZNhuAwQHvi/11IfcxsyQgF6jp4rHBNpvZQP9cA4Et0DF46C5/+Vkg2cwKgg92zt3nnKtwzlUUFhZ27QrlqFx+Uinji3O57enl1DU0R7o4IhJG4Qybt4ARZjbUzFLwbvjPDdpnLnC5v3wp8KJfK5kLzPB7qw0FRgBvHuLzAs91OfAUgJkN8O8DYWaT8a5ZU0hGgcQEbyibHQ3N3DFP00iLxLOwhY1/D+YrwHxgJfCYc265md1mZhf7uz0A5JtZJd6UBdf5xy4HHgNWAP8AvuycawUws0eB14BRZlZtZlf65/oxcJaZrQbO9N+DF2LLzOxd4G5ghtNNgqgxtiiXKz8+lNlvreeNtfobQCRemb5391dRUeEWLlwY6WL0Gg17Wzj7lwtISUpg3tdPITUp8dAHiUjUMbNFzrmKUNvisoOAxJaMlCR+eMlY1m7dzb0vaRppkXiksJGoMGVUPy6eMIh7X66kcoumkRaJNwobiRrfv7CMjJQkbnhimaaRFokzChuJGoXZqdxw/mjerNrOXxZqGmmReKKwkajyqYrBHD+0L3c8u5It9ZpGWiReKGwkqpgZP5o+jsbmNm57WtNIi8QLhY1EnWMKs/jy6cP5+5JNvPTelkgXR0S6gcJGotLVU4YxvF8WN85ZpmmkReKAwkaiUmpSYsc00r/UNNIiMU9hI1HrY6V9mTm5hAf/s45lGzSNtEgsU9hIVLvuPE0jLRIPFDYS1XLTk7n5ojKWbdjJQ69WRbo4InKEFDYS9S4YN5BPjO7Hz/+paaRFYpXCRqKemXHb1DGYwU1PaRppkViksJGYUNwng2+dNZKXVm3lmaWaRlok1ihsJGbMOqmUcUW53DJ3haaRFokxChuJGUmJCdwxfRzbdzfx439oGmmRWKKwkZjSPo30o2+u58112yNdHBHpIoWNxJxvnjWSorx0rn9iCU0trZEujoh0gcJGYk5GShI/nDaWNVt387uX10a6OCLSBQobiUmnj+rHRRMG8ZuXKqncsivSxRGRQ1DYSMy66cIy0pITuOHJpZpGWiTKKWwkZnnTSB/Lm+u289dFmkZaJJopbCSmfapiMJOH9uX2Z1aytb4p0sURkQNQ2EhMS0gwfjTNm0b6B3/XNNIi0UphIzFveL8svnT6Mcx9dyMvrdI00iLRSGEjceGaKcdwTGEmNz65jIa9mkZaJNoobCQupCYl8qNp3jTSdz2/OtLFEZEgChuJG8cPy2fm5MHc/8paTSMtEmUUNhJXrjv3WPpmpnL9E0s1jbRIFFHYSFzJzfCmkV66oY6HX/sg0sUREZ/CRuLOheMHMmVUIT//5yo21O6JdHFEBIWNxCEz4wdTx+IcfH+OppEWiQYKG4lLg/tm8O2zR/Lie1t4dulHkS6OSK+nsJG4NeukUsYW5XDL08up26NppEUiKaxhY2bnmtkqM6s0s+tCbE81s7/4298ws9KAbdf761eZ2TkB6x80sy1mtizoXH3N7DkzW+3/7OOvNzO72z/XEjObFMZLliiSlJjAHdPGU7Oric8/8Aa/fmE1r6zeys5GBY9IT0sK14nNLBH4DXAWUA28ZWZznXOBA1hdCexwzg03sxnAT4BPm1kZMAMYAwwCnjezkc65VuAh4B7gj0EfeR3wgnPux36wXQf8D3AeMMJ/HQ/81v8pvcC44lxunTqWh1+t4ufPvd+xfni/LCYOzqO8JI+Jg/MY1T+bpERV9EXCJWxhA0wGKp1zawHMbDYwFQgMm6nALf7y48A9Zmb++tnOuSZgnZlV+ud7zTm3ILAGFHSuKf7yw8DLeGEzFfij8+4Sv25meWY20Dm3qbsuVKLb504YwudOGELdnmaWVNfyzoe1LF5fy4vvbeHxRdUApCcnMq44l/KOAOrDgNy0CJdcJH6EM2yKgMBJRqrZv0bRsY9zrsXM6oB8f/3rQccWHeLz+gcEyEdA/4OUowjoFDZmdhVwFUBJSckhPkpiUW56MqeMKOSUEYUAOOf4cHsDi9d7AfTO+loe/M86mhd4vdcG5KR11HzKS/owriiX9JTESF6CSMwKZ9hEjHPOmdlh9Xd1zt0H3AdQUVGhvrK9gJkxJD+TIfmZTJ3o/S3T2NzKik07WeyHz+L1O5i3zOvNlphgjOqf3SmAhhVkkpBgkbwMkZgQzrDZAAwOeF/srwu1T7WZJQG5QE0Xjw22ub15zMwGAu1jzR/JuaSXSktOZFJJHyaV9OlYt21XE4v9prd31u9g7uKNPPLGhwBkpyV5wTM4j4l+81vfzJRIFV8kaoUzbN4CRpjZULwv9xnAZ4L2mQtcDrwGXAq86NdK5gJ/NrNf4HUQGAG8eYjPaz/Xj/2fTwWs/4p/z+h4oE73a+RwFGSlcmZZf84s81pm29oca7bu6mh6W7y+lnteqqTNrw8Pyc8ICKA+lA3MISVJnQ+kdwtb2Pj3YL4CzAcSgQedc8vN7DZgoXNuLvAA8Ce/A8B2vEDC3+8xvM4ELcCX/Z5omNmjeB0BCsysGrjZOfcAXsg8ZmZXAh8An/KL8ixwPlAJNAD/Ha5rlt4hIcEY0T+bEf2z+dTHvErz7qYWlm6o8zsf7OC1NTU8tXgjAClJCYwZlNPR9FY+OI/iPul4fWFEegfTUB77q6iocAsXLox0MSSGOefYVNfodz7YweL1tSzdUEdjszcSdUFWChMH77v3M744l+y05AiXWuTomNki51xFqG1x2UFAJNLMjEF56QzKS+f8cQMBaG5tY9VH9bwTEEDPr9zi7w8j/Gd/Jg7uQ3lJHiP7Z5OozgcSJ1SzCUE1G+kpdQ3NLK6u9Xu/eQFU2+CNcJCRksj44lwmDu7DxMF5TCrJo1+Onv2R6KWajUiUys1I5rSRhZw2ct+zPx/UNHjB43dAuP+VtbT4vQ8G5aZRXuKFz8SSPMYV5ZKWrGd/JPopbESiiJlRWpBJaUEm08qLAe/Zn+Ubd3Y0vb3zYS3PLPU6VCYlGKMHZlM+eF8ADc3Xsz8SfdSMFoKa0STaba1v6tT5YEl1HbuaWgBvpIQJgc/+FOfRR8/+SA84WDOawiYEhY3EmtY2R+WWXSxev6Nj7Lf3N9d3PPsztCCz08Cjowfo2R/pfgqbw6SwkXiwq6mFJdW1HU1vi9fXsrW+CfCe/RlXlNspgIry9OyPHB2FzWFS2Eg8cs6xsa7Ra3rzOx8s21BHU0v7sz+p+8Z9G5zH+MF5ZKXqtq50nXqjiQhmRlFeOkV56Vw4fhDgPfvz3qb6jt5vi9fX8tyKzf7+MLLfvoFHJ5bkMaKfnv2RI6OaTQiq2UhvVtuwt1PT2+L1tR3TamemJDK+OK9TAPXL1rM/4lHNRkS6LC8jhSmj+jFlVD/Aa35bt213pwC6b8G+Z3+K8tKZWJLXMfHcmEF69kf2p7ARkYMyM4YVZjGsMIvpk/Y9+7NsQ92+APqwlmeW7Hv2p6xj4FFv+J3S/Ax1Pujl1IwWgprRRA7flp2NHVMuvPPhDpZU19GwtxWAvIzkTgOPTizOIzdDA4/GGzWjiUjY9ctJ45wxAzhnzADAe/Zn9Zb6jprP4vW1/Ov91biAZ3+OKcxiWGEmQwu817CCTAqzU1ULikMKGxEJi8QEY/SAHEYPyGHm5BIA6hubWVpdxzvra1laXce6bbtZsHore/3u1+B1QigNCJ+hhZkMLchiaH6makMxTGEjIj0mOy2Zk4YXcNLwgo51rW2OTXV7WLdtN+u27WbtVu/nkuo6nl26qWMUBIC+mSkdtaDAMCrNz1SnhCinsBGRiEpMMIr7ZFDcJ4NTRhR22tbU0sr67e1BtKsjjBa8v5XHF1V32ndQbppfC/JqQsP8QCruk05SoobmiTSFjYhErdSkRIb3y2J4vyygf6dtu5paqPJrQx21om27mbt4IzsbWzr2S0owSvpm7KsRFbbXirLon6P7Qz1FYSMiMSkrNYmxRbmMLcrttN45x46GZtZt29XRJNf++s+abR1TcwOkJ3v3h4YFNM0NLfTe52VopOzupLARkbhiZvTNTKFvZl+OG9K307a2NsdHOxs7akHrtnrNc8s31vGP5R/RGnCDqE9GcueOCgVZDC3IpLQgg4wUfXUeLv2LiUivkZBgDMpLZ1BeOicHdFIAb5y49dsbOjXJrdu6m1cra3ji7Q2d9h2Ym0Zp/r5aUHutaHDfDJJ1fygkhY2ICJCcmNAxUkKwhr0tVG1r6OiosNYPpGeXbqK2obljv0T//lBpfoZXEwoIowE5ab16BlWFjYjIIWSkJFE2KIeyQTn7bduxey/ratqb5PbVil5fu509za0d+6UlJ3i1ocCu2/4zRH0ykuO+o4LCRkTkKPTJTKFPZgqTSvp0Wt/W5thc37ivg4IfRqs+que5FZs7BjIFbyrvwBAKfGXGyZxC8XEVIiJRJiHBGJibzsDcdE46Zv/7Q9U79lDVfm/If4bojbU1PPlO5/tD/XNSgwLI66hQ0jcjpqb2VtiIiPSw5MSEjvA4PWjbnr2tVNXsDggi7zV/+Wa2797bsV+CwWD/+aHS/MxOY8wNyk2PuvtDChsRkSiSnpLIsQNzOHbg/veHahv2sm7bbqr8e0TtYfTmuu0dI2wDpCbtuz/U8RyRH0b5mSkRuT+ksBERiRF5GSmUl6RQHnR/yDnHlvom1m71g8gf1mf1lnpeeG8zza377g9lpyV19JDb9xxRFqUFGWSnhW+gU4WNiEiMMzP656TRPyeNE4/J77StpbWNDbV7WLttd6fhfd6q2sFT724kcEqzwuxUpk4YxI0XlnV7GRU2IiJxLCkxgSH5mQzJz4RRnbc1NrfyQU2D30HB+zkwLz085QjLWUVEJOqlJScyakA2owZkh/2zYqffnIiIxCyFjYiIhJ3CRkREwk5hIyIiYRfWsDGzc81slZlVmtl1Ibanmtlf/O1vmFlpwLbr/fWrzOycQ53TzD5hZm+b2TIze9jMkvz1U8yszswW+6+bwnnNIiKyv7CFjZklAr8BzgPKgJlmFtx5+0pgh3NuOPBL4Cf+sWXADGAMcC5wr5klHuicZpYAPAzMcM6NBT4ALg/4nFeccxP9121humQRETmAcNZsJgOVzrm1zrm9wGxgatA+U/FCAuBx4AzzxlGYCsx2zjU559YBlf75DnTOfGCvc+59/1zPAZ8M47WJiMhhCGfYFAHrA95X++tC7uOcawHq8ILjQMceaP02IMnMKvz1lwKDA/Y70czeNbN5ZjYmVGHN7CozW2hmC7du3dr1qxQRkUOKi4c6nXPOzGYAvzSzVOCfQPuodG8DQ5xzu8zsfGAOMCLEOe4D7gMws61m9sFRFKkALwBjXbxcB+haolG8XAfoWtoNOdCGcIbNBjrXLor9daH2qfZv6OcCNYc4NuR659xrwCkAZnY2MNJfv7N9Z+fcs2Z2r5kVOOcO+I/pnCvs4jWGZGYLnXMVh94zusXLdYCuJRrFy3WArqUrwtmM9hYwwsyGmlkK3g3/uUH7zGXfjfxLgRedc85fP8PvrTYUryby5sHOaWb9/J+pwP8Av/PfD/DvA2Fmk/GuuSZM1ywiIiGErWbjnGsxs68A84FE4EHn3HIzuw1Y6JybCzwA/MnMKoHteOGBv99jwAqgBfiyc64VINQ5/Y/8rpldiBcmv3XOveivvxS4xsxagD14PdYCxjkVEZFwM33vdj8zu8q/BxTT4uU6QNcSjeLlOkDX0qXzKmxERCTcNFyNiIiEncJGRETCTmFzhI5m3Ldo04VrmeU/e9Q+vtz/i0Q5D8XMHjSzLWa27ADbzczu9q9ziZlN6ukydlUXriUmxvwzs8Fm9pKZrTCz5Wb29RD7xMTvpYvXEiu/lzQze9N/2H25md0aYp/u/Q5zzul1mC+8nnBrgGFACvAuUBa0z5eA3/nLM4C/RLrcR3Ets4B7Il3WLlzLqcAkYNkBtp8PzAMMOAF4I9JlPoprmQL8PdLl7MJ1DAQm+cvZwPsh/vuKid9LF68lVn4vBmT5y8nAG8AJQft063eYajZH5mjGfYs2XbmWmOCcW4DXhf5ApgJ/dJ7XgTwzG9gzpTs8XbiWmOCc2+Sce9tfrgdWsv+wVTHxe+nitcQE/996l/822X8F9xbr1u8whc2ROZpx36JNV64F4JN+E8fjZjY4xPZY0NVrjRWHHPMvmvjNMOV4f0UHirnfy0GuBWLk92LeSPqLgS3Ac865A/5euuM7TGEjXfE0UOqcG483ovbDh9hfwq99zL8JwK/xxvyLWmaWBfwN+IYLGEIqFh3iWmLm9+Kca3XOTcQb9muymY0N5+cpbI7M4Yz7hnUe9y3aHPJanHM1zrkm/+39wHE9VLbu1pXfW0xwzu1sbwZxzj0LJJtZQYSLFZKZJeN9OT/inHsixC4x83s51LXE0u+lnXOuFngJb+6wQN36HaawOTJHM+5btDnktQS1n1+M11Ydi+YCn/d7P50A1DnnNkW6UEfCYmTMP7+MDwArnXO/OMBuMfF76cq1xNDvpdDM8vzldOAs4L2g3br1Oywuphjoae4oxn2LNl28lq+Z2cV449Rtx+udFnXM7FG83kAFZlYN3Ix34xPn3O+AZ/F6PlUCDcB/R6akh9aFa4mVMf9OBj4HLPXvDwDcAJRAzP1eunItsfJ7GQg8bN7sxwnAY865v4fzO0zD1YiISNipGU1ERMJOYSMiImGnsBERkbBT2IiISNgpbEREJOwUNiIRYmatAaMDL7YQI24fxblLDzRitEgk6DkbkcjZ4w8XIhL3VLMRiTJmVmVmPzWzpf6cI8P99aVm9qI/IOoLZlbir+9vZk/6gz++a2Yn+adKNLPf+/OV/NN/UlwkIhQ2IpGTHtSM9umAbXXOuXHAPcBd/rpfAw/7A6I+Atztr78b+Jc/+OMkYLm/fgTwG+fcGKAW+GRYr0bkIDSCgEiEmNku51xWiPVVwCecc2v9gR8/cs7lm9k2YKBzrtlfv8k5V2BmW4HigMFS24fAf845N8J//z9AsnPuhz1waSL7Uc1GJDq5AywfjqaA5VZ0j1YiSGEjEp0+HfDzNX/5VfYNhvhZ4BV/+QXgGuiYECu3pwop0lX6S0ckctIDRg8G+Idzrr37cx8zW4JXO5npr/sq8Acz+y6wlX2jI38duM/MrsSrwVwDRN0Q/dK76Z6NSJTx79lUOOe2RbosIt1FzWgiIhJ2qtmIiEjYqWYjIiJhp7AREZGwU9iIiEjYKWxERCTsFDYiIhJ2/x/MxS36wt/5TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████| 972/972 [20:02<00:00,  1.24s/it, a_r=0.557, d_r=0.587, loss=0.00104, r_a=0.987, r_d=0.991, r_loss=7.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4:  78%|█████████████████████████████████████████████████████████████▊                 | 760/972 [15:43<04:23,  1.24s/it, a_r=0.557, d_r=0.588, loss=0.00102, r_a=0.99, r_d=0.992, r_loss=6.93]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40078/2905919882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwarmup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_constant_schedule_with_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_nr\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelFileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskipValidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowValidationGPUMem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_ACCUMULATION_STEPS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_ACCUMULATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCL_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCL_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontinous_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelFileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskipValidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowValidationGPUMem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_ACCUMULATION_STEPS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_ACCUMULATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCL_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCL_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontinous_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/splice-site-prediction/Code/src/train.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, fileName, criterion, train_loader, val_loader, optimizer, scheduler, warmup, BATCH_SIZE, epochs, device, verbose, CL_max, lowValidationGPUMem, skipValidation, NUM_ACCUMULATION_STEPS, reinforce, continous_labels, no_softmax)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mNUM_ACCUMULATION_STEPS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_110523_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████| 972/972 [20:05<00:00,  1.24s/it, a_r=0.56, d_r=0.588, loss=0.00102, r_a=0.989, r_d=0.991, r_loss=6.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 972/972 [20:04<00:00,  1.24s/it, a_r=0.558, d_r=0.586, loss=0.00101, r_a=0.991, r_d=0.992, r_loss=7.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.001008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████| 972/972 [20:16<00:00,  1.25s/it, a_r=0.559, d_r=0.587, loss=0.000989, r_a=0.991, r_d=0.993, r_loss=7.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████| 972/972 [20:12<00:00,  1.25s/it, a_r=0.563, d_r=0.591, loss=0.000986, r_a=0.993, r_d=0.994, r_loss=7.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████| 972/972 [20:13<00:00,  1.25s/it, a_r=0.559, d_r=0.593, loss=0.00104, r_a=0.989, r_d=0.99, r_loss=7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████| 972/972 [20:16<00:00,  1.25s/it, a_r=0.555, d_r=0.589, loss=0.00101, r_a=0.991, r_d=0.992, r_loss=6.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.001007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████| 972/972 [20:08<00:00,  1.24s/it, a_r=0.56, d_r=0.59, loss=0.000986, r_a=0.992, r_d=0.993, r_loss=6.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████| 972/972 [20:11<00:00,  1.25s/it, a_r=0.565, d_r=0.596, loss=0.000952, r_a=0.993, r_d=0.994, r_loss=7.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████| 972/972 [20:10<00:00,  1.25s/it, a_r=0.562, d_r=0.59, loss=0.00103, r_a=0.976, r_d=0.984, r_loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|████████████████████████████████████████████████████████████████████████████▊| 970/972 [20:12<00:02,  1.23s/it, a_r=0.555, d_r=0.584, loss=0.000996, r_a=0.982, r_d=0.986, r_loss=4.04]"
     ]
    }
   ],
   "source": [
    "for model_nr in range(1,10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_110523_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_110523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    \n",
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_110523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'rnasplice-blood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_110523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "#df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood/transformer_40k_test_set_predictions_120123.gz',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
