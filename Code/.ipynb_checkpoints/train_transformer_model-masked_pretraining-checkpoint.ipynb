{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "#from autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train3 import trainModel\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader2 import getData,spliceDataset,h5pyDataset,getDataPointList,getDataPointListFull,DataPointFull\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d\n",
    "from src.model_flash_attention import SpliceFormer2\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 24 15:34:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    38W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:98:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-PCI...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    38W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install /odinn/tmp/benediktj/torch-2.0.0+cu117-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data'\n",
    "setType = 'train'\n",
    "annotation, transcriptToLabel, seqData = getData(data_dir, setType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListFull(annotation_train,transcriptToLabel,SL,CL_max,shift=SL),CL_max)\n",
    "val_dataset = spliceDataset(getDataPointListFull(annotation_validation,transcriptToLabel,SL,CL_max,shift=SL),CL_max)\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=32, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//2, shuffle=False, num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 50\n",
    "hs = []\n",
    "learning_rate= 1e-4\n",
    "gamma=0.5\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlots(h,fileName):\n",
    "    plt.plot(h['loss'])\n",
    "    plt.plot(h['val_loss'])\n",
    "    #plt.title('Cross entropy loss')\n",
    "    plt.ylabel('Cross entropy Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.savefig(fileName+'LossTrainingCurve.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.plot(h['r2'])\n",
    "    plt.plot(h['val_r2'])\n",
    "    #plt.title('$R^2$')\n",
    "    plt.ylabel('$R^2$')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.savefig(fileName+'R2TrainingCurve.png',dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(h['hammingDistance'])\n",
    "    plt.plot(h['val_hammingDistance'])\n",
    "    #plt.title('Autoencoder hammingDistance')\n",
    "    plt.ylabel('Hamming Distance')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.savefig(fileName+'HDTrainingCurve.png',dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/50:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 2160/2716 [1:53:53<30:39,  3.31s/it, Hamming_dist=0.65, R2_score=0, loss=1.28]"
     ]
    }
   ],
   "source": [
    "model_m = SpliceFormer2(CL_max,SL,n_channels=64,depth=8,n_heads=4,dim_head=64,mlp_dim=512,dropout=0.1)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "model_m = torch.compile(model_m)\n",
    "\n",
    "modelFileName = '../Results/PyTorch_Models/transformer_10k_masked_pretrain'\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_m.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,reinforce=False,CL_max=CL_max,no_softmax=True)\n",
    "hs.append(h)\n",
    "\n",
    "#plt.plot(range(epochs),h['loss'],label='Train')\n",
    "#plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "getPlots(h,f\"../Results/{modelFileName.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_nr in range(3):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_200323_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS)\n",
    "    hs.append(h)\n",
    "\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    #plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|████████████| 2716/2716 [55:15<00:00,  1.22s/it, a_r=0.87, d_r=0.884, loss=0.000218, r_a=0.997, r_d=0.989, r_loss=5.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.015869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|█████████████| 2716/2716 [55:19<00:00,  1.22s/it, a_r=0.9, d_r=0.912, loss=0.000183, r_a=0.999, r_d=0.992, r_loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|█| 2716/2716 [55:58<00:00,  1.24s/it, a_r=0.914, d_r=0.921, loss=0.000164, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|█| 2716/2716 [55:31<00:00,  1.23s/it, a_r=0.918, d_r=0.93, loss=0.000154, r_a=0.999, r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|█| 2716/2716 [55:49<00:00,  1.23s/it, a_r=0.924, d_r=0.929, loss=0.000152, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|█| 2716/2716 [55:47<00:00,  1.23s/it, a_r=0.936, d_r=0.943, loss=0.000137, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|█| 2716/2716 [55:48<00:00,  1.23s/it, a_r=0.952, d_r=0.956, loss=0.000114, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|█| 2716/2716 [56:03<00:00,  1.24s/it, a_r=0.96, d_r=0.963, loss=9.62e-5, r_a=0.999, r_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|█| 2716/2716 [56:00<00:00,  1.24s/it, a_r=0.968, d_r=0.969, loss=7.83e-5, r_a=0.999, r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|█| 2716/2716 [55:50<00:00,  1.23s/it, a_r=0.967, d_r=0.972, loss=6.89e-5, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|█| 2716/2716 [55:34<00:00,  1.23s/it, a_r=0.876, d_r=0.889, loss=0.000209, r_a=0.996, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.015180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|█| 2716/2716 [55:34<00:00,  1.23s/it, a_r=0.902, d_r=0.91, loss=0.000181, r_a=0.998, r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|█| 2716/2716 [55:54<00:00,  1.24s/it, a_r=0.912, d_r=0.921, loss=0.000169, r_a=0.998, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|█| 2716/2716 [56:03<00:00,  1.24s/it, a_r=0.919, d_r=0.926, loss=0.000158, r_a=0.998, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|█| 2716/2716 [56:08<00:00,  1.24s/it, a_r=0.932, d_r=0.939, loss=0.000143, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|█| 2716/2716 [56:10<00:00,  1.24s/it, a_r=0.933, d_r=0.938, loss=0.000136, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|█| 2716/2716 [55:27<00:00,  1.23s/it, a_r=0.954, d_r=0.956, loss=0.000106, r_a=0.999, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|█| 2716/2716 [55:55<00:00,  1.24s/it, a_r=0.962, d_r=0.966, loss=9.17e-5, r_a=0.999, r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|█| 2716/2716 [55:47<00:00,  1.23s/it, a_r=0.966, d_r=0.967, loss=8.22e-5, r_a=0.999, r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|████████████| 2716/2716 [56:02<00:00,  1.24s/it, a_r=0.969, d_r=0.97, loss=7.14e-5, r_a=0.999, r_d=0.999, r_loss=3.66]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhw0lEQVR4nO3df3Dc9X3n8edLki2BtHaxLKTENrEp0lKTNtDqSEg6N0loG9OkONPCxUybo1fmmOQgJG1TCrkJSblyU27apuFCMsdBGpKmJYyTzLmtG3Ip0CaXBhAJbWKwQGMcLBIbYTu2Y8eWZb3vj/2uvF6vfizer7774/WY8fi7n/18v3rvGvTa7/fz2e9HEYGZmdlCtWVdgJmZNRYHh5mZVcXBYWZmVXFwmJlZVRwcZmZWlY6sC1gMK1eujLVr12ZdhplZQ3nyySdfjoi+8vaWCI61a9cyMjKSdRlmZg1F0vcrtftSlZmZVcXBYWZmVXFwmJlZVVpijMPMrFrHjx9nfHyco0ePZl1K6rq6uli9ejVLlixZUH8Hh5lZBePj4+RyOdauXYukrMtJTUSwd+9exsfHWbdu3YL28aUqM7MKjh49Sm9vb1OHBoAkent7qzqzcnCYmc2i2UOjqNrX6eCYw2f/ZSd/+68/yLoMM7O64uCYw4Mju3hwZFfWZZhZi9m7dy8XX3wxF198MQMDA6xatWrm8eTk5Jz7joyMcNNNN6VanwfH5zDUn+P/jb2cdRlm1mJ6e3t56qmnAPjoRz9KT08PH/zgB2een5qaoqOj8q/v4eFhhoeHU63PZxxzyPfn2HPwGD86MnfCm5ml7bd/+7d5z3vew+tf/3puvvlmHn/8cS677DIuueQS3vjGNzI6OgrAo48+yjve8Q6gEDq/8zu/w5vf/GbOP/987rrrrprU4jOOOQwN5AB4ds+PuXTdioyrMbOs/NHfbuPpHxys6THXv3oZH/m1i6raZ3x8nG9+85u0t7dz8OBBvv71r9PR0cHXvvY1PvShD/HFL37xtH22b9/OI488wqFDh8jn87z3ve9d8Pc1ZuPgmEO+vxAco7sPOjjMLHNXX3017e3tABw4cIBrr72W5557DkkcP3684j5vf/vb6ezspLOzk3PPPZc9e/awevXqM6rDwTGHVy3vItfVweieQ1mXYmYZqvbMIC3d3d0z2x/+8Id5y1vewpe//GV27tzJm9/85or7dHZ2zmy3t7czNTV1xnV4jGMOksj353h294+zLsXM7BQHDhxg1apVAHzmM59Z1J/t4JjH0ECO0T2HiIisSzEzm3HzzTdz6623cskll9TkLKIaaoVfiMPDw/FKF3K6/5s7+ciWbTz2ocvpX9ZV48rMrF4988wz/MzP/EzWZSyaSq9X0pMRcdrcXp9xzGNoZoDc4xxmZuDgmNdQfw8Az3qA3MwMcHDMq7enk5U9nWz3GYdZy2mFS/lQ/et0cCxAfqDHZxxmLaarq4u9e/c2fXgU1+Po6lr4GG6q3+OQtAH4ONAO3BsRf1L2fCfwWeAXgL3AuyJip6ReYDPw74DPRMSNFY69BTg/Il6b5msAyPcv468f/z7T00FbW2vcZtms1a1evZrx8XEmJiayLiV1xRUAFyq14JDUDtwN/DIwDjwhaUtEPF3S7Tpgf0RcIGkTcCfwLuAo8GHgtcmf8mP/OrBoX67ID/Rw9Pg0u/Yf4TW93fPvYGYNb8mSJQteEa/VpHmp6lJgLCJ2RMQk8ACwsazPRuD+ZHszcLkkRcThiPgGhQA5haQe4PeAP06v9FN5ZpWZ2UlpBscqoHQxi/GkrWKfiJgCDgC98xz3vwF/BhyZq5Ok6yWNSBo501PNwf7izQ4dHGZmDTU4Luli4Kcj4svz9Y2IeyJiOCKG+/r6zujn9nR2sPqcsxjd41uPmJmlGRwvAmtKHq9O2ir2kdQBLKcwSD6by4BhSTuBbwBDkh6tUb1zyvfnGN1d29sqm5k1ojSD4wlgUNI6SUuBTcCWsj5bgGuT7auAh2OOuW8R8amIeHVErAV+EXg2It5c88orGBrIsWPiMJNT04vx48zM6lZqs6oiYkrSjcBDFKbjfjoitkm6HRiJiC3AfcDnJI0B+yiECwDJWcUyYKmkdwK/UjYja1FdOJBjajp4/uXD5JMFnszMWlGq3+OIiK3A1rK220q2jwJXz7Lv2nmOvZMKU3XTMjOzas8hB4eZtbSGGhzP0vl93bS3iWc9JdfMWpyDY4E6O9pZt7LbqwGaWctzcFQh35/zdznMrOU5OKow1J/jhX1HODK5uKttmZnVEwdHFfIDPUTAc/4ioJm1MAdHFfIDywA8zmFmLc3BUYXzVpxNZ0ebZ1aZWUtzcFShvU0M9vf4jMPMWpqDo0pDnlllZi3OwVGlfH+OPQeP8aMjk1mXYmaWCQdHlYYGvKiTmbU2B0eV8l7UycxanIOjSq9a3kWuq8MD5GbWshwcVZJUuPXIbn8J0Mxak4PjFRgayDG65xBzrDllZta0HByvQL4/x4GfHOelQ8eyLsXMbNE5OF6BmUWdPLPKzFpQqsEhaYOkUUljkm6p8HynpC8kzz8maW3S3ivpEUk/lvSJkv5nS/p7SdslbZP0J2nWP5u8p+SaWQtLLTgktQN3A1cA64FrJK0v63YdsD8iLgA+BtyZtB8FPgx8sMKh/zQiLgQuAd4k6Yo06p/Liu6l9OU6PbPKzFpSmmcclwJjEbEjIiaBB4CNZX02Avcn25uByyUpIg5HxDcoBMiMiDgSEY8k25PAt4HVKb6GWXlRJzNrVWkGxypgV8nj8aStYp+ImAIOAL0LObiknwJ+DfjHWZ6/XtKIpJGJiYnqKl+A4j2rpqc9s8rMWktDDo5L6gD+BrgrInZU6hMR90TEcEQM9/X11byG/EAPR49Ps2v/kZof28ysnqUZHC8Ca0oer07aKvZJwmA5sHcBx74HeC4i/uLMy3xlPLPKzFpVmsHxBDAoaZ2kpcAmYEtZny3Atcn2VcDDMc+36iT9MYWA+UBty63OoO9ZZWYtqiOtA0fElKQbgYeAduDTEbFN0u3ASERsAe4DPidpDNhHIVwAkLQTWAYslfRO4FeAg8B/BbYD35YE8ImIuDet1zGbns4OVp9zFtt9xmFmLSa14ACIiK3A1rK220q2jwJXz7Lv2lkOq1rVd6YuHPDMKjNrPQ05OF4vhvpz7Jg4zOTUdNalmJktGgfHGcgP5JiaDp5/+XDWpZiZLRoHxxmYmVnly1Vm1kIcHGfg/L5u2tvEsx4gN7MW4uA4A50d7axb2e0zDjNrKQ6OM5Tvz/lLgGbWUhwcZyg/kOOFfUc4MjmVdSlmZovCwXGGigPkz+3xGuRm1hocHGdoZlEnj3OYWYtwcJyh81acTWdHm2dWmVnLcHCcofY2Mdjf4zMOM2sZDo4aGPJqgGbWQhwcNZDvz7Hn4DF+dGQy61LMzFLn4KiBmQFyj3OYWQtwcNRAMTh8ucrMWoGDowYGlnWR6+rwALmZtQQHRw1IIt+f49nd/hKgmTW/VIND0gZJo5LGJN1S4flOSV9Inn9M0tqkvVfSI5J+LOkTZfv8gqTvJvvcpWT92KwNDeQY3XOIeZZMNzNreKkFh6R24G7gCmA9cI2k9WXdrgP2R8QFwMeAO5P2o8CHgQ9WOPSngP8MDCZ/NtS++url+3Mc+MlxXjp0LOtSzMxSleYZx6XAWETsiIhJ4AFgY1mfjcD9yfZm4HJJiojDEfENCgEyQ9KrgGUR8a0ofLT/LPDOFF/DghXvWbXdM6vMrMmlGRyrgF0lj8eTtop9ImIKOAD0znPM8XmOCYCk6yWNSBqZmJiosvTqzcyscnCYWZNr2sHxiLgnIoYjYrivry/1n7eieyl9uU7PrDKzppdmcLwIrCl5vDppq9hHUgewHNg7zzFXz3PMzOR96xEzawFpBscTwKCkdZKWApuALWV9tgDXJttXAQ/HHNOSIuKHwEFJb0hmU/1H4P/UvvRXpnjPqulpz6wys+bVkdaBI2JK0o3AQ0A78OmI2CbpdmAkIrYA9wGfkzQG7KMQLgBI2gksA5ZKeifwKxHxNPBfgM8AZwH/kPypC/mBHo4en2bX/iO8prc763LMzFKRWnAARMRWYGtZ220l20eBq2fZd+0s7SPAa2tXZe0UZ1aN7j7k4DCzptW0g+NZGOz3zQ7NrPk5OGqop7ODNSvO8swqM2tqDo4a88wqM2t2Do4aG+rPsWPiMJNT01mXYmaWCgdHjeUHckxNB8+/fDjrUszMUuHgqLGZmVW+XGVmTcrBUWPn93XT3ibfs8rMmpaDo8Y6O9pZt7Lbd8k1s6bl4EhBfsAzq8yseTk4UpDvz/HCviMcmZzKuhQzs5pzcKSgOED+3B6vQW5mzcfBkYLiok6eWWVmzcjBkYLzVpxNZ0ebZ1aZWVNycKSgvU0M9vf4jMPMmpKDIyVD/TnfJdfMmpKDIyUXDuR46dAx9h+ezLoUM7OacnCkpDizyt/nMLNms6DgkNQtqS3ZHpJ0paQlC9hvg6RRSWOSbqnwfKekLyTPPyZpbclztybto5LeVtL+u5K2SfqepL+R1LWgV7rIijOrHBxm1mwWesbxz0CXpFXAV4F3U1j3e1aS2oG7gSuA9cA1ktaXdbsO2B8RFwAfA+5M9l1PYf3xi4ANwCcltSc//yZgOCJeS2Et803UoYFlXeS6OjxAbmZNZ6HBoYg4Avw68MmIuJrCL/W5XAqMRcSOiJgEHgA2lvXZCNyfbG8GLpekpP2BiDgWEc8DY8nxoLBO+lmSOoCzgR8s8DUsKkmFRZ12+0uAZtZcFhwcki4DfhP4+6StfZ59VgG7Sh6PJ20V+0TEFHAA6J1t34h4EfhT4AXgh8CBiPjqLAVfL2lE0sjExMQ8paZjaCDH6J5DREQmP9/MLA0LDY4PALcCX46IbZLOBx5JrapZSDqHwtnIOuDVQLek36rUNyLuiYjhiBju6+tbzDJn5PtzHPjJcfYcPJbJzzczS8OCgiMi/ikiroyIO5NB8pcj4qZ5dnsRWFPyeHXSVrFPculpObB3jn1/CXg+IiYi4jjwJeCNC3kNWfCtR8ysGS10VtVfS1omqRv4HvC0pD+YZ7cngEFJ6yQtpTCIvaWszxbg2mT7KuDhKFzX2QJsSmZdrQMGgccpXKJ6g6Szk7GQy4FnFvIasjAzJddfBDSzJrLQS1XrI+Ig8E7gHyhcKnr3XDskYxY3Ag9R+OX+YHKZ63ZJVybd7gN6JY0Bvwfckuy7DXgQeBr4CnBDRJyIiMcoDKJ/G/huUv89C3wNi25F91L6cp0+4zCzptKxwH5Lku9tvBP4REQclzTviG9EbAW2lrXdVrJ9FLh6ln3vAO6o0P4R4CMLrDtz+X4v6mRmzWWhZxz/C9gJdAP/LOk1wMG0imomQ0lwTE97ZpWZNYeFDo7fFRGrIuJXo+D7wFtSrq0p5Ad6OHp8ml37j2RdiplZTSx0cHy5pD8vfi9C0p9ROPuweRQHyLd7gNzMmsRCL1V9GjgE/Ifkz0HgL9Mqqpl4ZpWZNZuFDo7/dET8RsnjP5L0VAr1NJ3uzg7WrDjLM6vMrGks9IzjJ5J+sfhA0puAn6RTUvPxzCozayYLPeN4D/BZScuTx/s5+cU9m8dQf45HRyeYnJpmaYeXQDGzxrbQWVX/GhGvA34O+LmIuAR4a6qVNZH8QI6p6eD5lw9nXYqZ2Rmr6uNvRBxMvkEOhW962wIUB8g9zmFmzeBMrpuoZlU0uZ/u66GjTYzu9ncmzazxnUlw+KvQC7S0o411K7sZ9aJOZtYE5hwcl3SIygEh4KxUKmpSQwM5vjt+IOsyzMzO2JxnHBGRi4hlFf7kImKhM7KMwpTcF/Yd4cjkVNalmJmdEc8NXSTFAfLn9vhylZk1NgfHIvFqgGbWLBwci+S8FWfTtaTN96wys4bn4Fgk7W1i8NyczzjMrOGlGhySNkgalTQm6ZYKz3dK+kLy/GOS1pY8d2vSPirpbSXtPyVps6Ttkp6RdFmar6GWhvpzjPqMw8waXGrBIakduBu4AlgPXCNpfVm364D9EXEB8DHgzmTf9cAm4CJgA/DJ5HgAHwe+EhEXAq+jsJ55Q8gP9PDSoWPsPzyZdSlmZq9YmmcclwJjEbEjIiaBB4CNZX02Avcn25uByyUpaX8gIo5FxPPAGHBpcpPFfw/cBxARkxHxoxRfQ03NrM3hy1Vm1sDSDI5VwK6Sx+NJW8U+ETEFHAB659h3HTAB/KWk70i6V1LFlQglXV9csXBiYqIWr+eMFWdWOTjMrJE12uB4B/DzwKeSO/QeBk4bOwGIiHsiYjgihvv6+hazxlkNLOsi19XhAXIza2hpBseLwJqSx6uTtop9JHUAy4G9c+w7DoxHxGNJ+2YKQdIQJBUWdfI9q8ysgaUZHE8Ag5LWSVpKYbB7S1mfLZxcEOoq4OGIiKR9UzLrah0wCDweEbuBXZLyyT6XA0+n+BpqLj+QY/vugxRepplZ40ktOJIxixuBhyjMfHowIrZJul3SlUm3+4BeSWMU1ve4Jdl3G/AghVD4CnBDRJxI9nkf8HlJ/wZcDPz3tF5DGvIDOQ4enWLPwWNZl2Jm9oqkeqPCiNgKbC1ru61k+yhw9Sz73gHcUaH9KWC4poUuotJFnQaWd2VcjZlZ9RptcLzhzUzJ9RcBzaxBOTgW2YrupfTlOj2zyswaloMjA/n+nL/LYWYNy8GRgaEkOKanPbPKzBqPgyMDFw7kOHp8mhf2Hcm6FDOzqjk4MjDkRZ3MrIE5ODIweG4P4JlVZtaYHBwZ6O7sYM2Ks3zGYWYNycGREc+sMrNG5eDIyFB/jh0Th5mcms66FDOzqjg4MpIfyDE1HTz/8uGsSzEzq4qDIyPFRZ227z6YcSVmZtVxcGTk/JU9dLTJ4xxm1nAcHBlZ2tHGupXdjHpRJzNrMA6ODA0NeGaVmTUeB0eG8v05Xth3hCOTU1mXYma2YA6ODBXX5nhujy9XmVnjSDU4JG2QNCppTNItFZ7vlPSF5PnHJK0tee7WpH1U0tvK9muX9B1Jf5dm/WnL+55VZtaAUgsOSe3A3cAVwHrgGknry7pdB+yPiAuAjwF3JvuuBzYBFwEbgE8mxyt6P4V1zBvaeSvOpmtJG6O+Z5WZNZA0zzguBcYiYkdETAIPABvL+mwE7k+2NwOXS1LS/kBEHIuI54Gx5HhIWg28Hbg3xdoXRXubGDzXA+Rm1ljSDI5VwK6Sx+NJW8U+ETEFHAB659n3L4Cbgaa4V8dQf85nHGbWUBpqcFzSO4CXIuLJBfS9XtKIpJGJiYlFqO6VyQ/08NKhY+w/PJl1KWZmC5JmcLwIrCl5vDppq9hHUgewHNg7x75vAq6UtJPCpa+3SvqrSj88Iu6JiOGIGO7r6zvzV5OS4swqX64ys0aRZnA8AQxKWidpKYXB7i1lfbYA1ybbVwEPR0Qk7ZuSWVfrgEHg8Yi4NSJWR8Ta5HgPR8RvpfgaUlecWeXgMLNG0ZHWgSNiStKNwENAO/DpiNgm6XZgJCK2APcBn5M0BuyjEAYk/R4EngamgBsi4kRatWZpYFkXua4OT8k1s4aRWnAARMRWYGtZ220l20eBq2fZ9w7gjjmO/SjwaC3qzJIkLhzI8azvWWVmDaKhBseb1VB/ju27D1K4SmdmVt8cHHUgP5Dj4NEp9hw8lnUpZmbzcnDUgeLMKo9zmFkjcHDUgZkpuf4ioJk1AAdHHVjRvZS+XKfPOMysITg46kS+3/esMrPG4OCoE/lkNcDpac+sMrP65uCoE/n+HEePT/PCviNZl2JmNicHR50Y8qJOZtYgHBx1YvDcHsAzq8ys/jk46kR3ZwdrVpzlMw4zq3sOjjrimVVm1ggcHHVkqD/HjonDTE41xeKGZtakHBx1JD+QY2o6eP7lw1mXYmY2KwdHHSku6rR998GMKzEzm52Do46cv7KHjjZ5nMPM6pqDo44s7Whj3cpuRr2ok5nVMQdHnRka8MwqM6tvqQaHpA2SRiWNSbqlwvOdkr6QPP+YpLUlz92atI9KelvStkbSI5KelrRN0vvTrD8L+f4cL+w7wpHJqaxLMTOrKLXgkNQO3A1cAawHrpG0vqzbdcD+iLgA+BhwZ7LvemATcBGwAfhkcrwp4PcjYj3wBuCGCsdsaMW1OZ7b48tVZlaf0jzjuBQYi4gdETEJPABsLOuzEbg/2d4MXC5JSfsDEXEsIp4HxoBLI+KHEfFtgIg4BDwDrErxNSy6C33PKjOrc2kGxypgV8njcU7/JT/TJyKmgANA70L2TS5rXQI8VumHS7pe0oikkYmJiVf+KhbZmhVn07WkjVHfs8rM6lRDDo5L6gG+CHwgIip+6SEi7omI4YgY7uvrW9wCz0B7mxg81wPkZla/0gyOF4E1JY9XJ20V+0jqAJYDe+faV9ISCqHx+Yj4UiqVZ2yoP+czDjOrW2kGxxPAoKR1kpZSGOzeUtZnC3Btsn0V8HBERNK+KZl1tQ4YBB5Pxj/uA56JiD9PsfZM5Qd6eOnQMfYfnsy6FDOz06QWHMmYxY3AQxQGsR+MiG2Sbpd0ZdLtPqBX0hjwe8Atyb7bgAeBp4GvADdExAngTcC7gbdKeir586tpvYasFGdW+XKVmdWjjjQPHhFbga1lbbeVbB8Frp5l3zuAO8ravgGo9pXWlwsHlgGF4Hj9+b0ZV2NmdqqGHBxvdv3LOlnW1eEpuWZWlxwcdUgS+QEPkJtZfXJw1KnizKrCXAEzs/rh4KhT+YEcB49OsefgsaxLMTM7hYOjThVnVnmcw8zqjYOjTuWLU3I9zmFmdcbBUafO6V7KublOn3GYWd1xcNSxvBd1MrM65OCoY0P9heA4Me2ZVWZWPxwcdSzfn+Po8Wl27TuSdSlmZjMcHHVsyIs6mVkdcnDUscFzewDPrDKz+uLgqGPdnR2sWXGWzzjMrK44OOpcvn+ZZ1aZWV1xcNS5/EAPOyYOMzk1nXUpZmaAg6PuDfXnmJoOdrz846xLMTMDUl7Iyc5cPplZ9flvvcDPrloOgjaJtuRvzTwubhduy16pT/nfxT4q+7tyn8LzovTvQh8ofx6EkraSbSr0aZulPVmuq1jLaX2KHcxs0aUaHJI2AB8H2oF7I+JPyp7vBD4L/AKwF3hXROxMnrsVuA44AdwUEQ8t5JjN5vyVPZxz9hI+963vZ11K3SkPlLakoTSA2koCrfhcW1t5AJaG06n7zfycYqBy6vHa5gu8suCkGMSn/PxCH4rBXyl0T+l7eoi2S7S3iba2wvHbVbLdppkPASe3menfXvzAUNxuK/albL+SPkm/8j7F2ip9aClvL77PxTrh5POl799sH4xU8j4X/01P+6Ax238jJe2l7zmVjlHyPltBasEhqR24G/hlYBx4QtKWiHi6pNt1wP6IuEDSJuBO4F2S1gObgIuAVwNfkzSU7DPfMZvK0o42vvGHb+Xg0eNMB0xPBxEQROFxBBEnt6enC89F8XF5n+kgKLad3qfQVuG4wczzxeMXtgvPU9oOZf3iZFvpNhWOWbYvnKy5vB/FukraTtbCKa+n9HhRYb+ZOkrai31Kjzdd2h8gTr6Xp72Gmdc6z2su/ZnTEEyf2rfie3dy38K/T3Ai+W/jROn2dHAi+bc8MX16n+K/re9OsDCVAmfmA0mFwCk+B6cHWfJ0Elgng+u0s/aS/WdqmOlb+ZiUtP3d+36RriXtNX0f0jzjuBQYi4gdAJIeADYCpb/kNwIfTbY3A59Q4dVvBB6IiGPA85LGkuOxgGM2ne7ODro7fVXR0jWdBMmJ5APIye2T4TJdGjjThQCaLulT+oFk5m9O/SBSGnaUfFAp9o2Sn18a2BWPHad/CKr8geBk6E4nnyAqfUiY88NKheAu/3BRab+i0v3h9A8aM61x+v6lx+SUtvJjnvqhBk5eTq6lNH8brQJ2lTweB14/W5+ImJJ0AOhN2r9Vtu+qZHu+YwIg6XrgeoDzzjvvlb0CsxbS1ibakAc+bV5NO6sqIu6JiOGIGO7r68u6HDOzppFmcLwIrCl5vDppq9hHUgewnMIg+Wz7LuSYZmaWojSD4wlgUNI6SUspDHZvKeuzBbg22b4KeDgiImnfJKlT0jpgEHh8gcc0M7MUpXY5MxmzuBF4iMLU2U9HxDZJtwMjEbEFuA/4XDL4vY9CEJD0e5DCoPcUcENEnACodMy0XoOZmZ1OUTrs36SGh4djZGQk6zLMzBqKpCcjYri8vWkHx83MLB0ODjMzq4qDw8zMqtISYxySJoBXerOnlcDLNSyn0fn9OMnvxan8fpzULO/FayLitC/CtURwnAlJI5UGh1qV34+T/F6cyu/HSc3+XvhSlZmZVcXBYWZmVXFwzO+erAuoM34/TvJ7cSq/Hyc19XvhMQ4zM6uKzzjMzKwqDg4zM6uKg2MWkjZIGpU0JumWrOvJkqQ1kh6R9LSkbZLen3VN9UBSu6TvSPq7rGvJkqSfkrRZ0nZJz0i6LOuasiTpd5P/T74n6W8kdWVdU605OCooWS/9CmA9cE2yDnqrmgJ+PyLWA28Abmjx96Po/cAzWRdRBz4OfCUiLgReRwu/J5JWATcBwxHxWgp38d6UbVW15+CobGa99IiYBIprm7ekiPhhRHw72T5E4RfDqrn3am6SVgNvB+7NupYsSVoO/HsKSyQQEZMR8aNMi8peB3BWsjjd2cAPMq6n5hwclVVaL72lf1EWSVoLXAI8lnEpWfsL4GZgOuM6srYOmAD+Mrlsd6+k7qyLykpEvAj8KfAC8EPgQER8Nduqas/BYQsmqQf4IvCBiDiYdT1ZkfQO4KWIeDLrWupAB/DzwKci4hLgMNCyY4KSzqFwdWId8GqgW9JvZVtV7Tk4KvPa5mUkLaEQGp+PiC9lXU/G3gRcKWknhcuYb5X0V9mWlJlxYDwiimegmykESav6JeD5iJiIiOPAl4A3ZlxTzTk4KvPa5iUkicI17Gci4s+zridrEXFrRKyOiLUU/tt4OCKa7lPlQkTEbmCXpHzSdDmFJZ9b1QvAGySdnfx/czlNOFkgtTXHG9ls66VnXFaW3gS8G/iupKeStg9FxNbsSrI68j7g88mHrB3Af8q4nsxExGOSNgPfpjAb8Ts04e1HfMsRMzOrii9VmZlZVRwcZmZWFQeHmZlVxcFhZmZVcXCYmVlVHBxmNSDphKSnSv7U7NvTktZK+l6tjmd2pvw9DrPa+ElEXJx1EWaLwWccZimStFPS/5D0XUmPS7ogaV8r6WFJ/ybpHyWdl7T3S/qypH9N/hRvV9Eu6X8n6zx8VdJZmb0oa3kODrPaOKvsUtW7Sp47EBE/C3yCwl11Af4ncH9E/BzweeCupP0u4J8i4nUU7vlUvGPBIHB3RFwE/Aj4jVRfjdkc/M1xsxqQ9OOI6KnQvhN4a0TsSG4UuTsieiW9DLwqIo4n7T+MiJWSJoDVEXGs5Bhrgf8bEYPJ4z8ElkTEHy/CSzM7jc84zNIXs2xX41jJ9gk8PmkZcnCYpe9dJX//S7L9TU4uKfqbwNeT7X8E3gsza5ovX6wizRbKn1rMauOskjsHQ2EN7uKU3HMk/RuFs4Zrkrb3UVg17w8orKBXvKPs+4F7JF1H4czivRRWkjOrGx7jMEtRMsYxHBEvZ12LWa34UpWZmVXFZxxmZlYVn3GYmVlVHBxmZlYVB4eZmVXFwWFmZlVxcJiZWVX+P088rl+cUYWxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|████████████| 2716/2716 [55:43<00:00,  1.23s/it, a_r=0.88, d_r=0.891, loss=0.000213, r_a=0.996, r_d=0.998, r_loss=6.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.015477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|███████████| 2716/2716 [55:39<00:00,  1.23s/it, a_r=0.899, d_r=0.909, loss=0.000181, r_a=0.998, r_d=0.998, r_loss=4.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|████████████| 2716/2716 [56:01<00:00,  1.24s/it, a_r=0.91, d_r=0.919, loss=0.000166, r_a=0.998, r_d=0.999, r_loss=4.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|████████████| 2716/2716 [55:20<00:00,  1.22s/it, a_r=0.921, d_r=0.93, loss=0.000158, r_a=0.999, r_d=0.999, r_loss=5.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|████████████| 2716/2716 [55:41<00:00,  1.23s/it, a_r=0.93, d_r=0.937, loss=0.000142, r_a=0.999, r_d=0.999, r_loss=3.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|███████████| 2716/2716 [55:39<00:00,  1.23s/it, a_r=0.938, d_r=0.941, loss=0.000133, r_a=0.999, r_d=0.999, r_loss=4.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|███████████| 2716/2716 [55:30<00:00,  1.23s/it, a_r=0.952, d_r=0.955, loss=0.000113, r_a=0.998, r_d=0.999, r_loss=3.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|█████████████| 2716/2716 [55:36<00:00,  1.23s/it, a_r=0.96, d_r=0.962, loss=9.47e-5, r_a=0.999, r_d=0.999, r_loss=3.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|████████████| 2716/2716 [55:31<00:00,  1.23s/it, a_r=0.964, d_r=0.965, loss=7.88e-5, r_a=0.999, r_d=0.999, r_loss=3.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|████████████████| 2716/2716 [55:14<00:00,  1.22s/it, a_r=0.967, d_r=0.97, loss=7.26e-5, r_a=1, r_d=0.999, r_loss=3.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|████████████| 2716/2716 [55:55<00:00,  1.24s/it, a_r=0.878, d_r=0.891, loss=0.000214, r_a=0.997, r_d=0.992, r_loss=6.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.014978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|███████████| 2716/2716 [55:41<00:00,  1.23s/it, a_r=0.902, d_r=0.908, loss=0.000183, r_a=0.998, r_d=0.994, r_loss=5.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|███████████| 2716/2716 [55:50<00:00,  1.23s/it, a_r=0.913, d_r=0.922, loss=0.000168, r_a=0.998, r_d=0.993, r_loss=4.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|████████████| 2716/2716 [55:44<00:00,  1.23s/it, a_r=0.925, d_r=0.929, loss=0.00016, r_a=0.999, r_d=0.996, r_loss=3.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|█████████████| 2716/2716 [55:56<00:00,  1.24s/it, a_r=0.93, d_r=0.933, loss=0.000142, r_a=0.999, r_d=0.997, r_loss=4.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|███████████| 2716/2716 [55:25<00:00,  1.22s/it, a_r=0.937, d_r=0.944, loss=0.000131, r_a=0.999, r_d=0.996, r_loss=3.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|███████████| 2716/2716 [55:38<00:00,  1.23s/it, a_r=0.951, d_r=0.955, loss=0.000111, r_a=0.999, r_d=0.995, r_loss=4.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|████████████| 2716/2716 [55:39<00:00,  1.23s/it, a_r=0.964, d_r=0.965, loss=8.73e-5, r_a=0.999, r_d=0.995, r_loss=3.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|████████████| 2716/2716 [55:49<00:00,  1.23s/it, a_r=0.967, d_r=0.971, loss=7.94e-5, r_a=0.999, r_d=0.995, r_loss=3.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|████████████| 2716/2716 [55:30<00:00,  1.23s/it, a_r=0.969, d_r=0.969, loss=7.04e-5, r_a=0.999, r_d=0.997, r_loss=2.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|██████████| 2716/2716 [55:11<00:00,  1.22s/it, a_r=0.86, d_r=0.891, loss=0.000221, r_a=0.00734, r_d=0.997, r_loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.015926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|███████████| 2716/2716 [55:26<00:00,  1.22s/it, a_r=0.896, d_r=0.908, loss=0.000186, r_a=0.997, r_d=0.998, r_loss=5.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|███████████| 2716/2716 [55:09<00:00,  1.22s/it, a_r=0.913, d_r=0.923, loss=0.000169, r_a=0.998, r_d=0.999, r_loss=4.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|████████████| 2716/2716 [55:39<00:00,  1.23s/it, a_r=0.919, d_r=0.927, loss=0.00016, r_a=0.998, r_d=0.999, r_loss=5.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|███████████| 2716/2716 [55:15<00:00,  1.22s/it, a_r=0.927, d_r=0.937, loss=0.000146, r_a=0.999, r_d=0.999, r_loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|███████████| 2716/2716 [55:40<00:00,  1.23s/it, a_r=0.937, d_r=0.943, loss=0.000139, r_a=0.999, r_d=0.999, r_loss=4.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|███████████| 2716/2716 [55:31<00:00,  1.23s/it, a_r=0.951, d_r=0.956, loss=0.000113, r_a=0.999, r_d=0.999, r_loss=3.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|████████████| 2716/2716 [55:31<00:00,  1.23s/it, a_r=0.961, d_r=0.964, loss=9.04e-5, r_a=0.999, r_d=0.999, r_loss=2.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|████████████| 2716/2716 [55:44<00:00,  1.23s/it, a_r=0.963, d_r=0.966, loss=8.83e-5, r_a=0.999, r_d=0.999, r_loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|█████████████| 2716/2716 [55:15<00:00,  1.22s/it, a_r=0.967, d_r=0.97, loss=7.7e-5, r_a=0.999, r_d=0.999, r_loss=1.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_nr in range(5,10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS)\n",
    "    hs.append(h)\n",
    "\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    #plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▍                                                                       | 1/17 [02:43<43:28, 163.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10646374, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▍                                                                       | 1/17 [03:44<59:45, 224.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21194/3831447500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m#outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21194/3831447500.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m#outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Use the autograd function to broadcast if not detach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mtensor_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             return [tensor_copies[i:i + len(tensors)]\n\u001b[1;32m     73\u001b[0m                     for i in range(0, len(tensor_copies), len(tensors))]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0002340018349389342\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9952\t0.9491\t0.9879\t0.9912\t0.9769\t0.9794\t0.3031\t0.0018\t0.0003\t13561\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9958\t0.9519\t0.9896\t0.9925\t0.9799\t0.9790\t0.3300\t0.0016\t0.0002\t13601\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy = 0.00037596160351343195\n",
    "\n",
    "Acceptor:\n",
    "\n",
    "0.9955\t0.95\t0.9875\t0.9909\t0.9773\t1.0000\t0.0410\t0.0000\t0.0000\t13575\t14289.0\t14289\n",
    "\n",
    "Donor:\n",
    "\n",
    "0.9961\t0.9532\t0.9899\t0.9923\t0.9803\t1.0000\t0.0558\t0.0000\t0.0000\t13620\t14289.0\t14289\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [49:00<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0001087605119402784\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9808\t0.9401\t0.9916\t0.9956\t0.9661\t0.9824\t0.4289\t0.0016\t0.0002\t84336\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9817\t0.9452\t0.9943\t0.9969\t0.9698\t0.9819\t0.4858\t0.0015\t0.0002\t84796\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_40k_test_set_predictions_171022_2.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [04:54<00:00, 17.32s/it]\n"
     ]
    }
   ],
   "source": [
    "def odds_gmean(prediction,n_models,a = 1.5):\n",
    "    p = torch.pow(torch.prod(prediction,dim=0), a/n_models)\n",
    "    p_neg = torch.pow(torch.prod(1-prediction,dim=0), a/n_models)\n",
    "    return p / (p+p_neg)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models[:5])]\n",
    "#nr = [0,2,3]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_161022_{}'.format(i))) for i,model in enumerate(models[5:])]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs),n_models)\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00022591106861107486\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9961\t0.95\t0.9876\t0.9914\t0.9782\t0.9778\t0.3168\t0.0024\t0.0004\t13574\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9961\t0.9533\t0.9899\t0.9926\t0.9807\t0.9781\t0.3336\t0.0020\t0.0003\t13621\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [1:27:43<00:00,  3.80s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models[:5])]\n",
    "#nr = [0,2,3]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_161022_{}'.format(i))) for i,model in enumerate(models[5:])]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00010540342260087413\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9813\t0.941\t0.9921\t0.9959\t0.9673\t0.9811\t0.4463\t0.0022\t0.0003\t84422\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9825\t0.946\t0.9944\t0.9971\t0.9711\t0.9814\t0.4852\t0.0018\t0.0002\t84871\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_40k_test_set_predictions_191022.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [04:55<00:00, 17.35s/it]\n"
     ]
    }
   ],
   "source": [
    "def odds_gmean(prediction,n_models,a = 1.5):\n",
    "    p = torch.pow(torch.prod(prediction,dim=0), a/n_models)\n",
    "    p_neg = torch.pow(torch.prod(1-prediction,dim=0), a/n_models)\n",
    "    return p / (p+p_neg)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models[:5])]\n",
    "#nr = [0,2,3]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_161022_{}'.format(i))) for i,model in enumerate(models[5:])]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        #outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        outputs = odds_gmean(torch.stack(outputs),n_models)\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00028597514309361134\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9955\t0.95\t0.9875\t0.9909\t0.9773\t0.9980\t0.1311\t0.0000\t0.0000\t13575\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9961\t0.9532\t0.9899\t0.9923\t0.9803\t0.9980\t0.1549\t0.0000\t0.0000\t13620\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [1:23:22<00:00,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models[:5])]\n",
    "#nr = [0,2,3]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_161022_{}'.format(i))) for i,model in enumerate(models[5:])]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    #outputs = torch.mean(outputs,dim=0)\n",
    "    outputs = odds_gmean(outputs,n_models)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00014547907163697655\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9813\t0.941\t0.9918\t0.9955\t0.9671\t0.9984\t0.3592\t0.0000\t0.0000\t84418\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9823\t0.9459\t0.9941\t0.9969\t0.9707\t0.9984\t0.4408\t0.0000\t0.0000\t84857\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_40k_test_set_predictions_191022_2.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import get_GTEX_v8_Data,getDataPointListGTEX\n",
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8', setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 774/774 [48:32<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0015977755472590298\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9982\t0.7133\t0.8128\t0.8735\t0.7789\t0.8781\t0.0037\t0.0004\t0.0001\t63915\t89600.0\t89600\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.998\t0.7093\t0.8043\t0.8585\t0.7648\t0.8771\t0.0027\t0.0003\t0.0001\t64736\t91272.0\t91272\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77185"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7789+0.7648)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7133+0.7093)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128651"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "63915+64736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import get_GTEX_Data,getDataPointListGTEX,DataPointGTEX\n",
    "from src.evaluation_metrics import kullback_leibler_divergence_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_Data('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX', setType)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 892/892 [56:03<00:00,  3.77s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models[:5])]\n",
    "#nr = [0,2,3]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_161022_{}'.format(i))) for i,model in enumerate(models[5:])]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "kl_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    kl_2d.append(kullback_leibler_divergence_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Div = 0.00016740387218513566\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9801\t0.9247\t0.9749\t0.983\t0.9478\t0.9811\t0.3257\t0.0023\t0.0003\t50826\t54965.0\t54965\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9724\t0.9186\t0.9729\t0.9827\t0.9368\t0.9814\t0.3591\t0.0019\t0.0002\t50474\t54944.0\t54944\n"
     ]
    }
   ],
   "source": [
    "mean_kl = np.mean(kl_2d)\n",
    "print('KL Div = {}'.format(mean_kl))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(np.round(Y_true_acceptor,0), Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(np.round(Y_true_donor,0), Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9854\t0.8814\t0.9382\t0.9592\t0.9153\t0.9769\t0.1012\t0.0016\t0.0003\t53825\t61069.0\t61069\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9811\t0.8695\t0.932\t0.9565\t0.9031\t0.9767\t0.0830\t0.0012\t0.0002\t53998\t62103.0\t62103\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [05:01<00:00, 17.73s/it]\n"
     ]
    }
   ],
   "source": [
    "def odds_gmean(prediction,n_models,a = 1.5):\n",
    "    p = torch.pow(torch.prod(prediction,dim=0), a/n_models)\n",
    "    p_neg = torch.pow(torch.prod(1-prediction,dim=0), a/n_models)\n",
    "    return p / (p+p_neg)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs),n_models)\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00022536547672551296\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9964\t0.9501\t0.9878\t0.9917\t0.9781\t0.9797\t0.3242\t0.0025\t0.0003\t13576\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9959\t0.9535\t0.9903\t0.9926\t0.9808\t0.9799\t0.3404\t0.0020\t0.0002\t13624\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData(data_dir, setType)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [1:22:25<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0001054637939021545\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9811\t0.9409\t0.992\t0.996\t0.967\t0.9827\t0.4555\t0.0022\t0.0003\t84407\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9823\t0.9457\t0.9945\t0.9972\t0.9704\t0.9829\t0.4890\t0.0018\t0.0002\t84841\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_40k_test_set_predictions_261022.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 133024/133024 [07:37<00:00, 290.45it/s]\n"
     ]
    }
   ],
   "source": [
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData(data_dir, setType)    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "data = getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL,include_pos=True)\n",
    "\n",
    "chromosomes = []\n",
    "transcripts = []\n",
    "posistions = []\n",
    "\n",
    "for x in tqdm(data):\n",
    "    _ ,targets,pos,chrom,transcript = x.getData(seqData)\n",
    "    targets = targets[:,CL_max//2:-CL_max//2]\n",
    "    #is_expr = (targets.sum(axis=(0)) >= 1)\n",
    "    is_expr = targets.sum() >= 1\n",
    "    if is_expr:\n",
    "        chromosomes.extend(chrom)\n",
    "        transcripts.extend(transcript)\n",
    "        posistions.extend(pos)\n",
    "    #chromosomes.extend(chrom[is_expr])\n",
    "    #transcripts.extend(transcript[is_expr])\n",
    "    #posistions.extend(pos[is_expr])\n",
    "    #Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    #Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664940000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posistions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/tvd-191022.pkl', 'rb') as f:\n",
    "    tv_dist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664940000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/spliceai_10k_test_set_predictions_191022.gz')\n",
    "df2 = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-050422/transformer_40k_test_set_predictions_191022.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'transcript':transcripts,'chromosome':chromosomes,'posistions':posistions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tvd'] = tv_dist\n",
    "df2['tvd'] = tv_dist\n",
    "df3['tvd'] = tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_da = df1[df1['tvd']>=0.1]\n",
    "df2_da = df2[df2['tvd']>=0.1]\n",
    "df3_da = df3[df3['tvd']>=0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_da.columns = ['Y_true_acceptor', 'SpliceAI_acceptor', 'Y_true_donor', 'SpliceAI_donor','tvd']\n",
    "df2_da.columns = ['Y_true_acceptor', 'Transformer_acceptor', 'Y_true_donor', 'Transformer_donor','tvd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([df3_da[['transcript','chromosome','posistions']],df1_da.iloc[:,:-1],df2_da[['Transformer_acceptor','Transformer_donor','tvd']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[['transcript', 'chromosome', 'posistions', 'Y_true_acceptor','Y_true_donor',\n",
    "       'SpliceAI_acceptor', 'SpliceAI_donor',\n",
    "       'Transformer_acceptor', 'Transformer_donor', 'tvd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>posistions</th>\n",
       "      <th>Y_true_acceptor</th>\n",
       "      <th>SpliceAI_acceptor</th>\n",
       "      <th>Y_true_donor</th>\n",
       "      <th>SpliceAI_donor</th>\n",
       "      <th>Transformer_acceptor</th>\n",
       "      <th>Transformer_donor</th>\n",
       "      <th>tvd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108770716</th>\n",
       "      <td>ENST00000624731</td>\n",
       "      <td>chr1</td>\n",
       "      <td>156597888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093406</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.193057</td>\n",
       "      <td>0.100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371177</th>\n",
       "      <td>ENST00000427211</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1417946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.860327</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340976206</th>\n",
       "      <td>ENST00000342358</td>\n",
       "      <td>chr3</td>\n",
       "      <td>193360049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.521673</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.100008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525967583</th>\n",
       "      <td>ENST00000445716</td>\n",
       "      <td>chr7</td>\n",
       "      <td>92577977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.104691</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.100009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118776015</th>\n",
       "      <td>ENST00000413811</td>\n",
       "      <td>chr1</td>\n",
       "      <td>169851935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.959575</td>\n",
       "      <td>0.100010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69935035</th>\n",
       "      <td>ENST00000326637</td>\n",
       "      <td>chr1</td>\n",
       "      <td>74395435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.836652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195337084</th>\n",
       "      <td>ENST00000437509</td>\n",
       "      <td>chr3</td>\n",
       "      <td>16231792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.836748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430656951</th>\n",
       "      <td>ENST00000378004</td>\n",
       "      <td>chr5</td>\n",
       "      <td>143222357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.891665</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.843967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64484651</th>\n",
       "      <td>ENST00000235345</td>\n",
       "      <td>chr1</td>\n",
       "      <td>67008750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.933062</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.864458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415997291</th>\n",
       "      <td>ENST00000379264</td>\n",
       "      <td>chr5</td>\n",
       "      <td>131953953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.904157</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.877085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32673 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                transcript chromosome  posistions  Y_true_acceptor  \\\n",
       "108770716  ENST00000624731       chr1   156597888              0.0   \n",
       "371177     ENST00000427211       chr1     1417946              0.0   \n",
       "340976206  ENST00000342358       chr3   193360049              1.0   \n",
       "525967583  ENST00000445716       chr7    92577977              0.0   \n",
       "118776015  ENST00000413811       chr1   169851935              0.0   \n",
       "...                    ...        ...         ...              ...   \n",
       "69935035   ENST00000326637       chr1    74395435              0.0   \n",
       "195337084  ENST00000437509       chr3    16231792              1.0   \n",
       "430656951  ENST00000378004       chr5   143222357              1.0   \n",
       "64484651   ENST00000235345       chr1    67008750              1.0   \n",
       "415997291  ENST00000379264       chr5   131953953              1.0   \n",
       "\n",
       "           SpliceAI_acceptor  Y_true_donor  SpliceAI_donor  \\\n",
       "108770716           0.000050           0.0        0.093406   \n",
       "371177              0.960329           0.0        0.000093   \n",
       "340976206           0.621681           0.0        0.000057   \n",
       "525967583           0.204700           0.0        0.000032   \n",
       "118776015           0.000015           1.0        0.859690   \n",
       "...                      ...           ...             ...   \n",
       "69935035            0.869300           0.0        0.000073   \n",
       "195337084           0.893531           0.0        0.000039   \n",
       "430656951           0.047768           0.0        0.000049   \n",
       "64484651            0.068658           0.0        0.000022   \n",
       "415997291           0.027240           0.0        0.000117   \n",
       "\n",
       "           Transformer_acceptor  Transformer_donor       tvd  \n",
       "108770716              0.000400           0.193057  0.100002  \n",
       "371177                 0.860327           0.000307  0.100002  \n",
       "340976206              0.521673           0.000080  0.100008  \n",
       "525967583              0.104691           0.000107  0.100009  \n",
       "118776015              0.000139           0.959575  0.100010  \n",
       "...                         ...                ...       ...  \n",
       "69935035               0.032710           0.000012  0.836652  \n",
       "195337084              0.056783           0.000039  0.836748  \n",
       "430656951              0.891665           0.000119  0.843967  \n",
       "64484651               0.933062           0.000077  0.864458  \n",
       "415997291              0.904157           0.000285  0.877085  \n",
       "\n",
       "[32673 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('tvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>posistions</th>\n",
       "      <th>Y_true_acceptor</th>\n",
       "      <th>Y_true_donor</th>\n",
       "      <th>SpliceAI_acceptor</th>\n",
       "      <th>SpliceAI_donor</th>\n",
       "      <th>Transformer_acceptor</th>\n",
       "      <th>Transformer_donor</th>\n",
       "      <th>tvd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74191721</th>\n",
       "      <td>ENST00000319517</td>\n",
       "      <td>chr1</td>\n",
       "      <td>81862117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.815235</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.804913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225073839</th>\n",
       "      <td>ENST00000327906</td>\n",
       "      <td>chr3</td>\n",
       "      <td>52414495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082544</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.887458</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.804975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74487348</th>\n",
       "      <td>ENST00000359929</td>\n",
       "      <td>chr1</td>\n",
       "      <td>81862117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.815235</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.805152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69935137</th>\n",
       "      <td>ENST00000326637</td>\n",
       "      <td>chr1</td>\n",
       "      <td>74395537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.841945</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>0.818339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452862278</th>\n",
       "      <td>ENST00000296953</td>\n",
       "      <td>chr5</td>\n",
       "      <td>173133629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058971</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.878931</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.820021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69935035</th>\n",
       "      <td>ENST00000326637</td>\n",
       "      <td>chr1</td>\n",
       "      <td>74395435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.836652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195337084</th>\n",
       "      <td>ENST00000437509</td>\n",
       "      <td>chr3</td>\n",
       "      <td>16231792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893531</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.836748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430656951</th>\n",
       "      <td>ENST00000378004</td>\n",
       "      <td>chr5</td>\n",
       "      <td>143222357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047768</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.891665</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.843967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64484651</th>\n",
       "      <td>ENST00000235345</td>\n",
       "      <td>chr1</td>\n",
       "      <td>67008750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.933062</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.864458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415997291</th>\n",
       "      <td>ENST00000379264</td>\n",
       "      <td>chr5</td>\n",
       "      <td>131953953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.904157</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.877085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                transcript chromosome  posistions  Y_true_acceptor  \\\n",
       "74191721   ENST00000319517       chr1    81862117              0.0   \n",
       "225073839  ENST00000327906       chr3    52414495              1.0   \n",
       "74487348   ENST00000359929       chr1    81862117              0.0   \n",
       "69935137   ENST00000326637       chr1    74395537              0.0   \n",
       "452862278  ENST00000296953       chr5   173133629              1.0   \n",
       "69935035   ENST00000326637       chr1    74395435              0.0   \n",
       "195337084  ENST00000437509       chr3    16231792              1.0   \n",
       "430656951  ENST00000378004       chr5   143222357              1.0   \n",
       "64484651   ENST00000235345       chr1    67008750              1.0   \n",
       "415997291  ENST00000379264       chr5   131953953              1.0   \n",
       "\n",
       "           Y_true_donor  SpliceAI_acceptor  SpliceAI_donor  \\\n",
       "74191721            0.0           0.000093        0.815235   \n",
       "225073839           0.0           0.082544        0.000035   \n",
       "74487348            0.0           0.000093        0.815235   \n",
       "69935137            0.0           0.000056        0.841945   \n",
       "452862278           0.0           0.058971        0.000073   \n",
       "69935035            0.0           0.869300        0.000073   \n",
       "195337084           0.0           0.893531        0.000039   \n",
       "430656951           0.0           0.047768        0.000049   \n",
       "64484651            0.0           0.068658        0.000022   \n",
       "415997291           0.0           0.027240        0.000117   \n",
       "\n",
       "           Transformer_acceptor  Transformer_donor       tvd  \n",
       "74191721               0.000026           0.010388  0.804913  \n",
       "225073839              0.887458           0.000097  0.804975  \n",
       "74487348               0.000027           0.010148  0.805152  \n",
       "69935137               0.000030           0.023631  0.818339  \n",
       "452862278              0.878931           0.000134  0.820021  \n",
       "69935035               0.032710           0.000012  0.836652  \n",
       "195337084              0.056783           0.000039  0.836748  \n",
       "430656951              0.891665           0.000119  0.843967  \n",
       "64484651               0.933062           0.000077  0.864458  \n",
       "415997291              0.904157           0.000285  0.877085  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('tvd').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENST00000296953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('tvd',ascending=False).to_csv('../Results/transformer_spliceai_tvd_w_posistion.tsv',sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
