{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "\n",
    "from src.train import trainModel\n",
    "from src.dataloader import getData,spliceDataset,h5pyDataset,getDataPointList,getDataPointListFull,DataPoint\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics\n",
    "import copy\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 17 17:28:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    55W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    43W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    45W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    46W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 8\n",
    "k = 2\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = k*6*N_GPUS\n",
    "\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/gene_boundries.pkl', 'rb') as f:\n",
    "    gene_boundries = pickle.load(f)\n",
    "    \n",
    "def unionBoundry(names,gene_boundries):\n",
    "    for i,name in enumerate(names):\n",
    "        if i==0:\n",
    "            gene_start,gene_end = gene_boundries[name]\n",
    "        else:\n",
    "            start,end = gene_boundries[name]\n",
    "            gene_start,gene_end = np.min([gene_start,start]),np.max([gene_end,end])\n",
    "    return gene_start,gene_end\n",
    "inside_gene = []\n",
    "\n",
    "def is_inside_gene(names,gene_boundries):\n",
    "    inside_gene = []\n",
    "    for i,name in enumerate(names):\n",
    "        #if i==0:\n",
    "        gene_start,gene_end = gene_boundries[name]\n",
    "        #else:\n",
    "        #    start,end = gene_boundries[name]\n",
    "        #   gene_start,gene_end = np.min([gene_start,start]),np.max([gene_end,end])\n",
    "        inside_gene.append(gene_start <= pos <= gene_end)\n",
    "    \n",
    "    return np.any(inside_gene)\n",
    "\n",
    "#for i in tqdm(range(lead_sQTL.shape[0])):\n",
    "#    gene,chrm,strand,pos,jn_start,jn_end,ref_s,alt_s,event_id = lead_sQTL.iloc[i,:][['Gene_name','Chrom','Strand','Pos','Startx','End','REF','ALT','splice_event_id']]\n",
    "#    names = gene.split(',')\n",
    "#    gene_start,gene_end = unionBoundry(names,gene_boundries)\n",
    "#    inside_gene.append(gene_start <= pos <= gene_end)\n",
    "#inside_gene = []\n",
    "#for i in tqdm(range(lead_sQTL.shape[0])):\n",
    "#    gene,chrm,strand,pos,jn_start,jn_end,ref_s,alt_s,event_id = lead_sQTL.iloc[i,:][['Gene_name','Chrom','Strand','Pos','Startx','End','REF','ALT','splice_event_id']]\n",
    "#    names = gene.split(',')\n",
    "#    inside_gene.append(is_inside_gene(names,gene_boundries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfastx\n",
    "data_dir = '../Data/'\n",
    "fasta_file_path = '../Data/genome.fa'\n",
    "gtf_file_path = '../Data/Homo_sapiens.GRCh38.87.gtf'\n",
    "fasta = pyfastx.Fasta(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACCUMULATION_STEPS = 1\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_GTEX_131222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_boundries = {}\n",
    "#for gene in tqdm(genes):\n",
    "#    gene_boundries[gene[\"gene_name\"][0]] = [int(gene[3]),int(gene[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-050422/gene_boundries.pkl', 'wb') as f:\n",
    "#    pickle.dump(gene_boundries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = pd.DataFrame({'Gene_name':'SCN9A','Chrom':'chr2','Strand':'-','Pos':166227736,'Startx':166227723,'End':166228691,'REF':'CAT','ALT':'C','splice_event_id':'?'},index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:16<00:00, 76.94s/it]\n"
     ]
    }
   ],
   "source": [
    "def predictSplicing(seq,models):\n",
    "    outputs = []\n",
    "    for i in range(seq.shape[0]):\n",
    "        batch_features = torch.tensor(seq[i,:,:], device=device).float().unsqueeze(0)\n",
    "        batch_features = torch.swapaxes(batch_features,1,2)\n",
    "        prediction = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        prediction = torch.stack(prediction)\n",
    "        prediction = torch.mean(prediction,dim=0)\n",
    "        outputs.append(prediction)\n",
    "    \n",
    "    outputs = torch.cat(outputs,dim=2)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    return outputs\n",
    "\n",
    "def plotPrediction(outputs):\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1,figsize=(22, 6),sharex=True)\n",
    "    x = np.arange(outputs.shape[2])\n",
    "    ax1.plot(x,outputs[0,1,:],linewidth=2,zorder=-32)\n",
    "    ax2.plot(x,outputs[0,2,:],linewidth=2,zorder=-32)\n",
    "    plt.xlabel('Distance from transcript start (nt)')\n",
    "    ax1.set_ylabel('Acceptor score')\n",
    "    ax2.set_ylabel('Donor Score')\n",
    "    ax1.legend(prop={'size': 14})\n",
    "    ax2.legend(prop={'size': 14})\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def ceil_div(x, y):\n",
    "\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "\n",
    "IN_MAP = np.asarray([[0, 0, 0, 0],\n",
    "                     [1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def one_hot_encode(Xd):\n",
    "\n",
    "    return IN_MAP[Xd.astype('int8')]\n",
    "\n",
    "def reformat_data(X0):\n",
    "    # This function converts X0, Y0 of the create_datapoints function into\n",
    "    # blocks such that the data is broken down into data points where the\n",
    "    # input is a sequence of length SL+CL_max corresponding to SL nucleotides\n",
    "    # of interest and CL_max context nucleotides, the output is a sequence of\n",
    "    # length SL corresponding to the splicing information of the nucleotides\n",
    "    # of interest. The CL_max context nucleotides are such that they are\n",
    "    # CL_max/2 on either side of the SL nucleotides of interest.\n",
    "\n",
    "    num_points = ceil_div(len(X0)-CL_max, SL)\n",
    "    Xd = np.zeros((num_points, SL+CL_max))\n",
    "    X0 = np.pad(X0, [0, SL], 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(num_points):\n",
    "        Xd[i] = X0[SL*i:CL_max+SL*(i+1)]\n",
    "\n",
    "    return Xd\n",
    "\n",
    "def seqToArray(seq,strand):\n",
    "    seq = 'N'*(CL_max//2) + seq + 'N'*(CL_max//2)\n",
    "    seq = seq.upper()\n",
    "    seq = re.sub(r'[^AGTC]', '0',seq)\n",
    "    seq = seq.replace('A', '1').replace('C', '2')\n",
    "    seq = seq.replace('G', '3').replace('T', '4').replace('N', '0')\n",
    "    if strand == '+':\n",
    "        X0 = np.asarray([int(x) for x in seq])\n",
    "            \n",
    "    elif strand == '-':\n",
    "        X0 = (5-np.asarray([int(x) for x in seq[::-1]])) % 5  # Reverse complement\n",
    "        \n",
    "    Xd = reformat_data(X0)\n",
    "    return  one_hot_encode(Xd)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in tqdm(range(to_test.shape[0])):\n",
    "    gene,chrm,strand,pos,jn_start,jn_end,ref_s,alt_s,event_id = to_test.iloc[i,:][['Gene_name','Chrom','Strand','Pos','Startx','End','REF','ALT','splice_event_id']]\n",
    "    names = gene.split(',')\n",
    "    gene_start,gene_end = unionBoundry(names,gene_boundries)\n",
    "    starts,ends = [],[]\n",
    "    if pos<jn_start:\n",
    "        start,end = np.max([pos-CL_max//2,gene_start]),np.min([jn_end+CL_max//2,gene_end])\n",
    "    elif jn_start<=pos<jn_end:\n",
    "        start,end = np.max([jn_start-CL_max//2,gene_start]),np.min([jn_end+CL_max//2,gene_end])\n",
    "    else:\n",
    "        start,end = np.max([jn_start-CL_max//2,gene_start]),np.min([pos+CL_max//2,gene_end])\n",
    "    if start < 1:\n",
    "        start = 1\n",
    "    #for name in names:\n",
    "    #    tmp = gene_boundries[name]\n",
    "    #    starts.append(tmp[0])\n",
    "    #    ends.append(tmp[1])\n",
    "\n",
    "    #gene_start,gene_end = np.min(starts),np.max(ends)\n",
    "\n",
    "     #= df_gene[].iloc[0]\n",
    "    #start,end = np.max([pos-CL_max//2,gene_start]),np.min([pos+CL_max//2,gene_end])\n",
    "\n",
    "    #if strand=='-':\n",
    "    #    starts,ends = [],[]\n",
    "    #    for i in range(df_gene.shape[0]):\n",
    "    #        starts.append(pos+df_gene['acceptor'].iloc[i]-CL_max//2)\n",
    "    #        ends.append(pos+df_gene['donor'].iloc[i]+CL_max//2)\n",
    "    #    start2,end2 = np.min(starts),np.max(ends)\n",
    "    #    start = np.min([start,start2])\n",
    "    #    end = np.max([end,end2])\n",
    "    #else:\n",
    "    #    starts,ends = [],[]\n",
    "    #    for i in range(df_gene.shape[0]):\n",
    "    #        starts.append(pos-df_gene['donor'].iloc[i]-CL_max//2)\n",
    "    #        ends.append(pos-df_gene['acceptor'].iloc[i]+CL_max//2)\n",
    "    #    start2,end2 = np.min(starts),np.max(ends)\n",
    "    #    start = np.min([start,start2])\n",
    "    #    end = np.max([end,end2])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        pos_s = pos-start\n",
    "        ref = fasta[chrm][start-1:end].seq\n",
    "        alt = ref\n",
    "        ref_len = len(ref_s)\n",
    "        alt_len = len(alt_s)\n",
    "        assert ref_s == ref[pos_s:(pos_s+ref_len)]\n",
    "        alt = alt[:pos_s]+alt_s+alt[(pos_s+ref_len):]\n",
    "        alt_align = np.arange(len(ref))\n",
    "        alt_align = np.concatenate([alt_align[:pos_s],np.repeat(pos_s,alt_len),alt_align[pos_s+ref_len:]])\n",
    "\n",
    "        ref_len2 = len(ref)\n",
    "        alt_len2 = len(alt)\n",
    "\n",
    "        ref = seqToArray(ref,strand)\n",
    "        alt = seqToArray(alt,strand)\n",
    "\n",
    "        ref_prediction = predictSplicing(ref,models)[0,:,:ref_len2]\n",
    "        alt_prediction = predictSplicing(alt,models)[0,:,:alt_len2]\n",
    "\n",
    "        tmp = np.zeros_like(ref_prediction)\n",
    "        if strand=='-':\n",
    "            ref_prediction = ref_prediction[:,::-1]\n",
    "            alt_prediction = alt_prediction[:,::-1]\n",
    "\n",
    "        ref_acceptor = ref_prediction[1,:]\n",
    "        alt_acceptor = alt_prediction[1,:]\n",
    "        ref_donor = ref_prediction[2,:]\n",
    "        alt_donor = alt_prediction[2,:]\n",
    "\n",
    "        delta_1_a = alt_acceptor[:pos_s]-ref_acceptor[:pos_s]\n",
    "        delta_1_d = alt_donor[:pos_s]-ref_donor[:pos_s]\n",
    "        delta_3_a = alt_acceptor[pos_s+alt_len:]-ref_acceptor[pos_s+ref_len:]\n",
    "        delta_3_d = alt_donor[pos_s+alt_len:]-ref_donor[pos_s+ref_len:]\n",
    "\n",
    "\n",
    "        if ref_len2==alt_len2:\n",
    "            delta_2_a = alt_acceptor[pos_s:pos_s+ref_len]-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "            delta_2_d = alt_donor[pos_s:pos_s+ref_len]-ref_donor[pos_s:pos_s+ref_len]\n",
    "        elif ref_len2>alt_len2:\n",
    "            a_pad = np.pad(alt_acceptor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "            d_pad = np.pad(alt_donor[pos_s:pos_s+alt_len],(0, ref_len-alt_len), 'constant', constant_values=0)\n",
    "            delta_2_a = a_pad-ref_acceptor[pos_s:pos_s+ref_len]\n",
    "            delta_2_d = d_pad-ref_donor[pos_s:pos_s+ref_len]\n",
    "\n",
    "        elif ref_len2<alt_len2:\n",
    "            a_pad = np.pad(ref_acceptor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "            d_pad = np.pad(ref_donor[pos_s:pos_s+ref_len],(0, alt_len-ref_len), 'constant', constant_values=0)\n",
    "            delta_2_a = alt_acceptor[pos_s:pos_s+alt_len]-a_pad\n",
    "            delta_2_d = alt_donor[pos_s:pos_s+alt_len]-d_pad\n",
    "\n",
    "            delta_2_a =np.append(delta_2_a[:ref_len-1],delta_2_a[np.argmax(np.absolute(delta_2_a[ref_len-1:alt_len]))])\n",
    "            delta_2_d =np.append(delta_2_d[:ref_len-1],delta_2_d[np.argmax(np.absolute(delta_2_d[ref_len-1:alt_len]))])\n",
    "\n",
    "        acceptorDelta = np.concatenate([delta_1_a,delta_2_a,delta_3_a])\n",
    "        donorDelta = np.concatenate([delta_1_d,delta_2_d,delta_3_d])\n",
    "\n",
    "        if strand=='-':\n",
    "            acceptor_loc =jn_start-start\n",
    "            donor_loc = jn_end-start+1\n",
    "        else:\n",
    "            acceptor_loc = jn_end-start+1\n",
    "            donor_loc = jn_start-start\n",
    "\n",
    "        acceptor_delta_nr = alt_acceptor.shape[0]-np.argsort(np.argsort(np.absolute(acceptorDelta)))[acceptor_loc]\n",
    "        donor_delta_nr = alt_donor.shape[0]-np.argsort(np.argsort(np.absolute(donorDelta)))[donor_loc]\n",
    "        top_a_creation_pos = np.argmax(acceptorDelta)\n",
    "        top_d_creation_pos = np.argmax(donorDelta)\n",
    "        top_a_disruption_pos = np.argmin(acceptorDelta)\n",
    "        top_d_disruption_pos = np.argmin(donorDelta)\n",
    "        top_a_creation_delta = acceptorDelta[top_a_creation_pos]\n",
    "        top_d_creation_delta = donorDelta[top_d_creation_pos]\n",
    "        top_a_disruption_delta = acceptorDelta[top_a_disruption_pos]\n",
    "        top_d_disruption_delta = donorDelta[top_d_disruption_pos]\n",
    "\n",
    "        results[event_id] = [acceptorDelta[acceptor_loc],donorDelta[donor_loc],ref_acceptor[acceptor_loc],ref_donor[donor_loc],alt_acceptor[acceptor_loc],alt_donor[donor_loc],acceptor_delta_nr,donor_delta_nr,start+top_a_creation_pos,start+top_d_creation_pos,start+top_a_disruption_pos,start+top_d_disruption_pos,top_a_creation_delta,top_d_creation_delta,-top_a_disruption_delta,-top_d_disruption_delta]\n",
    "    except:\n",
    "        print('{} failed'.format(event_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(results).T\n",
    "df1.columns = ['acceptor_delta','donor_delta','ref_acceptor','ref_donor','alt_acceptor','alt_donor','acceptor_delta_order','donor_delta_order','top_a_creation_pos','top_d_creation_pos','top_a_disruption_pos','top_d_disruption_pos','top_a_creation_delta','top_d_creation_delta','top_a_disruption_delta','top_d_disruption_delta']\n",
    "df1.index.name = 'splice_event_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceptor_delta</th>\n",
       "      <th>donor_delta</th>\n",
       "      <th>ref_acceptor</th>\n",
       "      <th>ref_donor</th>\n",
       "      <th>alt_acceptor</th>\n",
       "      <th>alt_donor</th>\n",
       "      <th>acceptor_delta_order</th>\n",
       "      <th>donor_delta_order</th>\n",
       "      <th>top_a_creation_pos</th>\n",
       "      <th>top_d_creation_pos</th>\n",
       "      <th>top_a_disruption_pos</th>\n",
       "      <th>top_d_disruption_pos</th>\n",
       "      <th>top_a_creation_delta</th>\n",
       "      <th>top_d_creation_delta</th>\n",
       "      <th>top_a_disruption_delta</th>\n",
       "      <th>top_d_disruption_delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splice_event_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>-0.93297</td>\n",
       "      <td>-2.749875e-07</td>\n",
       "      <td>0.996282</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>166227735.0</td>\n",
       "      <td>166227527.0</td>\n",
       "      <td>166227723.0</td>\n",
       "      <td>166227670.0</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.008653</td>\n",
       "      <td>0.93297</td>\n",
       "      <td>0.572203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acceptor_delta   donor_delta  ref_acceptor  ref_donor  \\\n",
       "splice_event_id                                                          \n",
       "?                      -0.93297 -2.749875e-07      0.996282   0.000044   \n",
       "\n",
       "                 alt_acceptor  alt_donor  acceptor_delta_order  \\\n",
       "splice_event_id                                                  \n",
       "?                    0.063312   0.021675                  -1.0   \n",
       "\n",
       "                 donor_delta_order  top_a_creation_pos  top_d_creation_pos  \\\n",
       "splice_event_id                                                              \n",
       "?                            871.0         166227735.0         166227527.0   \n",
       "\n",
       "                 top_a_disruption_pos  top_d_disruption_pos  \\\n",
       "splice_event_id                                               \n",
       "?                         166227723.0           166227670.0   \n",
       "\n",
       "                 top_a_creation_delta  top_d_creation_delta  \\\n",
       "splice_event_id                                               \n",
       "?                            0.390159              0.008653   \n",
       "\n",
       "                 top_a_disruption_delta  top_d_disruption_delta  \n",
       "splice_event_id                                                  \n",
       "?                               0.93297                0.572203  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "166227723-166227736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-66"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "166227670-166227736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
