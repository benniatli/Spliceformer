{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.models import SpliceAI_10K\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d,kullback_leibler_divergence_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 10:46:03 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    38W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:98:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-PCI...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    40W / 250W |      0MiB / 40960MiB |     31%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in tqdm(gene_to_label.keys()):\n",
    "#    for d_key in gene_to_label[key][0]:\n",
    "#        gene_to_label[key][0][d_key] = 1\n",
    "#    for d_key in gene_to_label[key][1]:\n",
    "#        gene_to_label[key][1][d_key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation_train,gene_to_label,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//2, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:35<00:00,  4.25it/s, a_r=0.656, d_r=0.651, loss=0.000802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/4: 100%|███████████████████████████████████| 306/306 [00:29<00:00, 10.37it/s, a_r=0.61, d_r=0.594, loss=0.000988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9956\t0.7342\t0.8571\t0.9355\t0.8221\t0.9596\t0.2082\t0.0513\t0.0139\t14451\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9964\t0.7336\t0.858\t0.9375\t0.8215\t0.9474\t0.1840\t0.0439\t0.0112\t14755\t20114.0\t20114\n",
      "epoch: 1/4, val loss = 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████| 1425/1425 [05:24<00:00,  4.39it/s, a_r=0.657, d_r=0.645, loss=0.00081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/4: 100%|███████████████████████████████████| 306/306 [00:31<00:00,  9.79it/s, a_r=0.614, d_r=0.623, loss=0.00096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9954\t0.7386\t0.8648\t0.9422\t0.8281\t0.9581\t0.2110\t0.0532\t0.0143\t14537\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9961\t0.736\t0.8667\t0.9416\t0.8271\t0.9630\t0.2796\t0.0807\t0.0223\t14804\t20114.0\t20114\n",
      "epoch: 2/4, val loss = 0.000808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:21<00:00,  4.43it/s, a_r=0.662, d_r=0.656, loss=0.000778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/4: 100%|███████████████████████████████████| 306/306 [00:33<00:00,  9.11it/s, a_r=0.61, d_r=0.608, loss=0.000949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9963\t0.7414\t0.8675\t0.943\t0.8306\t0.9597\t0.1956\t0.0468\t0.0122\t14593\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9965\t0.7401\t0.8691\t0.9429\t0.8293\t0.9656\t0.2231\t0.0566\t0.0144\t14886\t20114.0\t20114\n",
      "epoch: 3/4, val loss = 0.000799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.66, d_r=0.649, loss=0.000756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/4: 100%|████████████████████████████████████| 306/306 [00:33<00:00,  9.11it/s, a_r=0.618, d_r=0.62, loss=0.00094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9959\t0.7433\t0.87\t0.9445\t0.8329\t0.9584\t0.2125\t0.0532\t0.0139\t14630\t19682.0\t19682\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9967\t0.7413\t0.8707\t0.9434\t0.8314\t0.9683\t0.2580\t0.0676\t0.0166\t14910\t20114.0\t20114\n",
      "epoch: 4/4, val loss = 0.000789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:21<00:00,  4.43it/s, a_r=0.652, d_r=0.652, loss=0.000804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.659, d_r=0.647, loss=0.000774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████| 1425/1425 [05:17<00:00,  4.49it/s, a_r=0.659, d_r=0.65, loss=0.000759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.672, d_r=0.658, loss=0.00075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.651, d_r=0.646, loss=0.000823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:17<00:00,  4.49it/s, a_r=0.665, d_r=0.655, loss=0.000765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.654, d_r=0.645, loss=0.000763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████| 1425/1425 [05:17<00:00,  4.49it/s, a_r=0.666, d_r=0.649, loss=0.000762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.65, d_r=0.643, loss=0.000812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.662, d_r=0.648, loss=0.000768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.651, d_r=0.654, loss=0.00077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████| 1425/1425 [05:17<00:00,  4.49it/s, a_r=0.665, d_r=0.658, loss=0.000766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.654, d_r=0.655, loss=0.000804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:17<00:00,  4.49it/s, a_r=0.657, d_r=0.652, loss=0.000799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.664, d_r=0.651, loss=0.000764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████| 1425/1425 [05:19<00:00,  4.47it/s, a_r=0.666, d_r=0.66, loss=0.000747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.648, d_r=0.641, loss=0.000829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.653, d_r=0.651, loss=0.000805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.657, d_r=0.647, loss=0.000782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.672, d_r=0.664, loss=0.000752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.644, d_r=0.634, loss=0.000811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.652, d_r=0.645, loss=0.000789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.663, d_r=0.655, loss=0.000784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.661, d_r=0.656, loss=0.000763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.645, d_r=0.647, loss=0.000821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.653, d_r=0.638, loss=0.000817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.662, d_r=0.656, loss=0.000764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████| 1425/1425 [05:19<00:00,  4.47it/s, a_r=0.668, d_r=0.66, loss=0.000743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.649, d_r=0.646, loss=0.000827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.661, d_r=0.649, loss=0.000775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.667, d_r=0.659, loss=0.000769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████| 1425/1425 [05:18<00:00,  4.47it/s, a_r=0.658, d_r=0.66, loss=0.000748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████| 1425/1425 [05:19<00:00,  4.46it/s, a_r=0.651, d_r=0.645, loss=0.000807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████| 1425/1425 [05:21<00:00,  4.44it/s, a_r=0.652, d_r=0.644, loss=0.000785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████| 1425/1425 [05:18<00:00,  4.48it/s, a_r=0.663, d_r=0.652, loss=0.000771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████| 1425/1425 [05:17<00:00,  4.48it/s, a_r=0.669, d_r=0.658, loss=0.000747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceAI_10K(CL_max)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_191022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/spliceai_encoder_10k_GTEX_021222_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=False,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=False,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:42<00:00, 10.14s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/SpliceAITrainingCode/dataset_test_0_10k.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00046280436537960215\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.995\t0.9305\t0.9844\t0.9885\t0.9684\t0.9902\t0.7589\t0.1575\t0.0407\t13296\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9947\t0.9349\t0.9868\t0.991\t0.9721\t0.9902\t0.7683\t0.1629\t0.0417\t13359\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [23:40<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0003201272902582534\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9799\t0.9255\t0.9885\t0.9948\t0.9583\t0.9916\t0.8257\t0.1771\t0.0503\t83027\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9815\t0.9302\t0.9916\t0.9964\t0.9634\t0.9916\t0.8360\t0.1814\t0.0518\t83451\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 774/774 [14:43<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_GTEX_021222_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0006331044024737925\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9969\t0.752\t0.8861\t0.958\t0.844\t0.9496\t0.2297\t0.0638\t0.0171\t67381\t89600.0\t89600\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9965\t0.7499\t0.8817\t0.9521\t0.8397\t0.9468\t0.2250\t0.0633\t0.0169\t68448\t91272.0\t91272\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/spliceai_10k_test_set_predictions_120123.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75095"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.752+0.7499)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84185"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.844+0.8397)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67381+68448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
