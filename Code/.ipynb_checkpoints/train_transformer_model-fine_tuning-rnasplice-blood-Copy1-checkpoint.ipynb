{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.model import SpliceFormer\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 31 12:07:41 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-DGXS-32GB            Off| 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   36C    P0               38W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS-32GB            Off| 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   36C    P0               37W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS-32GB            Off| 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   37C    P0               37W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS-32GB            Off| 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   34C    P0               37W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-250523/'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_rnasplice-blood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_to_label_2 = defaultdict(list)\n",
    "#for key in tqdm(gene_to_label.keys()):\n",
    "#    jn_start, jn_end = gene_to_label[key]\n",
    "#    jn_starts = defaultdict(int)\n",
    "#    jn_ends = defaultdict(int)\n",
    "#    for jn in jn_start:\n",
    "#        jn_starts[jn] = 1\n",
    "#    for jn in jn_end:\n",
    "#        jn_ends[jn] = 1\n",
    "#    gene_to_label_2[key] = [jn_starts,jn_ends]\n",
    "    \n",
    "#gene_to_label = gene_to_label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation_train,gene_to_label,SL,CL_max,shift=SL))\n",
    "val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//4, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:57<00:00,  1.25s/it, a_r=0.754, d_r=0.783, loss=0.000444, r_a=0.997, r_d=0.997, r_loss=4.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 685/685 [06:35<00:00,  1.73it/s, a_r=0.764, d_r=0.789, loss=0.000619, r_a=0.997, r_d=0.997, r_loss=5.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9968\t0.8112\t0.9043\t0.9576\t0.886\t0.9899\t0.1975\t0.0490\t0.0140\t14415\t17769.0\t17769\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9979\t0.8378\t0.9279\t0.9661\t0.909\t0.9916\t0.1938\t0.0409\t0.0102\t14197\t16946.0\t16946\n",
      "epoch: 1/4, val loss = 0.000455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:28<00:00,  1.23s/it, a_r=0.757, d_r=0.787, loss=0.000423, r_a=0.997, r_d=0.998, r_loss=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 685/685 [06:50<00:00,  1.67it/s, a_r=0.752, d_r=0.791, loss=0.000614, r_a=0.997, r_d=0.998, r_loss=5.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9973\t0.8141\t0.9092\t0.9591\t0.8883\t0.9921\t0.1560\t0.0349\t0.0085\t14466\t17769.0\t17769\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9981\t0.8398\t0.9313\t0.9687\t0.9114\t0.9947\t0.1909\t0.0373\t0.0083\t14231\t16946.0\t16946\n",
      "epoch: 2/4, val loss = 0.000450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:47<00:00,  1.25s/it, a_r=0.757, d_r=0.784, loss=0.000409, r_a=0.997, r_d=0.997, r_loss=4.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 685/685 [06:36<00:00,  1.73it/s, a_r=0.764, d_r=0.789, loss=0.000606, r_a=0.997, r_d=0.997, r_loss=5.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9973\t0.8144\t0.9109\t0.9612\t0.8893\t0.9944\t0.1997\t0.0456\t0.0108\t14471\t17769.0\t17769\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9976\t0.8396\t0.932\t0.97\t0.9118\t0.9951\t0.1946\t0.0367\t0.0076\t14228\t16946.0\t16946\n",
      "epoch: 3/4, val loss = 0.000446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:32<00:00,  1.24s/it, a_r=0.765, d_r=0.792, loss=0.000395, r_a=0.998, r_d=0.998, r_loss=4.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 685/685 [06:52<00:00,  1.66it/s, a_r=0.761, d_r=0.792, loss=0.000606, r_a=0.998, r_d=0.998, r_loss=5.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9968\t0.8151\t0.912\t0.9608\t0.8899\t0.9955\t0.1817\t0.0417\t0.0103\t14483\t17769.0\t17769\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9974\t0.8413\t0.9324\t0.9701\t0.9119\t0.9972\t0.2045\t0.0394\t0.0085\t14257\t16946.0\t16946\n",
      "epoch: 4/4, val loss = 0.000446\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:50<00:00,  1.25s/it, a_r=0.75, d_r=0.781, loss=0.000438, r_a=0.997, r_d=0.997, r_loss=3.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:48<00:00,  1.25s/it, a_r=0.752, d_r=0.784, loss=0.000423, r_a=0.997, r_d=0.998, r_loss=3.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:58<00:00,  1.25s/it, a_r=0.758, d_r=0.781, loss=0.000407, r_a=0.997, r_d=0.998, r_loss=3.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:24<00:00,  1.23s/it, a_r=0.761, d_r=0.787, loss=0.000404, r_a=0.998, r_d=0.998, r_loss=3.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:27<00:00,  1.23s/it, a_r=0.757, d_r=0.783, loss=0.000429, r_a=0.997, r_d=0.997, r_loss=3.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:18<00:00,  1.23s/it, a_r=0.757, d_r=0.787, loss=0.000439, r_a=0.997, r_d=0.998, r_loss=3.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:45<00:00,  1.24s/it, a_r=0.758, d_r=0.79, loss=0.000402, r_a=0.997, r_d=0.998, r_loss=3.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:40<00:00,  1.24s/it, a_r=0.763, d_r=0.792, loss=0.000398, r_a=0.997, r_d=0.998, r_loss=3.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:46<00:00,  1.24s/it, a_r=0.755, d_r=0.779, loss=0.000437, r_a=0.992, r_d=0.996, r_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:35<00:00,  1.24s/it, a_r=0.763, d_r=0.785, loss=0.000423, r_a=0.994, r_d=0.996, r_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:35<00:00,  1.24s/it, a_r=0.766, d_r=0.792, loss=0.000403, r_a=0.995, r_d=0.996, r_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:43<00:00,  1.24s/it, a_r=0.764, d_r=0.788, loss=0.000393, r_a=0.995, r_d=0.997, r_loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:48<00:00,  1.25s/it, a_r=0.748, d_r=0.777, loss=0.000446, r_a=0.997, r_d=0.997, r_loss=3.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:36<00:00,  1.24s/it, a_r=0.753, d_r=0.787, loss=0.000423, r_a=0.997, r_d=0.997, r_loss=2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:31<00:00,  1.23s/it, a_r=0.762, d_r=0.788, loss=0.000397, r_a=0.998, r_d=0.998, r_loss=3.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:40<00:00,  1.24s/it, a_r=0.765, d_r=0.795, loss=0.000397, r_a=0.998, r_d=0.998, r_loss=3.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:25<00:00,  1.23s/it, a_r=0.749, d_r=0.78, loss=0.00045, r_a=0.997, r_d=0.997, r_loss=7.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:31<00:00,  1.23s/it, a_r=0.762, d_r=0.786, loss=0.000421, r_a=0.997, r_d=0.998, r_loss=7.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:21<00:00,  1.23s/it, a_r=0.753, d_r=0.784, loss=0.000418, r_a=0.997, r_d=0.998, r_loss=6.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:33<00:00,  1.24s/it, a_r=0.756, d_r=0.789, loss=0.000412, r_a=0.998, r_d=0.998, r_loss=7.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:36<00:00,  1.24s/it, a_r=0.757, d_r=0.784, loss=0.000433, r_a=0.997, r_d=0.997, r_loss=7.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:42<00:00,  1.24s/it, a_r=0.756, d_r=0.781, loss=0.000424, r_a=0.998, r_d=0.997, r_loss=6.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:49<00:00,  1.25s/it, a_r=0.756, d_r=0.786, loss=0.000417, r_a=0.998, r_d=0.998, r_loss=6.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:37<00:00,  1.24s/it, a_r=0.757, d_r=0.79, loss=0.000402, r_a=0.998, r_d=0.998, r_loss=6.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:36<00:00,  1.24s/it, a_r=0.753, d_r=0.787, loss=0.000435, r_a=0.997, r_d=0.996, r_loss=6.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:28<00:00,  1.23s/it, a_r=0.756, d_r=0.783, loss=0.000425, r_a=0.997, r_d=0.998, r_loss=6.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:17<00:00,  1.22s/it, a_r=0.754, d_r=0.783, loss=0.000419, r_a=0.998, r_d=0.998, r_loss=6.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:31<00:00,  1.23s/it, a_r=0.763, d_r=0.793, loss=0.0004, r_a=0.998, r_d=0.998, r_loss=6.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:27<00:00,  1.23s/it, a_r=0.76, d_r=0.785, loss=0.000438, r_a=0.997, r_d=0.998, r_loss=6.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:37<00:00,  1.24s/it, a_r=0.753, d_r=0.779, loss=0.00042, r_a=0.997, r_d=0.997, r_loss=6.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:38<00:00,  1.24s/it, a_r=0.757, d_r=0.784, loss=0.000418, r_a=0.997, r_d=0.998, r_loss=6.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [30:26<00:00,  1.23s/it, a_r=0.763, d_r=0.789, loss=0.000407, r_a=0.998, r_d=0.998, r_loss=7.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4:  20%|██████████████████████████████▌                                                                                                                        | 300/1484 [06:19<24:49,  1.26s/it, a_r=0.758, d_r=0.784, loss=0.000485, r_a=0.946, r_d=0.946, r_loss=6.31]"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_250523_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    if model_nr>0:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    else:\n",
    "        h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "        plt.plot(range(epochs),h['loss'],label='Train')\n",
    "        plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [59:36<00:00,  2.41s/it, a_r=0.751, d_r=0.78, loss=0.000441, r_a=0.997, r_d=0.997, r_loss=6.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.000468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [57:47<00:00,  2.34s/it, a_r=0.76, d_r=0.791, loss=0.000416, r_a=0.997, r_d=0.997, r_loss=6.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [57:42<00:00,  2.33s/it, a_r=0.759, d_r=0.783, loss=0.000419, r_a=0.998, r_d=0.998, r_loss=6.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1484/1484 [57:41<00:00,  2.33s/it, a_r=0.764, d_r=0.791, loss=0.000388, r_a=0.998, r_d=0.998, r_loss=6.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_nr = 9\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "model_m.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_171022_{}'.format(model_nr)))\n",
    "modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_250523_{}'.format(model_nr)\n",
    "loss = categorical_crossentropy_2d().loss\n",
    "#loss = kl_div_2d(temp=temp).loss\n",
    "optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "if model_nr>0:\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "else:\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,val_loader,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=False,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=True,continous_labels=False)\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [09:27<00:00, 33.40s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/Data/SplicePrediction/gencode_40k_dataset_test_.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_250523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.00034991839976935375\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9961\t0.9418\t0.9838\t0.9885\t0.9736\t0.9952\t0.5718\t0.0776\t0.0195\t13458\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9962\t0.9456\t0.9866\t0.9914\t0.977\t0.9964\t0.6013\t0.0686\t0.0153\t13511\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    \n",
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_250523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_rnasplice-blood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [1:06:36<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(CL_max,bn_momentum=0.01/NUM_ACCUMULATION_STEPS,depth=4,heads=4,n_transformer_blocks=2,determenistic=True)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_finetune_rnasplice-blood_250523_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features)[0].detach() for i in range(n_models)])\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.000331228598385847\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9965\t0.8262\t0.9246\t0.9696\t0.9009\t0.9914\t0.2020\t0.0451\t0.0116\t60503\t73232.0\t73232\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9966\t0.8476\t0.9393\t0.9765\t0.9173\t0.9937\t0.2133\t0.0410\t0.0097\t59820\t70579.0\t70579\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor>0, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor>0, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'Y_true_acceptor':Y_true_acceptor,'Y_pred_acceptor':Y_pred_acceptor,'Y_true_donor':Y_true_donor,'Y_pred_donor':Y_pred_donor})\n",
    "#df.to_csv('/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood/transformer_40k_test_set_predictions_120123.gz',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
