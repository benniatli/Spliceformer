{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gffutils\n",
    "#gtf = gffutils.FeatureDB(\"/odinn/tmp/benediktj/Data/SplicePrediction/Homo_sapiens.GRCh38.87.db\")\n",
    "#transcriptToLSupport = {}\n",
    "#setType = 'train'\n",
    "#for transcript_id in tqdm(annotation['transcript']):\n",
    "#    transcript = gtf[transcript_id.split('.')[0]]\n",
    "#    transcriptToLSupport[transcript_id] = int(transcript[\"transcript_support_level\"][0])\n",
    "#gtf = gffutils.FeatureDB(\"/odinn/tmp/benediktj/Data/SplicePrediction/Homo_sapiens.GRCh38.87.db\")\n",
    "#genes = gtf.features_of_type('gene')\n",
    "#geneStartEnd = {}\n",
    "#for gene in tqdm(genes):\n",
    "#    if gene['gene_biotype'][0]=='protein_coding':\n",
    "#        geneStartEnd['{}.{}'.format(gene['gene_id'][0],gene['gene_version'][0])] = [gene[3],gene[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction'\n",
    "#with open(data_dir+'geneStartEnd.pickle', 'wb') as handle:\n",
    "#    pickle.dump(geneStartEnd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open(data_dir+'/transcriptSupport.pickle', 'wb') as handle:\n",
    "#    pickle.dump(transcriptToLSupport, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-050422/'\n",
    "#with open(data_dir+'transcriptSupport.pickle', 'rb') as handle:\n",
    "#    transcriptToSupport = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Model\n",
    "###############################################################################\n",
    "\n",
    "L = 32\n",
    "N_GPUS = 2\n",
    "\n",
    "#if int(sys.argv[1]) == 80:\n",
    "#    W = np.asarray([11, 11, 11, 11])\n",
    "#    AR = np.asarray([1, 1, 1, 1])\n",
    "#    BATCH_SIZE = 18*N_GPUS\n",
    "#elif int(sys.argv[1]) == 400:\n",
    "#    W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11])\n",
    "#    AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4])\n",
    "#    BATCH_SIZE = 18*N_GPUS\n",
    "#elif int(sys.argv[1]) == 2000:\n",
    "#    W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "#                    21, 21, 21, 21])\n",
    "#    AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "#                     10, 10, 10, 10])\n",
    "#    BATCH_SIZE = 12*N_GPUS\n",
    "#elif int(sys.argv[1]) == 10000:\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 6*N_GPUS\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-050422'\n",
    "setType = 'train'\n",
    "#with open('{}/sparse_sequence_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    seqData = pickle.load(handle)\n",
    "    \n",
    "with open('{}/sparse_discrete_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "    transcriptToLabel = pickle.load(handle)\n",
    "    \n",
    "CHROM_TRAIN = ['chr11', 'chr13', 'chr15', 'chr17', 'chr19', 'chr21',\n",
    "                           'chr2', 'chr4', 'chr6', 'chr8', 'chr10', 'chr12',\n",
    "                           'chr14', 'chr16', 'chr18', 'chr20', 'chr22', 'chrX', 'chrY']\n",
    "annotation = pd.read_csv(data_dir+'/annotation_ensembl_v87_train.txt',sep='\\t',header=None)[[0,1,2,3,4]]\n",
    "annotation.columns = ['name','chrom','strand','tx_start','tx_end']\n",
    "annotation['transcript'] = annotation['name'].apply(lambda x: x.split('---')[-2].split('.')[0]).values\n",
    "annotation['gene'] = annotation['name'].apply(lambda x: x.split('---')[-3].split('.')[0]).values\n",
    "#annotation['support'] = annotation['transcript'].apply(lambda x:transcriptToSupport[x])\n",
    "\n",
    "chrom_paths = glob(data_dir+'/sparse_sequence_data/*')\n",
    "chromToPath = {}\n",
    "for path in chrom_paths:\n",
    "    chromToPath[path.split('/')[-1].split('_')[0]] = path\n",
    "    \n",
    "seqData = {}\n",
    "for chrom in CHROM_TRAIN:\n",
    "    seqData[chrom] = load_npz(data_dir+'/sparse_sequence_data/{}_train.npz'.format(chrom)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_max=40000\n",
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "\n",
    "SL=5000\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "#splice_table='/odinn/tmp/benediktj/Data/SplicePrediction/annotation_ensembl_v87_train.txt'\n",
    "#ref_genome='/odinn/tmp/benediktj/SpliceAITrainingCode/genome.fa'\n",
    "# Input details\n",
    "\n",
    "#data_dir='/odinn/tmp/benediktj/Data/SplicePrediction/'\n",
    "#sequence='/odinn/tmp/benediktj/SpliceAITrainingCode/canonical_sequence.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0\n",
    "\n",
    "def print_topl_statistics(y_true, y_pred):\n",
    "    # Prints the following information: top-kL statistics for k=0.5,1,2,4,\n",
    "    # auprc, thresholds for k=0.5,1,2,4, number of true splice sites.\n",
    "\n",
    "    idx_true = np.nonzero(y_true == 1)[0]\n",
    "    argsorted_y_pred = np.argsort(y_pred)\n",
    "    sorted_y_pred = np.sort(y_pred)\n",
    "\n",
    "    topkl_accuracy = []\n",
    "    threshold = []\n",
    "\n",
    "    for top_length in [0.5, 1, 2, 4]:\n",
    "\n",
    "        idx_pred = argsorted_y_pred[-int(top_length*len(idx_true)):]\n",
    "\n",
    "        topkl_accuracy += [np.size(np.intersect1d(idx_true, idx_pred)) \\\n",
    "                  / float(min(len(idx_pred), len(idx_true)))]\n",
    "        threshold += [sorted_y_pred[-int(top_length*len(idx_true))]]\n",
    "\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "          np.round(topkl_accuracy[0],4), np.round(topkl_accuracy[1],4), np.round(topkl_accuracy[2],4),\n",
    "          np.round(topkl_accuracy[3],4), np.round(auprc,4), np.round(threshold[0],4), np.round(threshold[1],4),\n",
    "          np.round(threshold[2],4), np.round(threshold[3],4), len(idx_true)))\n",
    "    return (topkl_accuracy,[auprc],threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        \n",
    "        self.gate = nn.Linear(dim, inner_dim)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "        \n",
    "        \n",
    "        \n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        #indices = torch.triu_indices(dots.shape[2], dots.shape[3], offset=1)\n",
    "        #dots[:,:, indices[0], indices[1]] = float('-inf')\n",
    "        \n",
    "        attn = self.attend(dots)\n",
    "        \n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = torch.sigmoid(self.gate(x))*out\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = torch.arange(x.shape[1], device=x.device).type_as(self.inv_freq)\n",
    "        sinusoid_inp = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        emb = torch.cat((sinusoid_inp.sin(), sinusoid_inp.cos()), dim=-1)\n",
    "        return emb[None, :, :]\n",
    "\n",
    "def activation_func(activation):\n",
    "    return  nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size,dilation=1, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        paddingAmount = int(dilation*(kernel_size-1)/2)\n",
    "        self.convlayer1 = nn.Conv1d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size= kernel_size,dilation=dilation,stride=1,padding=paddingAmount,padding_mode='zeros')\n",
    "        self.convlayer2 = nn.Conv1d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size= kernel_size,dilation=dilation,stride=1,padding=paddingAmount,padding_mode='zeros')\n",
    "        self.activate = activation_func(activation)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_channels, momentum=0.01)\n",
    "        self.bn2 = nn.BatchNorm1d(self.in_channels, momentum=0.01)\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        residual = self.shortcut(x)\n",
    "        x = self.activate(self.bn1(x))\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.activate(self.bn2(x))\n",
    "        x = self.convlayer2(x)\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "class ResComboBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,res_W,res_dilation):\n",
    "        super().__init__()\n",
    "        self.comboBlock = nn.Sequential(\n",
    "        ResidualBlock(in_channels,out_channels,res_W,res_dilation),\n",
    "        ResidualBlock(in_channels,out_channels,res_W,res_dilation),\n",
    "        ResidualBlock(in_channels,out_channels,res_W,res_dilation),\n",
    "        ResidualBlock(in_channels,out_channels,res_W,res_dilation)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.comboBlock(x)\n",
    "    \n",
    "class smallModel(nn.Module):\n",
    "    def __init__(self, temp=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_channels = 32\n",
    "        self.res_W = [11,11,21,41]\n",
    "        res_dilation = [1,4,10,25]\n",
    "        self.kernel_size = 1\n",
    "        self.temp=temp\n",
    "        self.conv_layer_1 = nn.Conv1d(in_channels=5, out_channels=self.n_channels, kernel_size= self.kernel_size,stride=1)\n",
    "        self.skip_layers = nn.ModuleList([nn.Conv1d(in_channels=self.n_channels, out_channels=self.n_channels, kernel_size= self.kernel_size,stride=1) for i in range(5)])\n",
    "        self.res_layers = nn.ModuleList([ResComboBlock(in_channels=self.n_channels, out_channels=self.n_channels, res_W=self.res_W[i], res_dilation=res_dilation[i]) for i in range(4)])\n",
    "        self.conv_final = nn.Conv1d(in_channels=self.n_channels, out_channels=3, kernel_size= self.kernel_size,stride=1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        x = self.conv_layer_1(features)\n",
    "        skip = self.skip_layers[0](x)\n",
    "\n",
    "        for i,residualUnit in enumerate(self.res_layers):\n",
    "            x = residualUnit(x)\n",
    "            #if i ==2:\n",
    "            #    x_2 = x\n",
    "            skip += self.skip_layers[i+1](x)\n",
    "            #skip = torch.cat([skip,self.skip_layers[i+1](x)],axis=1)\n",
    "        \n",
    "        x_skip = skip[:,:,:]\n",
    "        x_cropped = skip[:,:,CL_max//2:-CL_max//2]\n",
    "        #x = self.conv_final(x_cropped)\n",
    "        #m_1 = nn.Softmax(dim=1)\n",
    "        #out_1 = m_1(x/temp)\n",
    "        #attention = m_1(self.conv_final(x_skip)/temp)\n",
    "        return x_cropped, x_skip\n",
    "    \n",
    "class SpliceFormerBlock(nn.Module):\n",
    "    def __init__(self, temp=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_channels = 32\n",
    "        \n",
    "        self.maxSeqLength = 4*128\n",
    "        \n",
    "        #self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=32, dim_feedforward=128*4, nhead=8,norm_first=True), num_layers=12)\n",
    "        self.transformer =  Transformer(self.n_channels, depth=4, heads=4, dim_head=32, mlp_dim=self.n_channels*16, dropout=0)\n",
    "        \n",
    "    def forward(self, x_skip,attention,pos_emb):\n",
    "        x_emb1 = torch.transpose(x_skip, 1, 2)\n",
    "        x_emb = x_emb1 +  pos_emb\n",
    "        acceptors_sorted = torch.argsort(attention[:,1,:],dim=1,descending=True)[:,:self.maxSeqLength//2:]\n",
    "        donors_sorted = torch.argsort(attention[:,2,:],dim=1,descending=True)[:,:self.maxSeqLength//2]\n",
    "        splice_idx = torch.cat([acceptors_sorted,donors_sorted],dim=1)\n",
    "        splice_idx = torch.sort(splice_idx,dim=1).values\n",
    "        splice_idx = splice_idx.unsqueeze(2).repeat(1,1,self.n_channels)\n",
    "        embedding = torch.gather(x_emb,1,splice_idx)\n",
    "        embedding = self.transformer(embedding)\n",
    "        tmp = torch.zeros_like(x_emb1)\n",
    "        embedding = tmp.scatter_(1, splice_idx, embedding) \n",
    "        embedding = torch.transpose(embedding, 1, 2)\n",
    "        #embedding = x_skip+embedding\n",
    "        return embedding\n",
    "    \n",
    "class SpliceFormer(nn.Module):\n",
    "    def __init__(self, temp=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_channels = 32\n",
    "        self.res_W = [11,11,21,41]\n",
    "        res_dilation = [1,4,10,25]\n",
    "        self.kernel_size = 1\n",
    "        self.smallModel = smallModel(temp=temp).apply(keras_init)\n",
    "        #self.res_kernel_size = 11\n",
    "        self.temp=temp\n",
    "        self.skip_layers = nn.ModuleList([nn.Conv1d(in_channels=self.n_channels, out_channels=self.n_channels, kernel_size= self.kernel_size,stride=1) for i in range(2)])\n",
    "        self.res_layers = nn.ModuleList([ResComboBlock(in_channels=self.n_channels, out_channels=self.n_channels, res_W=self.res_W[i], res_dilation=res_dilation[i]) for i in range(1)])\n",
    "        self.conv_final = nn.Conv1d(in_channels=self.n_channels, out_channels=3, kernel_size= self.kernel_size,stride=1)\n",
    "        self.pos_emb = FixedPositionalEmbedding(self.n_channels)\n",
    "        self.transformerBlock1 = SpliceFormerBlock()\n",
    "        self.transformerBlock2 = SpliceFormerBlock()\n",
    "        #self.transformerBlock3 = SpliceFormerBlock()\n",
    "        #self.transformerBlock4 = SpliceFormerBlock()\n",
    "        #self.transformerBlock5 = SpliceFormerBlock()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, features):\n",
    "        out1,x_skip = self.smallModel(features)\n",
    "        m_1 = nn.Softmax(dim=1)\n",
    "        out1 = m_1(self.conv_final(out1))\n",
    "        attention =  m_1(self.conv_final(x_skip))\n",
    "        pos_emb = self.pos_emb(torch.transpose(x_skip, 1, 2)).type_as(torch.transpose(x_skip, 1, 2))\n",
    "        emb1 = self.transformerBlock1(x_skip,attention,pos_emb)\n",
    "        \n",
    "        tmp = x_skip+emb1\n",
    "        attention =  m_1(self.conv_final(tmp)) \n",
    "        emb2 = self.transformerBlock2(tmp,attention,pos_emb)\n",
    "        \n",
    "        #tmp = x_skip+emb1+emb2\n",
    "        #attention =  m_1(self.conv_final(tmp))\n",
    "        #emb3 = self.transformerBlock3(tmp,attention,pos_emb)\n",
    "        #attention =  m_1(self.conv_final(x_skip))\n",
    "        \n",
    "        #tmp = x_skip+emb1+emb2+emb3\n",
    "        #attention =  m_1(self.conv_final(tmp))\n",
    "        #emb4 = self.transformerBlock4(tmp,attention,pos_emb)\n",
    "        \n",
    "        #tmp = x_skip+emb1+emb2+emb3+emb4\n",
    "        #attention =  m_1(self.conv_final(tmp))\n",
    "        #emb5 = self.transformerBlock5(tmp,attention,pos_emb)\n",
    "        \n",
    "        x_skip = x_skip+emb1+emb2\n",
    "        #x_skip = x_skip+emb1+emb2+emb3+emb4\n",
    "        m_2 = nn.Softmax(dim=1)\n",
    "        out_2 = m_2(self.conv_final(x_skip))\n",
    "        out_2 = out_2[:,:,(CL_max//2):-(CL_max//2)]\n",
    "        #print(out_2.shape)\n",
    "        #out_2 = torch.zeros_like(out_1)\n",
    "        #out_2 = m_2(x_skip+x_emb)\n",
    "        return out1,out_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation = annotation.drop_duplicates('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_MAP = np.asarray([[1, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 1],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "def shuffleIntrons(X0,label,strand,CL_max):\n",
    "    posistion = np.array(label[1])\n",
    "    l = posistion.shape[0]//2\n",
    "    #donors = label[1][l:]\n",
    "    #acceptors = label[1][:l]\n",
    "    if strand=='+':\n",
    "        splitAt = np.sort(posistion)+CL_max//2\n",
    "        X0,label = shuffler(X0,splitAt,l,CL_max,strand)\n",
    "    if strand=='-':\n",
    "        \n",
    "        X0 = X0[::-1,:]\n",
    "        splitAt = np.sort(X0.shape[0]-CL_max-posistion)+CL_max//2\n",
    "        X0,label = shuffler(X0,splitAt,l,CL_max,strand)\n",
    "        X0 = X0[::-1,:]\n",
    "        label[1] = list(X0.shape[0]-CL_max-np.array(label[1]))\n",
    "    return X0,label\n",
    "\n",
    "def shuffler(X0,splitAt,l,CL_max,strand):\n",
    "    \n",
    "    \n",
    "    for i in range(splitAt.shape[0]):\n",
    "        if i%2==0:\n",
    "            splitAt[i] = splitAt[i]+1\n",
    "    chunks = np.split(X0,splitAt)\n",
    "    intronIdx = 2*np.arange(l)+1\n",
    "    np.random.shuffle(intronIdx)\n",
    "    idx = []\n",
    "    for i in range(len(chunks)):\n",
    "        if i%2==0:\n",
    "            idx.append(i)\n",
    "        if i%2==1:\n",
    "            idx.append(intronIdx[i//2])\n",
    "    chunks = [chunks[i] for i in idx]\n",
    "    if strand=='+':\n",
    "        label = [l*[2,1],np.cumsum([chunks[i].shape[0] for i in range(len(chunks)-1)])-CL_max//2]\n",
    "    if strand=='-':\n",
    "        label = [l*[1,2],np.cumsum([chunks[i].shape[0] for i in range(len(chunks)-1)])-CL_max//2]\n",
    "    #print(strand)\n",
    "    #for i in range(l):\n",
    "    #    print(chunks[l*2][0],chunks[l*2][-1])\n",
    "    for i in range(splitAt.shape[0]):\n",
    "        if i%2==0:\n",
    "            label[1][i] = label[1][i]-1\n",
    "    X0 = np.concatenate((chunks),axis=0)\n",
    "    return X0,label\n",
    "\n",
    "class spliceDataset(Dataset):\n",
    "    def __init__(self, annotation, transform=None, target_transform=None):\n",
    "        #self.data = data\n",
    "        #self.labelDict = labelDict\n",
    "        self.annotation = annotation\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotation.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transcript,chrom,strand,tx_start,tx_end = self.annotation['transcript'].values[idx],self.annotation['chrom'].values[idx],self.annotation['strand'].values[idx],self.annotation['tx_start'].values[idx],self.annotation['tx_end'].values[idx]\n",
    "        #gene,chrom,strand = self.annotation['gene'].values[idx],self.annotation['chrom'].values[idx],self.annotation['strand'].values[idx]\n",
    "        \n",
    "        length = tx_end-tx_start\n",
    "        num_points = ceil_div(length, SL)\n",
    "        \n",
    "        Xd = np.zeros((num_points, SL+CL_max,5))\n",
    "        Yd = np.zeros((num_points, SL,3))\n",
    "        if strand=='+':\n",
    "            X0 = seqData[chrom][int(tx_start)-1-CL_max//2:int(tx_end)+SL+CL_max//2].toarray()\n",
    "            X0[:CL_max//2,:] = np.array([0,0,0,0,0])\n",
    "            X0[-(CL_max//2+SL):,:] = np.array([0,0,0,0,0])\n",
    "        else:\n",
    "            X0 = seqData[chrom][int(tx_start)-1-SL-CL_max//2:int(tx_end)+CL_max//2].toarray()\n",
    "            X0[:(CL_max//2+SL),:] = np.array([0,0,0,0,0])\n",
    "            X0[-CL_max//2:,:] = np.array([0,0,0,0,0])\n",
    "            X0 = X0[::-1,:]\n",
    "            X0[:,[0,1,2,3]] = X0[:,[0,1,2,3]][:,::-1]\n",
    "            \n",
    "        label = transcriptToLabel[transcript]\n",
    "        if self.target_transform:\n",
    "            if len(label[0])>2:\n",
    "                X0,label = shuffleIntrons(X0,label,strand,CL_max)\n",
    "        Y0 = np.zeros((length+SL,3))\n",
    "        Y0[:length,0] = np.ones(length)\n",
    "        Y0[label[1],:] = OUT_MAP[np.array(label[0]).astype('int8')]\n",
    "\n",
    "        for i in range(num_points):\n",
    "            tmp = X0[SL*i:CL_max+SL*(i+1),:]\n",
    "            if tmp.shape[0]==0:\n",
    "                continue\n",
    "            Xd[i,:,:] = tmp\n",
    "            Yd[i,:,:] = Y0[SL*i:SL*(i+1),:]\n",
    "        \n",
    "        #if self.transform:\n",
    "        #    X = self.transform(X)\n",
    "        #if self.target_transform:\n",
    "        #    label = self.target_transform(label)\n",
    "        \n",
    "        #X = torch.Tensor(X.copy())\n",
    "        #print(X.shape)\n",
    "        #X = torch.nn.functional.pad(X.clone(), (0,0,CL_max//2,CL_max//2+X.shape[0]-SL*(X.shape[0]//SL)), \"constant\", 0)\n",
    "        #X = torch.transpose(X.unfold(0,SL,CL_max//2),1,2)\n",
    "        #print(X.shape)\n",
    "        #Y = torch.transpose(torch.Tensor(Y).unfold(0,SL,CL_max//2),1,2)\n",
    "        return Xd,Yd\n",
    "        #if self.include_prob:\n",
    "        #    return X, [Y[t] for t in range(1)],[Y_prob[t] for t in range(1)]\n",
    "        #else:\n",
    "        #    return X, [Y[t] for t in range(1)]\n",
    "\n",
    "def ceil_div(x, y):\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (example, label)\n",
    "             where 'example' is a tensor of arbitrary shape\n",
    "             and label/length are scalars\n",
    "    \"\"\"\n",
    "    #unfold1 = nn.Unfold((SL*3,1),SL,CL_max//2)\n",
    "    #unfold2 = nn.Unfold((SL,1),SL,0)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        features.append(torch.Tensor(data[i][0]))\n",
    "        labels.append(torch.Tensor(data[i][1]))\n",
    "        #features.append(tmp.unfold(0,SL*3,CL_max//2))\n",
    "        #labels.append(torch.Tensor(data[i][1]).unfold(0,SL,CL_max//2))\n",
    "    return torch.cat(features,dim=0).float(), torch.cat(labels,dim=0).float()\n",
    "\n",
    "train_dataset = spliceDataset(annotation_train,target_transform=True)\n",
    "val_dataset = spliceDataset(annotation_validation)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=16,collate_fn=collate_fn, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False,collate_fn=collate_fn, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_topl_statistics(y_true, y_pred):\n",
    "    # Prints the following information: top-kL statistics for k=0.5,1,2,4,\n",
    "    # auprc, thresholds for k=0.5,1,2,4, number of true splice sites.\n",
    "\n",
    "    idx_true = np.nonzero(y_true == 1)[0]\n",
    "    argsorted_y_pred = np.argsort(y_pred)\n",
    "    sorted_y_pred = np.sort(y_pred)\n",
    "\n",
    "    topkl_accuracy = []\n",
    "    threshold = []\n",
    "\n",
    "    for top_length in [0.5, 1, 2, 4]:\n",
    "\n",
    "        idx_pred = argsorted_y_pred[-int(top_length*len(idx_true)):]\n",
    "\n",
    "        topkl_accuracy += [np.size(np.intersect1d(idx_true, idx_pred)) \\\n",
    "                  / float(min(len(idx_pred), len(idx_true)))]\n",
    "        threshold += [sorted_y_pred[-int(top_length*len(idx_true))]]\n",
    "\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "          np.round(topkl_accuracy[0],4), np.round(topkl_accuracy[1],4), np.round(topkl_accuracy[2],4),\n",
    "          np.round(topkl_accuracy[3],4), np.round(auprc,4), np.round(threshold[0],4), np.round(threshold[1],4),\n",
    "          np.round(threshold[2],4), np.round(threshold[3],4), len(idx_true)))\n",
    "    return (topkl_accuracy,[auprc],threshold)\n",
    "\n",
    "def trainModel(model,fileName,criterion,epochs,train_loader,val_loader,alpha=0.5,temp = 1,verbose=1):\n",
    "    learning_rate= 1e-3\n",
    "    #optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    \n",
    "    #optimizer_small = torch.optim.Adam(model.module.smallModel.parameters(), lr=learning_rate)\n",
    "    #scheduler_small = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)\n",
    "    losses = {}\n",
    "    losses['train'] = []\n",
    "    losses['val'] = []\n",
    "    val_results = []\n",
    "    best_val = np.inf\n",
    "    dataLoaders = {}\n",
    "    dataLoaders['train'] = train_loader\n",
    "    dataLoaders['val'] = val_loader\n",
    "    multiplier = 0.01\n",
    "    eps = torch.finfo(torch.float32).eps\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for phase in ['train','val']:\n",
    "            loop =tqdm(dataLoaders[phase])\n",
    "            if 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "            loss = 0\n",
    "            loss_small = 0\n",
    "            ema_loss = 0\n",
    "            ema_loss_small = 0\n",
    "            ema_l1 = 0\n",
    "            ema_a_recall = 0\n",
    "            ema_d_recall = 0\n",
    "            n_steps_completed = 0\n",
    "            #Y_true_argmax,Y_pred_argmax=[],[]\n",
    "            Y_true_acceptor,Y_true_donor,Y_pred_acceptor,Y_pred_donor=[],[],[],[]\n",
    "            for i,(batch_chunks, target_chunks) in enumerate(loop):\n",
    "                batch_chunks = torch.transpose(batch_chunks.to(device),1,2)\n",
    "                #print(batch_chunks.shape)\n",
    "                target_chunks = torch.transpose(torch.squeeze(target_chunks.to(device),0),1,2)\n",
    "                #prob_chunks = torch.transpose(torch.squeeze(prob_chunks[0].to(device),0),1,2)\n",
    "                #n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "                #print(batch_chunks.shape)\n",
    "                batch_chunks = torch.split(batch_chunks, BATCH_SIZE, dim=0)\n",
    "\n",
    "                target_chunks = torch.split(target_chunks, BATCH_SIZE, dim=0)\n",
    "                #prob_chunks = torch.split(prob_chunks, BATCH_SIZE, dim=0)\n",
    "                targets_list,outputs_list = [], []\n",
    "                for j in range(len(batch_chunks)):\n",
    "                    batch_features = batch_chunks[j]\n",
    "                    \n",
    "                    #targets = torch.argmax(target_chunks[j],1)\n",
    "                    targets = target_chunks[j]\n",
    "                    #probs = prob_chunks[j]\n",
    "                    if j==0 and phase == 'train':\n",
    "                        initial_X = batch_features\n",
    "                        initial_y = targets\n",
    "                        #initial_y_prob = probs\n",
    "                    if batch_features.shape[0]!=BATCH_SIZE and phase == 'train':\n",
    "                        additional_samples = BATCH_SIZE-batch_features.shape[0]\n",
    "                        batch_features = torch.cat([batch_features,initial_X[:additional_samples,:,:]],axis=0)\n",
    "                        targets = torch.cat([targets,initial_y[:additional_samples,:,:]],axis=0)\n",
    "                        #probs = torch.cat([probs,initial_y_prob[:additional_samples,:,:]],axis=0)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    #optimizer_small.zero_grad()\n",
    "\n",
    "                    out1,out2 = model(batch_features)\n",
    "                    \n",
    "                    if phase == 'val':\n",
    "                        outputs = out2.detach()\n",
    "                        #outputs = torch.zeros_like(out1).scatter_(2, splice_idx[:,:3,:], out2).detach()\n",
    "                        targets_list.extend(target_chunks[j].unsqueeze(0))\n",
    "                        outputs_list.extend(outputs.unsqueeze(0))\n",
    "                    \n",
    "\n",
    "                    #tmp_x = torch.transpose(outputs,1,2).reshape(targets.shape[0]*5000,3)\n",
    "                    #tmp_y = torch.transpose(targets,1,2).reshape(targets.shape[0]*5000,3)\n",
    "                    #keepAxis = tmp_y.sum(axis=1) >= 1\n",
    "                    #tmp_x = tmp_x[keepAxis].unsqueeze(0)\n",
    "                    #tmp_y = tmp_y[keepAxis].unsqueeze(0)\n",
    "                    #train_loss = criterion((tmp_x+eps).log(), tmp_y)\n",
    "                    #train_loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        outputs = out2\n",
    "                        #outputs = out1.clone()\n",
    "                        #outputs = outputs.scatter_(2, splice_idx[:,:3,:], out2) \n",
    "                        #meanAcceptor = torch.mean(torch.gather(out1,2,splice_idx[:,:3,:])[:,2,:])\n",
    "                        out_argmax = torch.flatten(torch.argmax(outputs,dim=1))\n",
    "                    #    out1_argmax = torch.flatten(torch.argmax(out1,dim=1))\n",
    "                        target_argmax = torch.flatten(torch.argmax(targets,dim=1))\n",
    "                        a_recall = torch.nanmean((out_argmax[target_argmax==1]==1).type(torch.float32))\n",
    "                        d_recall = torch.nanmean((out_argmax[target_argmax==2]==2).type(torch.float32))\n",
    "                        \n",
    "                    #probs = torch.log(probs+eps)\n",
    "                    #probs = torch.nn.functional.softmax(probs/temp, dim=1)\n",
    "                    train_loss_small = criterion(out1, targets)\n",
    "                    #top_targets = torch.gather(targets,2,splice_idx[:,:3,:])\n",
    "                    #top_out1 = torch.gather(out1,2,splice_idx[:,:3,:])\n",
    "                    l1_dist = (torch.sum(torch.abs(out1-out2))/(BATCH_SIZE*128)).detach()\n",
    "                    #l1_dist = (torch.sum(torch.abs(top_out1-out2))/(BATCH_SIZE*128)).detach()\n",
    "                   # if epoch==0:\n",
    "                   #     train_loss = (train_loss_small +criterion[1](out2,targets))/2\n",
    "                   # else:\n",
    "                    train_loss = criterion(out2,targets)\n",
    "                    #train_loss = criterion[1](torch.gather(out2,2,splice_idx[:,:3,:]), torch.gather(targets,2,splice_idx[:,:3,:]))\n",
    "                    #lambda_1 = 1\n",
    "                    #train_loss = alpha*train_loss1+(1-alpha)*train_loss2\n",
    "                    #train_loss = train_loss1\n",
    "                    if phase == 'train':\n",
    "                        train_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1, norm_type=2.0)\n",
    "                        optimizer.step()\n",
    "                        #if epoch < 5:\n",
    "                        #    train_loss_small.backward()\n",
    "                        #    optimizer_small.step()\n",
    "                        \n",
    "                        if epoch==0:\n",
    "                            warmup.step()\n",
    "                    loss = train_loss.item()+loss\n",
    "                    loss_small = train_loss_small.item()+loss_small\n",
    "                    loop.set_description('Epoch ({}) {}/{}'.format(phase,epoch + 1, epochs))\n",
    "                    n_steps_completed += 1\n",
    "                    if i==0 and j==0:\n",
    "                        ema_loss = train_loss.item()\n",
    "                        ema_loss_small = train_loss_small.item()\n",
    "                        if ~a_recall.isnan():\n",
    "                            ema_a_recall = a_recall.cpu().numpy()\n",
    "                        if ~d_recall.isnan():\n",
    "                            ema_d_recall = a_recall.cpu().numpy()\n",
    "                        #ema_loss_target = train_loss_target.item()\n",
    "                        #ema_loss_probs = train_loss_probs.item()\n",
    "                    else:\n",
    "                        ema_loss = train_loss.item()*multiplier + ema_loss*(1-multiplier)\n",
    "                        ema_loss_small = train_loss_small.item()*multiplier + ema_loss_small*(1-multiplier)\n",
    "                        ema_l1 = l1_dist.cpu().numpy()*multiplier + ema_l1*(1-multiplier)\n",
    "                        if ~a_recall.isnan():\n",
    "                            ema_a_recall = a_recall.cpu().numpy()*multiplier + ema_a_recall*(1-multiplier)\n",
    "                        if ~d_recall.isnan():\n",
    "                            ema_d_recall= d_recall.cpu().numpy()*multiplier + ema_d_recall*(1-multiplier)\n",
    "                        #ema_loss_probs = train_loss_probs.item()*multiplier + ema_loss_probs*(1-multiplier)\n",
    "                    loop.set_postfix(loss=ema_loss,loss_small=ema_loss_small, accepor_recall = ema_a_recall , donor_recall=ema_d_recall,pred_l1_dist=ema_l1)\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "                    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "\n",
    "                    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "                    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "                    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "                    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "                    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n",
    "                    #Y_true_argmax.extend(np.argmax(targets[is_expr, :, :],axis=2).flatten())\n",
    "                    #Y_pred_argmax.extend(np.argmax(outputs[is_expr, :, :],axis=2).flatten())\n",
    "            loss = loss / (n_steps_completed)\n",
    "            losses[phase].append(loss)\n",
    "            \n",
    "            if phase == 'val':\n",
    "                Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "                print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "                acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "                print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "                donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)\n",
    "                val_results.append([acceptor_val_results,donor_val_results])\n",
    "                \n",
    "            #if phase == 'val':\n",
    "            #    Y_true_argmax, Y_pred_argmax = np.array(Y_true_argmax), np.array(Y_pred_argmax)\n",
    "                #Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(np.round(Y_true_acceptor,0).astype(int)), np.array(np.round(Y_pred_acceptor,0).astype(int)),np.array(np.round(Y_true_donor,0).astype(int)), np.array(np.round(Y_pred_donor,0).astype(int))\n",
    "            #    print(\"\\n\\033[1m{}:\\033[0m\".format('Total'))\n",
    "            #    print('Accuracy: {}'.format(accuracy_score(Y_true_argmax, Y_pred_argmax)))\n",
    "            #    print('Precision: {}'.format(precision_score(Y_true_argmax, Y_pred_argmax,average='weighted')))\n",
    "            #    print('Recall: {}'.format(recall_score(Y_true_argmax, Y_pred_argmax,average='weighted')))\n",
    "            #    print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "            #    print('Acceptor accuracy: {}'.format(accuracy_score(Y_true_argmax==1, Y_pred_argmax==1)))\n",
    "            #    print('Acceptor precision: {}'.format(precision_score(Y_true_argmax==1, Y_pred_argmax==1)))\n",
    "            #    print('Acceptor recall: {}'.format(recall_score(Y_true_argmax==1, Y_pred_argmax==1)))\n",
    "            #    print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "            #    print('Donor accuracy: {}'.format(accuracy_score(Y_true_argmax==2, Y_pred_argmax==2)))\n",
    "            #    print('Donor precision: {}'.format(precision_score(Y_true_argmax==2, Y_pred_argmax==2)))\n",
    "            #    print('Donor recall: {}'.format(recall_score(Y_true_argmax==2, Y_pred_argmax==2)))\n",
    "                #print('Donor precision: {}'.format(precision_score(Y_true_donor, Y_pred_donor)))\n",
    "                #print('Donor recall: {}'.format(recall_score(Y_true_donor, Y_pred_donor)))\n",
    "                #donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)\n",
    "                #val_results.append([acceptor_val_results,donor_val_results])\n",
    "            \n",
    "            if verbose == 1:\n",
    "                print(\"epoch: {}/{}, {} loss = {:.6f}\".format(epoch + 1, epochs, phase, loss))\n",
    "            if phase == 'val':\n",
    "                torch.save(model.state_dict(), fileName)\n",
    "                #torch.save(smallModel.state_dict(), fileName+\"_small\")\n",
    "                #if loss < best_val:\n",
    "                #    best_val = loss\n",
    "                #    torch.save(model.state_dict(), fileName)\n",
    "        if epoch>5:\n",
    "            scheduler.step()\n",
    "        \n",
    "        #if epoch<5:\n",
    "         #   scheduler_small.step()\n",
    "        \n",
    "    h = pd.DataFrame({'loss':losses['train'],'val_loss':losses['val']})\n",
    "    return h\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorical_crossentropy_2d:\n",
    "    def __init__(self, weights=None,mask=False):\n",
    "        self.weights = weights\n",
    "        self.mask = mask\n",
    "        self.eps = torch.finfo(torch.float32).eps\n",
    "        \n",
    "    def loss(self,y_pred,y_true):\n",
    "        if self.mask:\n",
    "            loss_sum = torch.sum(self.weights[0]*y_true[:, 0, :]*torch.log(y_pred[:, 0, :]+self.eps) + self.weights[1]*y_true[:, 1, :]*torch.log(y_pred[:, 1, :]+self.eps) + self.weights[2]*y_true[:, 2, :]*torch.log(y_pred[:, 2, :]+self.eps))\n",
    "            weight_sum = torch.sum(self.weights[0]*y_true[:, 0, :] + self.weights[1]*y_true[:, 1, :] + self.weights[2]*y_true[:, 2, :])+self.eps\n",
    "            return -loss_sum/weight_sum\n",
    "        else:\n",
    "            prob_sum = torch.sum(y_true)\n",
    "            return -torch.sum(y_true[:, 0, :]*torch.log(y_pred[:, 0, :]+self.eps) + y_true[:, 1, :]*torch.log(y_pred[:, 1, :]+self.eps) + y_true[:, 2, :]*torch.log(y_pred[:, 2, :]+self.eps))/prob_sum\n",
    "        #loss_sum = torch.sum(self.weights[0]*y_true[:, 0, :]*torch.log(y_pred[:, 0, :]+1e-10) + self.weights[1]*y_true[:, 1, :]*torch.log(y_pred[:, 1, :]+1e-10) + self.weights[2]*y_true[:, 2, :]*torch.log(y_pred[:, 2, :]+1e-10))\n",
    "        #weight_sum = torch.sum(self.weights[0]*y_true[:, 0, :] + self.weights[1]*y_true[:, 1, :] + self.weights[2]*y_true[:, 2, :])\n",
    "        #return -loss_sum/weight_sum\n",
    "        \n",
    "class kl_div_2d:\n",
    "    def __init__(self,temp=1):\n",
    "        self.eps = torch.finfo(torch.float32).eps\n",
    "        self.temp = temp\n",
    "        \n",
    "    def loss(self,y_pred,y_true):\n",
    "        if self.temp!=1:\n",
    "            y_true = torch.nn.Softmax(dim=1)(torch.log(y_true+self.eps)/self.temp)\n",
    "        return -torch.mean((y_true[:, 0, :]*torch.log(y_pred[:, 0, :]/(y_true[:, 0, :]+self.eps)+self.eps) + y_true[:, 1, :]*torch.log(y_pred[:, 1, :]/(y_true[:, 1, :]+self.eps)+self.eps) + y_true[:, 2, :]*torch.log(y_pred[:, 2, :]/(y_true[:, 2, :]+self.eps)+self.eps))*self.temp**2)\n",
    "        #x = -torch.sum(y_true[:, 0, :]*torch.log(y_pred[:, 0, :]/(y_true[:, 0, :]+self.eps)+self.eps) + y_true[:, 1, :]*torch.log(y_pred[:, 1, :]/(y_true[:, 1, :]+self.eps)+self.eps) + y_true[:, 2, :]*torch.log(y_pred[:, 2, :]/(y_true[:, 2, :]+self.eps)+self.eps))*self.temp**2\n",
    "        #return x/(y_pred.shape[0]*y_pred.shape[2])\n",
    "        \n",
    "#def weights_init(m):\n",
    "#    if isinstance(m, nn.Conv1d):\n",
    "#        if m.out_channels==3:\n",
    "#            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            #torch.nn.init.zeros_(m.bias)\n",
    "#            m.bias = nn.Parameter(torch.Tensor(np.log([n_null/(n_acceptor+n_donor),n_acceptor/(n_null+n_donor),n_donor/(n_acceptor+n_null)])))\n",
    "        #else:\n",
    "        #    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        #    if m.bias is not None:\n",
    "        #        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "        #        bound = 1 / np.sqrt(fan_in)\n",
    "        #        nn.init.uniform_(m.bias, -bound, bound)\n",
    "        \n",
    "#def weights_init(m):\n",
    "#    if isinstance(m, nn.Conv1d):\n",
    "#        if m.out_channels==3:\n",
    "#            torch.nn.init.xavier_uniform_(m.weight)\n",
    "#            #torch.nn.init.zeros_(m.bias)\n",
    "#            m.bias = nn.Parameter(torch.Tensor(np.log([n_null/(n_acceptor+n_donor),n_acceptor/(n_null+n_donor),n_donor/(n_acceptor+n_null)])))\n",
    "        #else:\n",
    "        #    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        #    if m.bias is not None:\n",
    "        #        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "        #        bound = 1 / np.sqrt(fan_in)\n",
    "        #        nn.init.uniform_(m.bias, -bound, bound)\n",
    "        \n",
    "        \n",
    "def keras_init(m):\n",
    "    if isinstance(m, nn.Conv1d): \n",
    "        fin, fout = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "        a = np.sqrt(6/(m.in_channels*(fin+fout)))\n",
    "        torch.nn.init.uniform_(m.weight, a=-a, b=a)\n",
    "        #print(m,nn.init._calculate_fan_in_and_fan_out(m.weight))\n",
    "        #nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        #nn.init.kaiming_uniform_(m.weight,mode='fan_in', nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        #if m.bias is not None:\n",
    "        #    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "        #    bound = 1 / np.sqrt(fan_in)\n",
    "        #    nn.init.uniform_(m.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|| 202/202 [37:45<00:00, 11.21s/it, accepor_recall=0.784, donor_recall=0.763, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.008069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|| 23/23 [06:33<00:00, 17.12s/it, accepor_recall=0.809, donor_recall=0.809, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9672\t0.8716\t0.9677\t0.9849\t0.9184\t0.9277999997138977\t0.29109999537467957\t0.015200000256299973\t0.0027000000700354576\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9647\t0.8711\t0.9718\t0.9859\t0.918\t0.8751000165939331\t0.2953999936580658\t0.020800000056624413\t0.004000000189989805\t21432\n",
      "epoch: 1/10, val loss = 0.000298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|| 202/202 [37:11<00:00, 11.05s/it, accepor_recall=0.802, donor_recall=0.783, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|| 23/23 [07:01<00:00, 18.33s/it, accepor_recall=0.873, donor_recall=0.855, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9662\t0.8764\t0.9679\t0.9836\t0.9194\t0.9761000275611877\t0.6406000256538391\t0.06710000336170197\t0.014000000432133675\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9648\t0.8846\t0.9735\t0.9874\t0.9219\t0.9440000057220459\t0.4797999858856201\t0.03909999877214432\t0.009499999694526196\t21432\n",
      "epoch: 2/10, val loss = 0.000305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|| 202/202 [37:24<00:00, 11.11s/it, accepor_recall=0.843, donor_recall=0.833, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|| 23/23 [06:42<00:00, 17.49s/it, accepor_recall=0.9, donor_recall=0.908, loss=0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9685\t0.8987\t0.976\t0.9875\t0.9328\t0.9682999849319458\t0.6162999868392944\t0.049800001084804535\t0.010700000450015068\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9657\t0.8971\t0.9818\t0.9902\t0.9359\t0.9611999988555908\t0.5878999829292297\t0.044199999421834946\t0.010200000368058681\t21432\n",
      "epoch: 3/10, val loss = 0.000265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|| 202/202 [37:16<00:00, 11.07s/it, accepor_recall=0.859, donor_recall=0.851, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|| 23/23 [06:57<00:00, 18.17s/it, accepor_recall=0.859, donor_recall=0.859, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9725\t0.9028\t0.9795\t0.9874\t0.9387\t0.9573000073432922\t0.361299991607666\t0.010300000198185444\t0.00279999990016222\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9697\t0.8991\t0.9804\t0.9896\t0.9359\t0.9319999814033508\t0.4198000133037567\t0.017400000244379044\t0.0038999998942017555\t21432\n",
      "epoch: 4/10, val loss = 0.000233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|| 202/202 [37:32<00:00, 11.15s/it, accepor_recall=0.873, donor_recall=0.87, loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|| 23/23 [06:10<00:00, 16.09s/it, accepor_recall=0.835, donor_recall=0.832, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.973\t0.8998\t0.9776\t0.9871\t0.9359\t0.9527999758720398\t0.2709999978542328\t0.006800000090152025\t0.0017000000225380063\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9693\t0.9\t0.981\t0.9899\t0.9375\t0.9243000149726868\t0.26440000534057617\t0.006899999920278788\t0.0013000000035390258\t21432\n",
      "epoch: 5/10, val loss = 0.000248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|| 202/202 [37:40<00:00, 11.19s/it, accepor_recall=0.873, donor_recall=0.864, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|| 23/23 [06:29<00:00, 16.96s/it, accepor_recall=0.916, donor_recall=0.935, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.97\t0.9068\t0.9811\t0.9891\t0.9403\t0.9664000272750854\t0.6362000107765198\t0.02759999968111515\t0.004800000227987766\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9682\t0.9056\t0.9831\t0.9908\t0.9401\t0.9674000144004822\t0.6875\t0.05380000174045563\t0.010999999940395355\t21432\n",
      "epoch: 6/10, val loss = 0.000251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|| 202/202 [37:23<00:00, 11.11s/it, accepor_recall=0.879, donor_recall=0.875, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|| 23/23 [06:19<00:00, 16.52s/it, accepor_recall=0.891, donor_recall=0.892, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9689\t0.9092\t0.9814\t0.9897\t0.9385\t0.9354000091552734\t0.4284999966621399\t0.009700000286102295\t0.001500000013038516\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9687\t0.9028\t0.9821\t0.9907\t0.938\t0.9488000273704529\t0.48159998655319214\t0.01549999974668026\t0.0026000000070780516\t21432\n",
      "epoch: 7/10, val loss = 0.000227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|| 202/202 [37:20<00:00, 11.09s/it, accepor_recall=0.903, donor_recall=0.9, loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|| 23/23 [06:11<00:00, 16.14s/it, accepor_recall=0.913, donor_recall=0.916, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9677\t0.9073\t0.9819\t0.9899\t0.9393\t0.9638000130653381\t0.6252999901771545\t0.014800000004470348\t0.002099999925121665\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9717\t0.9076\t0.9845\t0.9918\t0.9435\t0.9560999870300293\t0.600600004196167\t0.0203000009059906\t0.003000000026077032\t21432\n",
      "epoch: 8/10, val loss = 0.000226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|| 202/202 [37:24<00:00, 11.11s/it, accepor_recall=0.918, donor_recall=0.913, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|| 23/23 [06:14<00:00, 16.26s/it, accepor_recall=0.9, donor_recall=0.893, loss=0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9714\t0.916\t0.9835\t0.991\t0.945\t0.9542999863624573\t0.46950000524520874\t0.006200000178068876\t0.0008999999845400453\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9719\t0.9115\t0.9846\t0.9924\t0.946\t0.9513000249862671\t0.4422999918460846\t0.007499999832361937\t0.0012000000569969416\t21432\n",
      "epoch: 9/10, val loss = 0.000209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|| 202/202 [37:21<00:00, 11.10s/it, accepor_recall=0.916, donor_recall=0.908, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|| 23/23 [06:05<00:00, 15.91s/it, accepor_recall=0.913, donor_recall=0.913, loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9684\t0.9151\t0.9842\t0.9912\t0.9441\t0.9668999910354614\t0.5687999725341797\t0.010599999688565731\t0.0017000000225380063\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9699\t0.9128\t0.9855\t0.9929\t0.9447\t0.9624000191688538\t0.5685999989509583\t0.01119999960064888\t0.0017000000225380063\t21432\n",
      "epoch: 10/10, val loss = 0.000211\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|| 202/202 [37:18<00:00, 11.08s/it, accepor_recall=0.78, donor_recall=0.78, loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.007872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|| 23/23 [06:10<00:00, 16.13s/it, accepor_recall=0.705, donor_recall=0.772, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.964\t0.8529\t0.9606\t0.9817\t0.9049\t0.7645999789237976\t0.26429998874664307\t0.032999999821186066\t0.007199999876320362\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9647\t0.8706\t0.9705\t0.9864\t0.9154\t0.8671000003814697\t0.2727999985218048\t0.020600000396370888\t0.00430000014603138\t21432\n",
      "epoch: 1/10, val loss = 0.000329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|| 202/202 [37:36<00:00, 11.17s/it, accepor_recall=0.798, donor_recall=0.808, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|| 23/23 [06:11<00:00, 16.14s/it, accepor_recall=0.848, donor_recall=0.857, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9696\t0.8862\t0.9743\t0.9874\t0.9282\t0.9308000206947327\t0.39730000495910645\t0.0272000003606081\t0.005200000014156103\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9683\t0.8887\t0.9789\t0.9891\t0.9298\t0.8935999870300293\t0.4140999913215637\t0.03310000151395798\t0.006099999882280827\t21432\n",
      "epoch: 2/10, val loss = 0.000265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|| 202/202 [37:30<00:00, 11.14s/it, accepor_recall=0.825, donor_recall=0.824, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|| 23/23 [06:00<00:00, 15.68s/it, accepor_recall=0.891, donor_recall=0.885, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.969\t0.8979\t0.9763\t0.9863\t0.9336\t0.9611999988555908\t0.5562000274658203\t0.021900000050663948\t0.0034000000450760126\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9691\t0.898\t0.9799\t0.9902\t0.9357\t0.9555000066757202\t0.46700000762939453\t0.016699999570846558\t0.0027000000700354576\t21432\n",
      "epoch: 3/10, val loss = 0.000245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|| 202/202 [37:18<00:00, 11.08s/it, accepor_recall=0.856, donor_recall=0.843, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|| 23/23 [06:11<00:00, 16.17s/it, accepor_recall=0.863, donor_recall=0.872, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9728\t0.9006\t0.9773\t0.9864\t0.9364\t0.9553999900817871\t0.382099986076355\t0.012600000016391277\t0.0026000000070780516\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9694\t0.9054\t0.9816\t0.99\t0.9378\t0.9509999752044678\t0.36070001125335693\t0.009700000286102295\t0.0015999999595806003\t21432\n",
      "epoch: 4/10, val loss = 0.000237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|| 202/202 [37:50<00:00, 11.24s/it, accepor_recall=0.868, donor_recall=0.868, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|| 23/23 [06:21<00:00, 16.59s/it, accepor_recall=0.899, donor_recall=0.891, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9704\t0.9059\t0.9799\t0.9883\t0.9391\t0.9690999984741211\t0.5249000191688538\t0.01979999989271164\t0.003800000064074993\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9706\t0.9079\t0.983\t0.9914\t0.9411\t0.9557999968528748\t0.4375999867916107\t0.019200000911951065\t0.0035000001080334187\t21432\n",
      "epoch: 5/10, val loss = 0.000226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|| 202/202 [37:23<00:00, 11.10s/it, accepor_recall=0.874, donor_recall=0.856, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|| 23/23 [06:13<00:00, 16.24s/it, accepor_recall=0.918, donor_recall=0.925, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9725\t0.9079\t0.9816\t0.9898\t0.9418\t0.9775000214576721\t0.6651999950408936\t0.024900000542402267\t0.00419999985024333\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9711\t0.9089\t0.9849\t0.9935\t0.9443\t0.9728999733924866\t0.6171000003814697\t0.028200000524520874\t0.004800000227987766\t21432\n",
      "epoch: 6/10, val loss = 0.000233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|| 202/202 [37:44<00:00, 11.21s/it, accepor_recall=0.886, donor_recall=0.881, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|| 23/23 [06:05<00:00, 15.90s/it, accepor_recall=0.891, donor_recall=0.903, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9686\t0.9106\t0.9815\t0.9888\t0.9406\t0.9661999940872192\t0.46399998664855957\t0.009100000374019146\t0.0015999999595806003\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9686\t0.9102\t0.9832\t0.9912\t0.9411\t0.9686999917030334\t0.5160999894142151\t0.011099999770522118\t0.0017000000225380063\t21432\n",
      "epoch: 7/10, val loss = 0.000221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|| 202/202 [37:30<00:00, 11.14s/it, accepor_recall=0.904, donor_recall=0.891, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|| 23/23 [06:24<00:00, 16.74s/it, accepor_recall=0.911, donor_recall=0.912, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9732\t0.9148\t0.9827\t0.9899\t0.9462\t0.9729999899864197\t0.5569000244140625\t0.013399999588727951\t0.002099999925121665\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9727\t0.9155\t0.9844\t0.9923\t0.9456\t0.9656999707221985\t0.5311999917030334\t0.015799999237060547\t0.0024999999441206455\t21432\n",
      "epoch: 8/10, val loss = 0.000211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|| 202/202 [37:38<00:00, 11.18s/it, accepor_recall=0.902, donor_recall=0.89, loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|| 23/23 [06:20<00:00, 16.56s/it, accepor_recall=0.912, donor_recall=0.915, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9691\t0.9143\t0.9832\t0.9905\t0.9434\t0.9546999931335449\t0.6043999791145325\t0.01360000018030405\t0.002199999988079071\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9653\t0.9145\t0.9852\t0.9926\t0.9422\t0.9330999851226807\t0.5570999979972839\t0.015399999916553497\t0.0024999999441206455\t21432\n",
      "epoch: 9/10, val loss = 0.000214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|| 202/202 [37:41<00:00, 11.19s/it, accepor_recall=0.92, donor_recall=0.906, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|| 23/23 [06:27<00:00, 16.87s/it, accepor_recall=0.914, donor_recall=0.92, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9693\t0.9151\t0.9832\t0.9905\t0.9439\t0.9751999974250793\t0.6304000020027161\t0.008500000461935997\t0.0012000000569969416\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9669\t0.914\t0.9858\t0.9931\t0.944\t0.9725000262260437\t0.6032000184059143\t0.01119999960064888\t0.0015999999595806003\t21432\n",
      "epoch: 10/10, val loss = 0.000212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|| 202/202 [37:43<00:00, 11.21s/it, accepor_recall=0.778, donor_recall=0.771, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.007784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|| 23/23 [06:30<00:00, 17.00s/it, accepor_recall=0.794, donor_recall=0.838, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9638\t0.8623\t0.9647\t0.9828\t0.9103\t0.9081000089645386\t0.32010000944137573\t0.023000000044703484\t0.00430000014603138\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9651\t0.8638\t0.967\t0.9853\t0.9123\t0.9287999868392944\t0.4422999918460846\t0.03920000046491623\t0.006599999964237213\t21432\n",
      "epoch: 1/10, val loss = 0.000310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|| 202/202 [37:35<00:00, 11.17s/it, accepor_recall=0.786, donor_recall=0.787, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|| 23/23 [07:10<00:00, 18.70s/it, accepor_recall=0.891, donor_recall=0.911, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.962\t0.8757\t0.9695\t0.9859\t0.9167\t0.9682999849319458\t0.6158999800682068\t0.05779999867081642\t0.010400000028312206\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9641\t0.8787\t0.974\t0.9887\t0.922\t0.9724000096321106\t0.6762999892234802\t0.06669999659061432\t0.010599999688565731\t21432\n",
      "epoch: 2/10, val loss = 0.000320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|| 202/202 [37:27<00:00, 11.13s/it, accepor_recall=0.826, donor_recall=0.824, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|| 23/23 [06:28<00:00, 16.90s/it, accepor_recall=0.858, donor_recall=0.805, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9679\t0.8952\t0.9757\t0.9869\t0.9311\t0.9088000059127808\t0.4056999981403351\t0.025800000876188278\t0.004600000102072954\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9663\t0.8934\t0.9777\t0.988\t0.9312\t0.8234999775886536\t0.30410000681877136\t0.017400000244379044\t0.0034000000450760126\t21432\n",
      "epoch: 3/10, val loss = 0.000264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|| 202/202 [37:39<00:00, 11.19s/it, accepor_recall=0.858, donor_recall=0.847, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|| 23/23 [06:18<00:00, 16.44s/it, accepor_recall=0.846, donor_recall=0.866, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9678\t0.8988\t0.9782\t0.9876\t0.9346\t0.9258000254631042\t0.2930000126361847\t0.007799999788403511\t0.0017999999690800905\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9714\t0.896\t0.9806\t0.9909\t0.9362\t0.9311000108718872\t0.34769999980926514\t0.011300000362098217\t0.002099999925121665\t21432\n",
      "epoch: 4/10, val loss = 0.000244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|| 202/202 [37:34<00:00, 11.16s/it, accepor_recall=0.853, donor_recall=0.844, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|| 23/23 [06:18<00:00, 16.46s/it, accepor_recall=0.872, donor_recall=0.888, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9729\t0.9056\t0.9802\t0.9879\t0.9404\t0.9422000050544739\t0.43459999561309814\t0.015300000086426735\t0.003100000089034438\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9681\t0.9065\t0.9836\t0.9915\t0.9391\t0.9254000186920166\t0.43459999561309814\t0.01850000023841858\t0.0031999999191612005\t21432\n",
      "epoch: 5/10, val loss = 0.000227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|| 202/202 [37:37<00:00, 11.18s/it, accepor_recall=0.872, donor_recall=0.868, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|| 23/23 [06:27<00:00, 16.84s/it, accepor_recall=0.9, donor_recall=0.91, loss=0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9699\t0.9118\t0.9813\t0.9894\t0.94\t0.9567000269889832\t0.5407999753952026\t0.01940000057220459\t0.0035000001080334187\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9686\t0.9032\t0.9813\t0.9917\t0.9384\t0.9629999995231628\t0.5877000093460083\t0.02969999983906746\t0.005400000140070915\t21432\n",
      "epoch: 6/10, val loss = 0.000231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|| 202/202 [37:36<00:00, 11.17s/it, accepor_recall=0.879, donor_recall=0.873, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|| 23/23 [06:38<00:00, 17.34s/it, accepor_recall=0.913, donor_recall=0.922, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9727\t0.9108\t0.9816\t0.9896\t0.9424\t0.9771999716758728\t0.6051999926567078\t0.01810000091791153\t0.002400000113993883\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9711\t0.9104\t0.9843\t0.9916\t0.9445\t0.9830999970436096\t0.6215999722480774\t0.018400000408291817\t0.0026000000070780516\t21432\n",
      "epoch: 7/10, val loss = 0.000225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|| 202/202 [37:21<00:00, 11.10s/it, accepor_recall=0.898, donor_recall=0.895, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|| 23/23 [06:15<00:00, 16.33s/it, accepor_recall=0.895, donor_recall=0.892, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9722\t0.9177\t0.9836\t0.9908\t0.9461\t0.958299994468689\t0.4399000108242035\t0.0071000000461936\t0.0012000000569969416\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9687\t0.9106\t0.9844\t0.9923\t0.943\t0.9437999725341797\t0.4194999933242798\t0.008500000461935997\t0.0013000000035390258\t21432\n",
      "epoch: 8/10, val loss = 0.000209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|| 202/202 [37:46<00:00, 11.22s/it, accepor_recall=0.908, donor_recall=0.904, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|| 23/23 [06:01<00:00, 15.70s/it, accepor_recall=0.911, donor_recall=0.912, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.971\t0.9154\t0.9832\t0.991\t0.9453\t0.9625999927520752\t0.5770000219345093\t0.010499999858438969\t0.0017000000225380063\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9672\t0.9149\t0.9852\t0.9924\t0.9446\t0.9642000198364258\t0.54830002784729\t0.010700000450015068\t0.0015999999595806003\t21432\n",
      "epoch: 9/10, val loss = 0.000208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|| 202/202 [37:55<00:00, 11.27s/it, accepor_recall=0.922, donor_recall=0.914, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|| 23/23 [06:05<00:00, 15.87s/it, accepor_recall=0.914, donor_recall=0.914, loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9702\t0.917\t0.984\t0.9911\t0.9452\t0.9671000242233276\t0.5940999984741211\t0.009399999864399433\t0.001500000013038516\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.968\t0.9157\t0.9863\t0.9926\t0.946\t0.9679999947547913\t0.5644000172615051\t0.010400000028312206\t0.001500000013038516\t21432\n",
      "epoch: 10/10, val loss = 0.000206\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|| 202/202 [37:38<00:00, 11.18s/it, accepor_recall=0.781, donor_recall=0.781, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.007075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|| 23/23 [06:16<00:00, 16.35s/it, accepor_recall=0.783, donor_recall=0.798, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9677\t0.8693\t0.9698\t0.9848\t0.9177\t0.8962000012397766\t0.28049999475479126\t0.020999999716877937\t0.00419999985024333\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9672\t0.871\t0.9727\t0.9874\t0.92\t0.8924999833106995\t0.2849000096321106\t0.02019999921321869\t0.003800000064074993\t21432\n",
      "epoch: 1/10, val loss = 0.000297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|| 202/202 [37:54<00:00, 11.26s/it, accepor_recall=0.808, donor_recall=0.808, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|| 23/23 [06:11<00:00, 16.16s/it, accepor_recall=0.852, donor_recall=0.845, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9653\t0.8848\t0.973\t0.9858\t0.9234\t0.9215999841690063\t0.47269999980926514\t0.03779999911785126\t0.007799999788403511\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9648\t0.8859\t0.9787\t0.9907\t0.9288\t0.9265000224113464\t0.3869999945163727\t0.026000000536441803\t0.0052999998442828655\t21432\n",
      "epoch: 2/10, val loss = 0.000270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|| 202/202 [37:50<00:00, 11.24s/it, accepor_recall=0.841, donor_recall=0.834, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|| 23/23 [06:05<00:00, 15.90s/it, accepor_recall=0.864, donor_recall=0.867, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9679\t0.9006\t0.9784\t0.9874\t0.9344\t0.9585999846458435\t0.367000013589859\t0.01119999960064888\t0.0020000000949949026\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.968\t0.8988\t0.9786\t0.9897\t0.9333\t0.9462000131607056\t0.35760000348091125\t0.0142000000923872\t0.002400000113993883\t21432\n",
      "epoch: 3/10, val loss = 0.000243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|| 202/202 [37:33<00:00, 11.16s/it, accepor_recall=0.851, donor_recall=0.849, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|| 23/23 [05:55<00:00, 15.44s/it, accepor_recall=0.866, donor_recall=0.876, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9686\t0.9067\t0.9807\t0.9888\t0.9389\t0.9408000111579895\t0.41999998688697815\t0.012299999594688416\t0.002099999925121665\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9674\t0.9015\t0.9807\t0.9905\t0.9359\t0.9487000107765198\t0.42719998955726624\t0.014499999582767487\t0.002300000051036477\t21432\n",
      "epoch: 4/10, val loss = 0.000228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|| 202/202 [37:44<00:00, 11.21s/it, accepor_recall=0.867, donor_recall=0.865, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|| 23/23 [06:31<00:00, 17.03s/it, accepor_recall=0.901, donor_recall=0.904, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9663\t0.9037\t0.9808\t0.9895\t0.9384\t0.9757999777793884\t0.5605999827384949\t0.019300000742077827\t0.002899999963119626\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9664\t0.8999\t0.9811\t0.9904\t0.9343\t0.9772999882698059\t0.5547000169754028\t0.020999999716877937\t0.0031999999191612005\t21432\n",
      "epoch: 5/10, val loss = 0.000240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|| 202/202 [37:30<00:00, 11.14s/it, accepor_recall=0.878, donor_recall=0.862, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|| 23/23 [06:32<00:00, 17.06s/it, accepor_recall=0.851, donor_recall=0.875, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9733\t0.9057\t0.9772\t0.9876\t0.9377\t0.9448000192642212\t0.28929999470710754\t0.00559999980032444\t0.0010000000474974513\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9697\t0.903\t0.9796\t0.9893\t0.9378\t0.9429000020027161\t0.3944000005722046\t0.011599999852478504\t0.0017999999690800905\t21432\n",
      "epoch: 6/10, val loss = 0.000236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|| 202/202 [37:40<00:00, 11.19s/it, accepor_recall=0.879, donor_recall=0.863, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|| 23/23 [06:30<00:00, 16.99s/it, accepor_recall=0.913, donor_recall=0.918, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.97\t0.9116\t0.9814\t0.9902\t0.9422\t0.9714999794960022\t0.6054999828338623\t0.019899999722838402\t0.0035000001080334187\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9674\t0.9098\t0.984\t0.9918\t0.9421\t0.9685999751091003\t0.6110000014305115\t0.02630000002682209\t0.004600000102072954\t21432\n",
      "epoch: 7/10, val loss = 0.000226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|| 202/202 [37:43<00:00, 11.20s/it, accepor_recall=0.901, donor_recall=0.888, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|| 23/23 [06:50<00:00, 17.87s/it, accepor_recall=0.919, donor_recall=0.922, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9718\t0.9165\t0.9832\t0.9904\t0.9451\t0.9790999889373779\t0.6238999962806702\t0.009999999776482582\t0.0015999999595806003\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9685\t0.9135\t0.9858\t0.9924\t0.9445\t0.9757999777793884\t0.5960999727249146\t0.012799999676644802\t0.0017999999690800905\t21432\n",
      "epoch: 8/10, val loss = 0.000213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|| 202/202 [37:28<00:00, 11.13s/it, accepor_recall=0.913, donor_recall=0.897, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|| 23/23 [06:33<00:00, 17.10s/it, accepor_recall=0.92, donor_recall=0.922, loss=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9724\t0.9152\t0.9846\t0.9916\t0.9464\t0.9664000272750854\t0.5842000246047974\t0.012500000186264515\t0.0020000000949949026\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9698\t0.9145\t0.9858\t0.9929\t0.9462\t0.953000009059906\t0.5655999779701233\t0.01720000058412552\t0.003000000026077032\t21432\n",
      "epoch: 9/10, val loss = 0.000207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|| 202/202 [37:39<00:00, 11.19s/it, accepor_recall=0.914, donor_recall=0.902, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|| 23/23 [06:34<00:00, 17.13s/it, accepor_recall=0.909, donor_recall=0.914, loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9726\t0.9153\t0.9846\t0.991\t0.946\t0.9599000215530396\t0.5521000027656555\t0.008799999952316284\t0.00139999995008111\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9704\t0.9144\t0.9848\t0.9927\t0.9456\t0.9480000138282776\t0.5432000160217285\t0.011500000022351742\t0.0017000000225380063\t21432\n",
      "epoch: 10/10, val loss = 0.000205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/10: 100%|| 202/202 [37:35<00:00, 11.17s/it, accepor_recall=0.78, donor_recall=0.781, loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, train loss = 0.007802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 1/10: 100%|| 23/23 [06:25<00:00, 16.75s/it, accepor_recall=0.716, donor_recall=0.696, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9646\t0.8652\t0.9631\t0.9812\t0.9091\t0.7991999983787537\t0.17569999396800995\t0.013199999928474426\t0.0027000000700354576\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9634\t0.8662\t0.9695\t0.9864\t0.9144\t0.8079000115394592\t0.14219999313354492\t0.008999999612569809\t0.0019000000320374966\t21432\n",
      "epoch: 1/10, val loss = 0.000355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/10: 100%|| 202/202 [37:38<00:00, 11.18s/it, accepor_recall=0.809, donor_recall=0.805, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/10, train loss = 0.000448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 2/10: 100%|| 23/23 [06:08<00:00, 16.04s/it, accepor_recall=0.83, donor_recall=0.831, loss=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9665\t0.8795\t0.9693\t0.9867\t0.9201\t0.9233999848365784\t0.3481000065803528\t0.02250000089406967\t0.0044999998062849045\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9684\t0.8824\t0.9763\t0.989\t0.9253\t0.904699981212616\t0.3467999994754791\t0.023099999874830246\t0.00430000014603138\t21432\n",
      "epoch: 2/10, val loss = 0.000277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/10: 100%|| 202/202 [37:17<00:00, 11.08s/it, accepor_recall=0.839, donor_recall=0.832, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/10, train loss = 0.000286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 3/10: 100%|| 23/23 [06:24<00:00, 16.71s/it, accepor_recall=0.874, donor_recall=0.864, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9658\t0.8867\t0.9751\t0.9877\t0.9276\t0.9510999917984009\t0.4519999921321869\t0.026200000196695328\t0.004800000227987766\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9684\t0.8883\t0.9766\t0.9899\t0.929\t0.9241999983787537\t0.39899998903274536\t0.025699999183416367\t0.004900000058114529\t21432\n",
      "epoch: 3/10, val loss = 0.000260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/10: 100%|| 202/202 [37:48<00:00, 11.23s/it, accepor_recall=0.851, donor_recall=0.845, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/10, train loss = 0.000256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 4/10: 100%|| 23/23 [06:11<00:00, 16.13s/it, accepor_recall=0.903, donor_recall=0.901, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9657\t0.9026\t0.98\t0.9886\t0.9373\t0.9733999967575073\t0.5601999759674072\t0.02199999988079071\t0.003700000001117587\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9686\t0.9006\t0.9811\t0.9909\t0.9372\t0.9629999995231628\t0.541100025177002\t0.029600000008940697\t0.0052999998442828655\t21432\n",
      "epoch: 4/10, val loss = 0.000240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 5/10: 100%|| 202/202 [37:58<00:00, 11.28s/it, accepor_recall=0.865, donor_recall=0.862, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/10, train loss = 0.000240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 5/10: 100%|| 23/23 [06:03<00:00, 15.81s/it, accepor_recall=0.889, donor_recall=0.908, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9694\t0.9045\t0.9791\t0.9885\t0.938\t0.9574999809265137\t0.4740999937057495\t0.016599999740719795\t0.0024999999441206455\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9696\t0.9016\t0.9825\t0.9916\t0.939\t0.9664999842643738\t0.5317000150680542\t0.018300000578165054\t0.0024999999441206455\t21432\n",
      "epoch: 5/10, val loss = 0.000232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 6/10: 100%|| 202/202 [37:54<00:00, 11.26s/it, accepor_recall=0.864, donor_recall=0.86, loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/10, train loss = 0.000224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 6/10: 100%|| 23/23 [06:33<00:00, 17.09s/it, accepor_recall=0.888, donor_recall=0.887, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9704\t0.9045\t0.9818\t0.9902\t0.9395\t0.968500018119812\t0.4465000033378601\t0.013500000350177288\t0.002400000113993883\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9685\t0.9077\t0.9841\t0.9922\t0.9416\t0.9528999924659729\t0.41019999980926514\t0.012000000104308128\t0.0020000000949949026\t21432\n",
      "epoch: 6/10, val loss = 0.000221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 7/10: 100%|| 202/202 [37:48<00:00, 11.23s/it, accepor_recall=0.878, donor_recall=0.867, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/10, train loss = 0.000214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 7/10: 100%|| 23/23 [06:28<00:00, 16.88s/it, accepor_recall=0.876, donor_recall=0.886, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9709\t0.9085\t0.9801\t0.9892\t0.941\t0.9648000001907349\t0.4300999939441681\t0.010099999606609344\t0.0015999999595806003\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9696\t0.9019\t0.9811\t0.9905\t0.937\t0.9557999968528748\t0.47510001063346863\t0.016300000250339508\t0.0027000000700354576\t21432\n",
      "epoch: 7/10, val loss = 0.000229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 8/10: 100%|| 202/202 [37:47<00:00, 11.23s/it, accepor_recall=0.898, donor_recall=0.886, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/10, train loss = 0.000187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 8/10: 100%|| 23/23 [06:20<00:00, 16.55s/it, accepor_recall=0.918, donor_recall=0.914, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.969\t0.9136\t0.9823\t0.9901\t0.9441\t0.9688000082969666\t0.6488999724388123\t0.021400000900030136\t0.0032999999821186066\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9682\t0.9101\t0.9845\t0.9917\t0.9423\t0.9465000033378601\t0.5770000219345093\t0.020400000736117363\t0.0034000000450760126\t21432\n",
      "epoch: 8/10, val loss = 0.000221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 9/10: 100%|| 202/202 [37:58<00:00, 11.28s/it, accepor_recall=0.905, donor_recall=0.896, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/10, train loss = 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 9/10: 100%|| 23/23 [06:17<00:00, 16.40s/it, accepor_recall=0.915, donor_recall=0.916, loss=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9719\t0.9143\t0.9836\t0.9906\t0.9471\t0.9714000225067139\t0.597100019454956\t0.010400000028312206\t0.001500000013038516\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9694\t0.914\t0.9853\t0.9926\t0.9448\t0.9690999984741211\t0.5680000185966492\t0.013299999758601189\t0.0020000000949949026\t21432\n",
      "epoch: 9/10, val loss = 0.000211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 10/10: 100%|| 202/202 [37:31<00:00, 11.14s/it, accepor_recall=0.917, donor_recall=0.907, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10, train loss = 0.000159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (val) 10/10: 100%|| 23/23 [06:22<00:00, 16.62s/it, accepor_recall=0.915, donor_recall=0.912, loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9692\t0.9161\t0.984\t0.9911\t0.9463\t0.9697999954223633\t0.6129999756813049\t0.008700000122189522\t0.00139999995008111\t21432\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9676\t0.9129\t0.9855\t0.9928\t0.9444\t0.961899995803833\t0.5741000175476074\t0.010700000450015068\t0.0017000000225380063\t21432\n",
      "epoch: 10/10, val loss = 0.000206\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "hs = []\n",
    "#val_results_combined = []\n",
    "temp=1\n",
    "#for model_nr in range(5):\n",
    "for model_nr in range(5):\n",
    "    model_m = SpliceFormer(temp=1)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    modelFileName = '../Results/PyTorch_Models/transformer_encoder_40k_intronshuffle_060422_{}'.format(model_nr)\n",
    "    #model_m.load_state_dict(torch.load('../Results/PyTorch_Models/SpliceAI_Ensembl_dgxtest_{}'.format(0)))\n",
    "    #loss = nn.CrossEntropyLoss(weight=torch.from_numpy(weights).float().to(device),ignore_index=-1,reduction='mean')\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = nn.KLDivLoss()\n",
    "    #loss = \n",
    "    h = trainModel(model_m,modelFileName,loss,epochs,train_loader,val_loader,alpha=0.1,temp=temp)\n",
    "    hs.append(h)\n",
    "    #print(model_m.module.conv_final.bias)\n",
    "    #val_results_combined.append(val_results)\n",
    "    plt.plot(range(epochs),h['loss'],label='Train')\n",
    "    plt.plot(range(epochs),h['val_loss'],label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-050422'\n",
    "setType = 'test'\n",
    "#with open('{}/sparse_sequence_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    seqData = pickle.load(handle)\n",
    "    \n",
    "with open('{}/sparse_discrete_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "    transcriptToLabel = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "CHROM_TEST = ['chr1', 'chr3', 'chr5', 'chr7', 'chr9']\n",
    "\n",
    "annotation = pd.read_csv(data_dir+'/annotation_ensembl_v87_{}.txt'.format(setType),sep='\\t',header=None)[[0,1,2,3,4]]\n",
    "annotation.columns = ['name','chrom','strand','tx_start','tx_end']\n",
    "annotation['transcript'] = annotation['name'].apply(lambda x: x.split('---')[-2].split('.')[0]).values\n",
    "annotation['gene'] = annotation['name'].apply(lambda x: x.split('---')[-3].split('.')[0]).values\n",
    "#annotation['support'] = annotation['transcript'].apply(lambda x:transcriptToSupport[x])\n",
    "\n",
    "chrom_paths = glob(data_dir+'/sparse_sequence_data/*')\n",
    "chromToPath = {}\n",
    "for path in chrom_paths:\n",
    "    chromToPath[path.split('/')[-1].split('_')[0]] = path\n",
    "    \n",
    "seqData = {}\n",
    "for chrom in CHROM_TEST:\n",
    "    seqData[chrom] = load_npz(data_dir+'/sparse_sequence_data/{}_{}.npz'.format(chrom,setType)).tocsr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = 1\n",
    "n_models = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceFormer(temp=temp)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_intronshuffle_060422_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(annotation)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0,collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks.to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks.to(device),0),1,2)\n",
    "    batch_chunks = torch.split(batch_chunks, BATCH_SIZE, dim=0)\n",
    "    target_chunks = torch.split(target_chunks, BATCH_SIZE, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features)[1].detach() for i in range(n_models)])\n",
    "        outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
