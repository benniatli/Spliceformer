{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c3bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benediktj/Python3.9.1/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gmean\n",
    "from tqdm import tqdm\n",
    "import gffutils\n",
    "import os.path\n",
    "from liftover import ChainFile\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "import pyfastx\n",
    "import re\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from glob import glob\n",
    "from scipy.sparse import lil_matrix,csr_matrix,coo_matrix,dok_matrix, save_npz\n",
    "import pickle\n",
    "#\n",
    "blacklist = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/ENCFF220FIN.bed',header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cab6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpileRepeats = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/simpleRepeat.txt',header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88746baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gffutils.create_db('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX/gencode.v42.annotation.gtf', \"/odinn/tmp/benediktj/Data/SplicePrediction-GTEX/gencode.v42.annotation.db\", force=True,disable_infer_genes=True, disable_infer_transcripts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d829cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_gencode = gffutils.FeatureDB('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/gencode.v42.annotation.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e71ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafcutterFiles = glob('/nfs/odinn/users/solvir/GTEx/GTEx_Analysis_v8_sQTL_leafcutter_counts/*_perind_numers.counts.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5adf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#junctions = pd.read_csv('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/GTEx_Analysis_2017-06-05_v8_STARv2.5.3a_junctions.gct', skiprows=2,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64dad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLowCountJunctions(junctions,blacklist,simpileRepeats):\n",
    "    tmp2 = junctions.iloc[:,2:]\n",
    "    transcriptCount = np.sum(tmp2,axis=1)\n",
    "    tmp2.columns = [x.split('-')[1] for x in junctions.columns[2:]]\n",
    "    tmp2 = tmp2.T.groupby(tmp2.columns).sum().T\n",
    "\n",
    "    includeJunction = np.sum(tmp2 > 0,axis=1)>=4\n",
    "\n",
    "    discardJunctionDict = defaultdict(bool)\n",
    "    discardReason = defaultdict(bool)\n",
    "    prev_chrom = 'chr1'\n",
    "    blacklist_chrom = blacklist[blacklist[0]==prev_chrom]\n",
    "    simpileRepeats_chrom = simpileRepeats[simpileRepeats[1]==prev_chrom]\n",
    "    \n",
    "    for i,junction in tqdm(enumerate(junctions.Name.values)):\n",
    "        chrom,start,end = junctions.iloc[i,0].split('_')\n",
    "        start,end = int(start),int(end)\n",
    "        cond1 = includeJunction[i]==False\n",
    "        \n",
    "        if cond1:\n",
    "            geneID = junctions.iloc[i,1].split('.')[0]\n",
    "            discardJunctionDict[junction+'_'+geneID] = True\n",
    "            discardReason[junction+'_'+geneID] = 'LowReadCount'\n",
    "            prev_chrom = chrom\n",
    "            continue\n",
    "            \n",
    "        if prev_chrom != chrom:\n",
    "            blacklist_chrom = blacklist[blacklist[0]==chrom]\n",
    "        tmp = blacklist_chrom[np.logical_not(np.any([blacklist_chrom[1]>=end, blacklist_chrom[2]<=start],0))]\n",
    "        cond2 = False\n",
    "        for i_b in range(tmp.shape[0]):\n",
    "            if (np.isin(start, range(tmp.iloc[i_b,1],tmp.iloc[i_b,2]+1)) or np.isin(end, range(tmp.iloc[i_b,1],tmp.iloc[i_b,2]+1))):\n",
    "                cond2 = True\n",
    "                break\n",
    "                \n",
    "        if cond2:\n",
    "            geneID = junctions.iloc[i,1].split('.')[0]\n",
    "            discardJunctionDict[junction+'_'+geneID] = True\n",
    "            discardReason[junction+'_'+geneID] = 'InBlacklistedRegion'\n",
    "            prev_chrom = chrom\n",
    "            continue\n",
    "                \n",
    "        if prev_chrom != chrom:\n",
    "            simpileRepeats_chrom = simpileRepeats[simpileRepeats[1]==chrom]\n",
    "        \n",
    "        tmp = simpileRepeats_chrom[np.logical_not(np.any([simpileRepeats_chrom[2]>=end,simpileRepeats_chrom[3]<=start],0))]\n",
    "        cond3 = False\n",
    "        for i_b in range(tmp.shape[0]):\n",
    "            if (np.isin(start, range(tmp.iloc[i_b,2],tmp.iloc[i_b,3]+1)) or np.isin(end, range(tmp.iloc[i_b,2],tmp.iloc[i_b,3]+1))):\n",
    "                cond3 = True\n",
    "                break\n",
    "        \n",
    "        if cond3:\n",
    "            geneID = junctions.iloc[i,1].split('.')[0]\n",
    "            discardJunctionDict[junction+'_'+geneID] = True\n",
    "            discardReason[junction+'_'+geneID] = 'InRepeatRegion'\n",
    "            prev_chrom = chrom\n",
    "            continue\n",
    "        \n",
    "        prev_chrom = chrom\n",
    "        \n",
    "    return discardJunctionDict,discardReason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d2fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discardJunctionDict,discardReason = findLowCountJunctions(junctions,blacklist,simpileRepeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac6fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/discardJunctions.pkl', 'rb') as f:\n",
    "    discardJunctionDict = pickle.load(f)\n",
    "\n",
    "with open('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/discardReason.pkl', 'rb') as f:\n",
    "     discardReason = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5b84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/discardJunctions.pkl', 'wb') as f:\n",
    "#    pickle.dump(discardJunctionDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d37a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/discardReason.pkl', 'wb') as f:\n",
    "#    pickle.dump(discardReason, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a411b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafcutterFiles = glob('/odinn/tmp/bjarnih/RNA/leafCutter/GTEx/*/meta_results/clusters_*_summary.tab')\n",
    "chrmToLeafcutterFiles = defaultdict(list)\n",
    "for file in leafcutterFiles:\n",
    "    chrm = file.split('/')[-1].split('_')[1]\n",
    "    chrmToLeafcutterFiles[chrm].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc6fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinedLeafCutterDF(chrm,chrmToLeafcutterFiles):\n",
    "    files = chrmToLeafcutterFiles[chrm]\n",
    "    for i in range(len(files)):\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(files[i],sep='\\t')\n",
    "        else:\n",
    "            df = pd.concat([df,pd.read_csv(files[i],sep='\\t')],axis=0)\n",
    "            df = df.drop_duplicates('splice_event_id')\n",
    "    return df.sort_values('Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc0012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = pyfastx.Fasta('/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/GRCh38.p13.genome.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3714b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-GTEX-V8/'\n",
    "\n",
    "seqData = {}\n",
    "\n",
    "CHROM_GROUP = ['chr1', 'chr3', 'chr5', 'chr7', 'chr9',\n",
    "'chr11', 'chr13', 'chr15', 'chr17', 'chr19', 'chr21',\n",
    "'chr2', 'chr4', 'chr6', 'chr8', 'chr10', 'chr12',\n",
    "'chr14', 'chr16', 'chr18', 'chr20', 'chr22', 'chrX', 'chrY']\n",
    "\n",
    "for chrom in CHROM_GROUP:\n",
    "        seqData[chrom] = dok_matrix((len(fasta[chrom]), 5), dtype=np.int8)\n",
    "\n",
    "seqData[chrom] = dok_matrix((len(fasta[chrom]), 5), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c12f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datapoints(seq, strand, tx_start, tx_end):\n",
    "    # This function first converts the sequence into an integer array, where\n",
    "    # A, C, G, T, Missing are mapped to 1, 2, 3, 4, 5 respectively. If the strand is\n",
    "    # negative, then reverse complementing is done. . It then calls reformat_data and one_hot_encode\n",
    "\n",
    "    seq = seq.upper()\n",
    "    seq = re.sub(r'[^AGTC]', '5',seq)\n",
    "    seq = seq.replace('A', '1').replace('C', '2')\n",
    "    seq = seq.replace('G', '3').replace('T', '4')\n",
    "\n",
    "    tx_start = int(tx_start)\n",
    "    tx_end = int(tx_end) \n",
    "\n",
    "    Y_idx = []\n",
    "    \n",
    "    X0 = np.asarray([int(x) for x in seq])\n",
    "\n",
    "    X = one_hot_encode(X0)\n",
    "\n",
    "    return X\n",
    "\n",
    "def ceil_div(x, y):\n",
    "    return int(ceil(float(x)/y))\n",
    "\n",
    "\n",
    "IN_MAP = np.asarray([[0, 0, 0, 0,0],\n",
    "                     [1, 0, 0, 0,0],\n",
    "                     [0, 1, 0, 0,0],\n",
    "                     [0, 0, 1, 0,0],\n",
    "                     [0, 0, 0, 1,0],\n",
    "                    [0, 0, 0, 0,1]])\n",
    "# One-hot encoding of the inputs: 0 is for padding, and 1, 2, 3, 4 correspond\n",
    "# to A, C, G, T, Missing respectively.\n",
    "\n",
    "OUT_MAP = np.asarray([[1, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 1],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "def one_hot_encode(Xd):\n",
    "    return IN_MAP[Xd.astype('int8')]\n",
    "\n",
    "def getJunctions(gtf,transcript,strand):\n",
    "    #transcript = gtf[transcript_id.split('.')[0]]\n",
    "    exon_junctions = []\n",
    "    tx_start = int(transcript[3])\n",
    "    tx_end = int(transcript[4])\n",
    "    exons = gtf.children(transcript, featuretype=\"exon\")\n",
    "    for exon in exons:\n",
    "        exon_start = int(exon[3])\n",
    "        exon_end = int(exon[4])\n",
    "        exon_junctions.append((exon_start,exon_end))\n",
    "\n",
    "    intron_junctions = []\n",
    "\n",
    "    if strand=='+':\n",
    "        intron_start = exon_junctions[0][1]\n",
    "        for i,exon_junction in enumerate(exon_junctions[1:]):\n",
    "            intron_end = exon_junction[0]\n",
    "            intron_junctions.append((intron_start,intron_end))\n",
    "            if i+1 != len(exon_junctions[1:]):\n",
    "                intron_start = exon_junction[1]\n",
    "\n",
    "    elif strand=='-':\n",
    "        exon_junctions.reverse()\n",
    "        intron_start = exon_junctions[0][1]\n",
    "        for i,exon_junction in enumerate(exon_junctions[1:]):\n",
    "            intron_end = exon_junction[0]\n",
    "            intron_junctions.append((intron_start,intron_end))\n",
    "            if i+1 != len(exon_junctions[1:]):\n",
    "                intron_start = exon_junction[1]\n",
    "\n",
    "    return np.array(intron_junctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce92d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252416it [5:16:39, 13.29it/s]  \n"
     ]
    }
   ],
   "source": [
    "transcripts = gtf_gencode.features_of_type('transcript')\n",
    "gene_to_label = {}\n",
    "save_seq = True\n",
    "prev_chrom = 'chr1'\n",
    "leaf_cutter_junctions = getCombinedLeafCutterDF(prev_chrom,chrmToLeafcutterFiles)\n",
    "for transcript in tqdm(transcripts): \n",
    "    chrom,gene_start,gene_end,strand,gene_id,transcript_id,gene_type,gene_name,level = transcript[0],transcript[3],transcript[4],transcript[6],transcript[8]['gene_id'][0],transcript[8]['transcript_id'][0],transcript[8]['gene_type'][0],transcript[8]['gene_name'][0],transcript[8]['level'][0]\n",
    "    \n",
    "    try:\n",
    "        cond1 = 'Ensembl_canonical' in transcript[8]['tag']\n",
    "        cond2 = gene_type=='protein_coding'\n",
    "        cond3 = int(level)<3\n",
    "        if cond1 and cond2 and cond3:\n",
    "            intron_junctions = getJunctions(gtf_gencode,transcript,strand)\n",
    "            junction_starts = defaultdict(int)\n",
    "            junction_ends = defaultdict(int)\n",
    "            \n",
    "           \n",
    "            if len(intron_junctions>0):\n",
    "                if chrom!=prev_chrom:\n",
    "                    leaf_cutter_junctions = getCombinedLeafCutterDF(chrom,chrmToLeafcutterFiles)\n",
    "                for junction in intron_junctions:\n",
    "                    junction_starts[junction[0]] = 1\n",
    "                    junction_ends[junction[1]] = 1\n",
    "                simple_gene_id = gene_id.split('.')[0]\n",
    "                alt_junctions = leaf_cutter_junctions[leaf_cutter_junctions['Gene_id']==simple_gene_id]\n",
    "                if alt_junctions.shape[0]>0:\n",
    "                    clusters = defaultdict(int)\n",
    "                    for i,pos in enumerate(alt_junctions['Start']):\n",
    "                        if junction_starts[pos] == 1:\n",
    "                            clusters[alt_junctions.iloc[i,:]['ClusterID']] = 1\n",
    "                    for i,pos in enumerate(alt_junctions['End']):\n",
    "                        if junction_ends[pos] == 1:\n",
    "                            clusters[alt_junctions.iloc[i,:]['ClusterID']] = 1\n",
    "                    for cluster in clusters.keys():\n",
    "                        cluster_junctions = alt_junctions[alt_junctions['ClusterID']==cluster][['Start','End']]\n",
    "                        for i_junc in range(cluster_junctions.shape[0]):\n",
    "                            start,end = cluster_junctions.iloc[i_junc,:]['Start'],cluster_junctions.iloc[i_junc,:]['End']\n",
    "                            junction_id = '{}_{}_{}_{}'.format(chrom,start,end,simple_gene_id)\n",
    "                            if not discardJunctionDict[junction_id]:\n",
    "                                junction_starts[start] = 1\n",
    "                                junction_ends[end] = 1\n",
    "                    \n",
    "                    junction_starts = {k:v for k,v in junction_starts.items() if v != 0}\n",
    "                    junction_ends = {k:v for k,v in junction_ends.items() if v != 0}\n",
    "                    gene_to_label[gene_id] = [junction_starts, junction_ends]\n",
    "            \n",
    "                    if save_seq:\n",
    "                        seq = fasta[chrom][int(gene_start)-1:int(gene_end)]\n",
    "                        seq = seq.seq\n",
    "                        X = create_datapoints(seq, strand, gene_start, gene_end)\n",
    "                        seqData[chrom][int(gene_start)-1:int(gene_end)] = X\n",
    "                        jn_start = list(junction_starts.keys())\n",
    "                        jn_end = list(junction_ends.keys())\n",
    "                        name = '{}\\t{}\\t{}\\t{}'.format(gene_name,gene_id,transcript_id,level)\n",
    "\n",
    "                        if strand=='+':\n",
    "                            with open('{}/annotation_GTEX_v8.txt'.format(data_dir), 'a') as the_file:\n",
    "                                the_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(name,chrom,strand,gene_start,gene_end,','.join([str(x) for x in jn_start]),','.join([str(x) for x in jn_end])))\n",
    "                        if strand=='-':\n",
    "                            with open('{}/annotation_GTEX_v8.txt'.format(data_dir,), 'a') as the_file:\n",
    "                                the_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(name,chrom,strand,gene_start,gene_end,','.join([str(x) for x in jn_end]),','.join([str(x) for x in jn_start])))\n",
    "\n",
    "                        if chrom!=prev_chrom:\n",
    "                            save_npz('{}/sparse_sequence_data/{}.npz'.format(data_dir,prev_chrom), seqData[prev_chrom].tocoo())\n",
    "                            del seqData[prev_chrom]\n",
    "\n",
    "                        prev_chrom = chrom\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "        #print(gene[2])\n",
    "        #print(gene[8]['transcript_support_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e46ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz('{}/sparse_sequence_data/{}.npz'.format(data_dir,prev_chrom), seqData[prev_chrom].tocoo())\n",
    "#del seqData[prev_chrom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae7201e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/gene_to_label.pickle'.format(data_dir), 'wb') as handle:\n",
    "    pickle.dump(gene_to_label, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf95dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
