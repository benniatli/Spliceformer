{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import pickle5 as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from glob import glob\n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "import copy\n",
    "\n",
    "from src.train import trainModel\n",
    "\n",
    "#from src.dataloader import getData,spliceDataset,h5pyDataset,collate_fn\n",
    "from src.dataloader import get_GTEX_v8_Data,spliceDataset,h5pyDataset,getDataPointList,getDataPointListGTEX,DataPointGTEX\n",
    "from src.weight_init import keras_init\n",
    "from src.losses import categorical_crossentropy_2d,kl_div_2d\n",
    "from src.model import SpliceAI_10K\n",
    "from src.evaluation_metrics import print_topl_statistics,cross_entropy_2d,kullback_leibler_divergence_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 17:23:16 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    35W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    34W / 250W |      0MiB / 32510MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(23673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gtf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 32\n",
    "N_GPUS = 3\n",
    "k = 2\n",
    "NUM_ACCUMULATION_STEPS=1\n",
    "# Hyper-parameters:\n",
    "# L: Number of convolution kernels\n",
    "# W: Convolution window size in each residual unit\n",
    "# AR: Atrous rate in each residual unit\n",
    "\n",
    "W = np.asarray([11, 11, 11, 11, 11, 11, 11, 11,\n",
    "                21, 21, 21, 21, 41, 41, 41, 41])\n",
    "AR = np.asarray([1, 1, 1, 1, 4, 4, 4, 4,\n",
    "                 10, 10, 10, 10, 25, 25, 25, 25])\n",
    "BATCH_SIZE = 16*k*N_GPUS\n",
    "\n",
    "k = NUM_ACCUMULATION_STEPS*k\n",
    "\n",
    "CL = 2 * np.sum(AR*(W-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/odinn/tmp/benediktj/Data/SplicePrediction-rnasplice-blood-070623/'\n",
    "setType = 'train'\n",
    "annotation, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in tqdm(gene_to_label.keys()):\n",
    "#    for d_key in gene_to_label[key][0]:\n",
    "#        gene_to_label[key][0][d_key] = 1\n",
    "#    for d_key in gene_to_label[key][1]:\n",
    "#        gene_to_label[key][1][d_key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum nucleotide context length (CL_max/2 on either side of the \n",
    "# position of interest)\n",
    "# CL_max should be an even number\n",
    "# Sequence length of SpliceAIs (SL+CL will be the input length and\n",
    "# SL will be the output length)\n",
    "\n",
    "SL=5000\n",
    "CL_max=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert CL_max % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_gene, validation_gene = train_test_split(annotation['gene'].drop_duplicates(),test_size=.1,random_state=435)\n",
    "#annotation_train = annotation[annotation['gene'].isin(train_gene)]\n",
    "#annotation_validation = annotation[annotation['gene'].isin(validation_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('{}/sparse_discrete_gene_label_data_{}.pickle'.format(data_dir,setType), 'rb') as handle:\n",
    "#    gene_to_label_old = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in gene_to_label_old.keys():\n",
    "#    if len(gene_to_label[gene])==0:\n",
    "#        gene_to_label[gene] = gene_to_label_old[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spliceDataset(getDataPointListGTEX(annotation,gene_to_label,SL,CL_max,shift=SL))\n",
    "#val_dataset = spliceDataset(getDataPointListGTEX(annotation_validation,gene_to_label,SL,CL_max,shift=SL))\n",
    "train_dataset.seqData = seqData\n",
    "#val_dataset.seqData = seqData\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE//2, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "hs = []\n",
    "learning_rate= k*1e-4\n",
    "gamma=0.5\n",
    "temp = 1\n",
    "#final_lr = 1e-5\n",
    "#gamma = 1/(learning_rate/final_lr)**(1/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [20:13<00:00,  1.33it/s, a_r=0.621, d_r=0.616, loss=0.000935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:45<00:00,  1.37it/s, a_r=0.633, d_r=0.629, loss=0.000916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:46<00:00,  1.36it/s, a_r=0.631, d_r=0.624, loss=0.000906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████| 1619/1619 [19:45<00:00,  1.37it/s, a_r=0.63, d_r=0.635, loss=0.000893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:45<00:00,  1.37it/s, a_r=0.619, d_r=0.624, loss=0.000984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████| 1619/1619 [19:46<00:00,  1.36it/s, a_r=0.63, d_r=0.628, loss=0.000922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.632, d_r=0.63, loss=0.000899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.634, d_r=0.629, loss=0.000901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████| 1619/1619 [19:47<00:00,  1.36it/s, a_r=0.624, d_r=0.622, loss=0.00098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.627, d_r=0.627, loss=0.000956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.633, d_r=0.629, loss=0.000913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████| 1619/1619 [19:46<00:00,  1.36it/s, a_r=0.631, d_r=0.63, loss=0.000906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.618, d_r=0.616, loss=0.000957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.628, d_r=0.627, loss=0.000921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:47<00:00,  1.36it/s, a_r=0.636, d_r=0.633, loss=0.000898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████| 1619/1619 [19:47<00:00,  1.36it/s, a_r=0.634, d_r=0.631, loss=0.000891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.623, d_r=0.623, loss=0.000972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.627, d_r=0.631, loss=0.000929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.633, d_r=0.63, loss=0.000905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|████████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.637, d_r=0.633, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:46<00:00,  1.36it/s, a_r=0.621, d_r=0.621, loss=0.000988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.626, d_r=0.627, loss=0.000901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|███████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.635, d_r=0.63, loss=0.000903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████| 1619/1619 [19:50<00:00,  1.36it/s, a_r=0.63, d_r=0.629, loss=0.000916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.626, d_r=0.624, loss=0.000957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.626, d_r=0.633, loss=0.000935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.636, d_r=0.633, loss=0.000913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████| 1619/1619 [19:47<00:00,  1.36it/s, a_r=0.638, d_r=0.633, loss=0.000905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|███████████████| 1619/1619 [19:47<00:00,  1.36it/s, a_r=0.623, d_r=0.623, loss=0.00096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.635, d_r=0.629, loss=0.000914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:50<00:00,  1.36it/s, a_r=0.632, d_r=0.636, loss=0.000898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.636, d_r=0.638, loss=0.000882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.624, d_r=0.627, loss=0.000959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.627, d_r=0.624, loss=0.000937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.631, d_r=0.632, loss=0.000913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.636, d_r=0.635, loss=0.000892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 1/4: 100%|██████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.622, d_r=0.622, loss=0.000961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, train loss = 0.001043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 2/4: 100%|███████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.63, d_r=0.629, loss=0.000937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/4, train loss = 0.000937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 3/4: 100%|██████████████| 1619/1619 [19:48<00:00,  1.36it/s, a_r=0.633, d_r=0.633, loss=0.000914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/4, train loss = 0.000913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch (train) 4/4: 100%|███████████████| 1619/1619 [19:49<00:00,  1.36it/s, a_r=0.64, d_r=0.639, loss=0.000916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/4, train loss = 0.000896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_nr in range(10):\n",
    "    model_m = SpliceAI_10K(CL_max)\n",
    "    model_m.apply(keras_init)\n",
    "    model_m = model_m.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        model_m = nn.DataParallel(model_m)\n",
    "    \n",
    "    model_m.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_071122_{}'.format(model_nr)))\n",
    "    modelFileName = '../Results/PyTorch_Models/spliceai_encoder_10k_finetune_rnasplice-blood_050623_{}'.format(model_nr)\n",
    "    loss = categorical_crossentropy_2d().loss\n",
    "    #loss = kl_div_2d(temp=temp).loss\n",
    "    optimizer = torch.optim.AdamW(model_m.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    warmup = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=100)\n",
    "    h = trainModel(model_m,modelFileName,loss,train_loader,None,optimizer,scheduler,warmup,BATCH_SIZE,epochs,device,skipValidation=True,lowValidationGPUMem=True,NUM_ACCUMULATION_STEPS=NUM_ACCUMULATION_STEPS,CL_max=CL_max,reinforce=False,continous_labels=False)\n",
    "    hs.append(h)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 16/16 [06:18<00:00, 23.67s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "h5f = h5py.File('/odinn/tmp/benediktj/SpliceAITrainingCode/dataset_test_0_10k.h5')\n",
    "\n",
    "num_idx = len(h5f.keys())//2\n",
    "\n",
    "test_dataset = h5pyDataset(h5f,list(range(num_idx)))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_finetune_rnasplice-blood_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    \n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "ce_2d = []\n",
    "\n",
    "for (batch_chunks,target_chunks) in tqdm(test_loader):\n",
    "    batch_chunks = torch.transpose(batch_chunks[0].to(device),1,2)\n",
    "    target_chunks = torch.transpose(torch.squeeze(target_chunks[0].to(device),0),1,2)\n",
    "    #print(np.max(target_chunks.cpu().numpy()[:,2,:]))\n",
    "    n_chunks = int(np.ceil(batch_chunks.shape[0]/BATCH_SIZE))\n",
    "    batch_chunks = torch.chunk(batch_chunks, n_chunks, dim=0)\n",
    "    target_chunks = torch.chunk(target_chunks, n_chunks, dim=0)\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    for j in range(len(batch_chunks)):\n",
    "        batch_features = batch_chunks[j]\n",
    "        targets = target_chunks[j]\n",
    "        outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "        outputs = torch.mean(torch.stack(outputs),dim=0)\n",
    "        #outputs = odds_gmean(torch.stack(outputs))\n",
    "        #outputs = (outputs[0]+outputs[1]+outputs[2])/n_models\n",
    "        targets_list.extend(targets.unsqueeze(0))\n",
    "        outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(torch.vstack(targets_list),1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(torch.vstack(outputs_list),1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0005279586512631472\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9969\t0.9496\t0.9873\t0.9897\t0.9782\t0.9918\t0.8195\t0.1928\t0.0542\t13569\t14289.0\t14289\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9971\t0.9515\t0.9896\t0.9917\t0.9802\t0.9919\t0.8320\t0.2018\t0.0556\t13596\t14289.0\t14289\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getData\n",
    "setType = 'test'\n",
    "annotation_test, transcriptToLabel_test, seqData = getData('/odinn/tmp/benediktj/Data/SplicePrediction-050422', setType)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import getDataPointListFull,DataPointFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 1386/1386 [23:40<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_finetune_rnasplice-blood_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListFull(annotation_test,transcriptToLabel_test,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0003201272902582534\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9799\t0.9255\t0.9885\t0.9948\t0.9583\t0.9916\t0.8257\t0.1771\t0.0503\t83027\t89712.0\t89712\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9815\t0.9302\t0.9916\t0.9964\t0.9634\t0.9916\t0.8360\t0.1814\t0.0518\t83451\t89712.0\t89712\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "setType = 'test'\n",
    "annotation_test, gene_to_label, seqData = get_GTEX_v8_Data(data_dir, setType,'annotation_GTEX_v8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "100%|████████████████████████████████████████████████████████████████████████| 803/803 [25:53<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "n_models = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_m = SpliceAI_10K(CL_max)\n",
    "model_m.apply(keras_init)\n",
    "model_m = model_m.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_m = nn.DataParallel(model_m)\n",
    "\n",
    "output_class_labels = ['Null', 'Acceptor', 'Donor']\n",
    "\n",
    "#for output_class in [1,2]:\n",
    "models = [copy.deepcopy(model_m) for i in range(n_models)]\n",
    "[model.load_state_dict(torch.load('../Results/PyTorch_Models/spliceai_encoder_10k_finetune_rnasplice-blood_050623_{}'.format(i))) for i,model in enumerate(models)]\n",
    "#nr = [0,2,3]\n",
    "#[model.load_state_dict(torch.load('../Results/PyTorch_Models/transformer_encoder_40k_201221_{}'.format(nr[i]))) for i,model in enumerate(models)]\n",
    "#chunkSize = num_idx/10\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "Y_true_acceptor, Y_pred_acceptor = [],[]\n",
    "Y_true_donor, Y_pred_donor = [],[]\n",
    "test_dataset = spliceDataset(getDataPointListGTEX(annotation_test,gene_to_label,SL,CL_max,shift=SL))\n",
    "test_dataset.seqData = seqData\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "#targets_list = []\n",
    "#outputs_list = []\n",
    "ce_2d = []\n",
    "for (batch_features ,targets) in tqdm(test_loader):\n",
    "    batch_features = batch_features.type(torch.FloatTensor).to(device)\n",
    "    targets = targets.to(device)[:,:,CL_max//2:-CL_max//2]\n",
    "    outputs = ([models[i](batch_features).detach() for i in range(n_models)])\n",
    "    #outputs = (outputs[0]+outputs[1]+outputs[2]+outputs[3]+outputs[4])/n_models\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = torch.mean(outputs,dim=0)\n",
    "    #outputs = odds_gmean(outputs)\n",
    "    #targets_list.extend(targets.unsqueeze(0))\n",
    "    #outputs_list.extend(outputs.unsqueeze(0))\n",
    "\n",
    "    targets = torch.transpose(targets,1,2).cpu().numpy()\n",
    "    outputs = torch.transpose(outputs,1,2).cpu().numpy()\n",
    "    ce_2d.append(cross_entropy_2d(targets,outputs))\n",
    "\n",
    "    is_expr = (targets.sum(axis=(1,2)) >= 1)\n",
    "    Y_true_acceptor.extend(targets[is_expr, :, 1].flatten())\n",
    "    Y_true_donor.extend(targets[is_expr, :, 2].flatten())\n",
    "    Y_pred_acceptor.extend(outputs[is_expr, :, 1].flatten())\n",
    "    Y_pred_donor.extend(outputs[is_expr, :, 2].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy = 0.0007128483277989966\n",
      "\n",
      "\u001b[1mAcceptor:\u001b[0m\n",
      "0.9977\t0.7404\t0.8768\t0.951\t0.8324\t0.9444\t0.2401\t0.0732\t0.0207\t73199\t98870.0\t98870\n",
      "\n",
      "\u001b[1mDonor:\u001b[0m\n",
      "0.9976\t0.7412\t0.8749\t0.9459\t0.8308\t0.9422\t0.2447\t0.0743\t0.0207\t74201\t100114.0\t100114\n"
     ]
    }
   ],
   "source": [
    "mean_ce = np.mean(ce_2d)\n",
    "print('Cross entropy = {}'.format(mean_ce))\n",
    "Y_true_acceptor, Y_pred_acceptor,Y_true_donor, Y_pred_donor = np.array(Y_true_acceptor), np.array(Y_pred_acceptor),np.array(Y_true_donor), np.array(Y_pred_donor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Acceptor'))\n",
    "acceptor_val_results = print_topl_statistics(Y_true_acceptor, Y_pred_acceptor)\n",
    "print(\"\\n\\033[1m{}:\\033[0m\".format('Donor'))\n",
    "donor_val_results =print_topl_statistics(Y_true_donor, Y_pred_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407999999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7404+0.7412)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8324+0.8308)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198984"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98870+100114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73199+74201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
